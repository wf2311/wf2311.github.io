{"meta":{"title":"王峰的博客","subtitle":"保持学习","description":null,"author":"王峰","url":"https://www.wangfeng.pro"},"pages":[{"title":"About","date":"2021-04-29T08:59:32.080Z","updated":"2021-04-29T08:59:32.080Z","comments":true,"path":"about/index.html","permalink":"https://www.wangfeng.pro/about/index.html","excerpt":"","text":""},{"title":"archives","date":"2018-01-04T16:00:00.000Z","updated":"2018-10-25T17:26:31.581Z","comments":false,"path":"archives/index.html","permalink":"https://www.wangfeng.pro/archives/index.html","excerpt":"","text":""},{"title":"Categories","date":"2021-04-29T08:59:32.082Z","updated":"2021-04-29T08:59:32.081Z","comments":true,"path":"categories/index.html","permalink":"https://www.wangfeng.pro/categories/index.html","excerpt":"","text":""},{"title":"contact","date":"2018-09-30T09:25:30.000Z","updated":"2020-04-30T01:10:57.364Z","comments":true,"path":"contact/index.html","permalink":"https://www.wangfeng.pro/contact/index.html","excerpt":"","text":""},{"title":"friends","date":"2018-12-12T13:25:30.000Z","updated":"2020-05-22T04:53:42.137Z","comments":true,"path":"friends/index.html","permalink":"https://www.wangfeng.pro/friends/index.html","excerpt":"","text":""},{"title":"Tags","date":"2021-04-29T08:59:32.085Z","updated":"2021-04-29T08:59:32.085Z","comments":true,"path":"tags/index.html","permalink":"https://www.wangfeng.pro/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"SpringCloud中使用Apollo实现动态刷新","slug":"微服务/配置中心/SpringCloud中使用Apollo实现动态刷新","date":"2021-05-17T12:14:24.000Z","updated":"2021-05-23T02:05:13.294Z","comments":true,"path":"2021/05/springcloud中使用apollo实现动态刷新.html","link":"","permalink":"https://www.wangfeng.pro/2021/05/springcloud%E4%B8%AD%E4%BD%BF%E7%94%A8apollo%E5%AE%9E%E7%8E%B0%E5%8A%A8%E6%80%81%E5%88%B7%E6%96%B0","excerpt":"","text":"普通字段在需要刷新的字段上使用@value注解即可，例如： 12345678@Value(&quot;$&#123;test.user.name&#125;&quot;)private String name;@Value(&quot;$&#123;test.user.age&#125;&quot;)private Integer age;@Value(&quot;$&#123;test.user.sex&#125;&quot;)private Boolean sex; bean使用@ConfigurationProperties动态刷新bean使用@ConfigurationProperties注解目前还不支持自动刷新，得编写一定的代码实现刷新。目前官方提供2种刷新方案： 基于RefreshScope实现刷新 基于EnvironmentChangeEvent实现刷新 方法一：基于RefreshScope实现刷新 确保项目中已引入依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-context&lt;/artifactId&gt;&lt;/dependency&gt; 实体类上使用@RefreshScope注解 123456789@ConfigurationProperties(&quot;test.user&quot;)@Data@Component@RefreshScopepublic class TestUserProperties implements Serializable &#123; private Integer age; private String name; private Boolean sex;&#125; 在namespace=config的命名空间中定义配置： 123test.user.name = zhangsantest.user.age = 10test.user.sex = 1 利用RefreshScope搭配@ApolloConfigChangeListener监听实现bean的动态刷新 1234567891011121314@Componentpublic class ApolloDynamicConfigPropertiesRefresh &#123; @Resource RefreshScope refreshScope; @ApolloConfigChangeListener(value=&quot;config&quot;) private void refresh(ConfigChangeEvent changeEvent)&#123; refreshScope.refresh(&quot;testUserProperties&quot;); PrintChangeKeyUtils.printChange(changeEvent); &#125;&#125; @ApolloConfigChangeListener(value=&quot;config&quot;) 表示监听namespace=config的配置文件的变化 refreshScope.refresh(&quot;testUserProperties&quot;); 表示如果触发监听事件，则刷新名为testUserProperties的bean； PrintChangeKeyUtils.printChange(changeEvent); 表示打印发送变化的熟悉（可选）,PrintChangeKeyUtils定义为： 123456789101112131415161718import com.ctrip.framework.apollo.model.ConfigChange;import com.ctrip.framework.apollo.model.ConfigChangeEvent;import org.springframework.util.CollectionUtils;import java.util.Set;public class PrintChangeKeyUtils &#123; public static void printChange(ConfigChangeEvent changeEvent) &#123; Set&lt;String&gt; changeKeys = changeEvent.changedKeys(); if (!CollectionUtils.isEmpty(changeKeys)) &#123; for (String changeKey : changeKeys) &#123; ConfigChange configChange = changeEvent.getChange(changeKey); System.out.println(&quot;key:&quot; + changeKey + &quot;;oldValue:&quot; + configChange.getOldValue() + &quot;;newValue:&quot; + configChange.getNewValue()); &#125; &#125; &#125;&#125; 方法二：基于EnvironmentChangeEvent实现刷新 定义实体类 12345678@ConfigurationProperties(&quot;test.user&quot;)@Data@Componentpublic class TestUserProperties implements Serializable &#123; private Integer age; private String name; private Boolean sex;&#125; 与方法一的差异是不使用@RefreshScope注解 利用spring的事件驱动配合@ApolloConfigChangeListener监听实现bean的动态刷新： 1234567891011121314151617181920@Componentpublic class ApolloDynamicConfigPropertiesRefresh implements ApplicationContextAware &#123; private ApplicationContext applicationContext; RefreshScope refreshScope; @ApolloConfigChangeListener(value=&quot;config&quot;) private void refresh(ConfigChangeEvent changeEvent)&#123; applicationContext.publishEvent(new EnvironmentChangeEvent(changeEvent.changedKeys())); PrintChangeKeyUtils.printChange(changeEvent); &#125; @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException &#123; this.applicationContext = applicationContext; &#125;&#125; 两种方式动态刷新原理浅析：RefreshScope首先了解Spring中几个相关的类： 注解@RefreshScope(org.springframework.cloud.context.config.annotation.RefreshScope) 12345678910111213@Target(&#123; ElementType.TYPE, ElementType.METHOD &#125;)@Retention(RetentionPolicy.RUNTIME)@Scope(&quot;refresh&quot;)@Documentedpublic @interface RefreshScope &#123; /** * @see Scope#proxyMode() * @return proxy mode */ ScopedProxyMode proxyMode() default ScopedProxyMode.TARGET_CLASS;&#125; 注解@Scope(org.springframework.context.annotation.Scope) 123456789101112131415@Target(&#123;ElementType.TYPE, ElementType.METHOD&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface Scope &#123; @AliasFor(&quot;scopeName&quot;) String value() default &quot;&quot;; @AliasFor(&quot;value&quot;) String scopeName() default &quot;&quot;; ScopedProxyMode proxyMode() default ScopedProxyMode.DEFAULT;&#125; 接口Scope(org.springframework.beans.factory.config.Scope) 12345678910111213141516public interface Scope &#123; Object get(String name, ObjectFactory&lt;?&gt; objectFactory); @Nullable Object remove(String name); void registerDestructionCallback(String name, Runnable callback); @Nullable Object resolveContextualObject(String key); @Nullable String getConversationId();&#125; 类RefreshScope(org.springframework.cloud.context.scope.refresh.RefreshScope) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091@ManagedResourcepublic class RefreshScope extends GenericScope implements ApplicationContextAware,ApplicationListener&lt;ContextRefreshedEvent&gt;, Ordered &#123; private ApplicationContext context; private BeanDefinitionRegistry registry; private boolean eager = true; private int order = Ordered.LOWEST_PRECEDENCE - 100; /** * Creates a scope instance and gives it the default name: &quot;refresh&quot;. */ public RefreshScope() &#123; super.setName(&quot;refresh&quot;); &#125; @Override public int getOrder() &#123; return this.order; &#125; public void setOrder(int order) &#123; this.order = order; &#125; public void setEager(boolean eager) &#123; this.eager = eager; &#125; @Override public void postProcessBeanDefinitionRegistry(BeanDefinitionRegistry registry) throws BeansException &#123; this.registry = registry; super.postProcessBeanDefinitionRegistry(registry); &#125; @Override public void onApplicationEvent(ContextRefreshedEvent event) &#123; start(event); &#125; public void start(ContextRefreshedEvent event) &#123; if (event.getApplicationContext() == this.context &amp;&amp; this.eager &amp;&amp; this.registry != null) &#123; eagerlyInitialize(); &#125; &#125; private void eagerlyInitialize() &#123; for (String name : this.context.getBeanDefinitionNames()) &#123; BeanDefinition definition = this.registry.getBeanDefinition(name); if (this.getName().equals(definition.getScope()) &amp;&amp; !definition.isLazyInit()) &#123; Object bean = this.context.getBean(name); if (bean != null) &#123; bean.getClass(); &#125; &#125; &#125; &#125; @ManagedOperation(description = &quot;Dispose of the current instance of bean name &quot; + &quot;provided and force a refresh on next method execution.&quot;) public boolean refresh(String name) &#123; if (!name.startsWith(SCOPED_TARGET_PREFIX)) &#123; // User wants to refresh the bean with this name but that isn&#x27;t the one in the // cache... name = SCOPED_TARGET_PREFIX + name; &#125; // Ensure lifecycle is finished if bean was disposable if (super.destroy(name)) &#123; this.context.publishEvent(new RefreshScopeRefreshedEvent(name)); return true; &#125; return false; &#125; @ManagedOperation(description = &quot;Dispose of the current instance of all beans &quot; + &quot;in this scope and force a refresh on next method execution.&quot;) public void refreshAll() &#123; super.destroy(); this.context.publishEvent(new RefreshScopeRefreshedEvent()); &#125; @Override public void setApplicationContext(ApplicationContext context) throws BeansException &#123; this.context = context; &#125;&#125; 带有@RefreshScope注解后的Bean，在初始话的过程中，会通过AnnotationScopeMetadataResolver#resolveScopeMetadata提取元数据： 123456789101112131415161718@Overridepublic ScopeMetadata resolveScopeMetadata(BeanDefinition definition) &#123; ScopeMetadata metadata = new ScopeMetadata(); if (definition instanceof AnnotatedBeanDefinition) &#123; AnnotatedBeanDefinition annDef = (AnnotatedBeanDefinition) definition; AnnotationAttributes attributes = AnnotationConfigUtils.attributesFor( annDef.getMetadata(), this.scopeAnnotationType); if (attributes != null) &#123; metadata.setScopeName(attributes.getString(&quot;value&quot;)); ScopedProxyMode proxyMode = attributes.getEnum(&quot;proxyMode&quot;); if (proxyMode == ScopedProxyMode.DEFAULT) &#123; proxyMode = this.defaultProxyMode; &#125; metadata.setScopedProxyMode(proxyMode); &#125; &#125; return metadata;&#125; 可以理解为 @RefreshScope 是scopeName=”refresh”的 @Scope，其Bean的注册将通过AnnotatedBeanDefinitionReader#registerBean完成的： 1234567891011121314151617181920212223242526272829303132333435363738private &lt;T&gt; void doRegisterBean(Class&lt;T&gt; beanClass, @Nullable String name, @Nullable Class&lt;? extends Annotation&gt;[] qualifiers, @Nullable Supplier&lt;T&gt; supplier, @Nullable BeanDefinitionCustomizer[] customizers) &#123; AnnotatedGenericBeanDefinition abd = new AnnotatedGenericBeanDefinition(beanClass); if (this.conditionEvaluator.shouldSkip(abd.getMetadata())) &#123; return; &#125; abd.setInstanceSupplier(supplier); ScopeMetadata scopeMetadata = this.scopeMetadataResolver.resolveScopeMetadata(abd); abd.setScope(scopeMetadata.getScopeName()); String beanName = (name != null ? name : this.beanNameGenerator.generateBeanName(abd, this.registry)); AnnotationConfigUtils.processCommonDefinitionAnnotations(abd); if (qualifiers != null) &#123; for (Class&lt;? extends Annotation&gt; qualifier : qualifiers) &#123; if (Primary.class == qualifier) &#123; abd.setPrimary(true); &#125; else if (Lazy.class == qualifier) &#123; abd.setLazyInit(true); &#125; else &#123; abd.addQualifier(new AutowireCandidateQualifier(qualifier)); &#125; &#125; &#125; if (customizers != null) &#123; for (BeanDefinitionCustomizer customizer : customizers) &#123; customizer.customize(abd); &#125; &#125; BeanDefinitionHolder definitionHolder = new BeanDefinitionHolder(abd, beanName); definitionHolder = AnnotationConfigUtils.applyScopedProxyMode(scopeMetadata, definitionHolder, this.registry); BeanDefinitionReaderUtils.registerBeanDefinition(definitionHolder, this.registry); &#125; 测试123456789101112131415161718192021222324252627@RestController@RequestMapping(&quot;/test/dynamic/config&quot;)public class DynamicConfigTestController &#123; @Value(&quot;$&#123;test.user.name&#125;&quot;) private String name; @Value(&quot;$&#123;test.user.age&#125;&quot;) private Integer age; @Value(&quot;$&#123;test.user.sex&#125;&quot;) private Boolean sex; @Resource private TestUserProperties userProperties; @GetMapping(&quot;/user&quot;) public Map&lt;String, Object&gt; properties() &#123; Map&lt;String, Object&gt; map = new HashMap&lt;&gt;(); map.put(&quot;name&quot;, name); map.put(&quot;age&quot;, age); map.put(&quot;sex&quot;, sex); map.put(&quot;user&quot;, userProperties.toString()); return map; &#125;&#125; 参考 apollo与springboot集成实现动态刷新配置 @RefreshScope那些事","categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.wangfeng.pro/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"配置中心","slug":"微服务/配置中心","permalink":"https://www.wangfeng.pro/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/"}],"tags":[{"name":"Apollo","slug":"Apollo","permalink":"https://www.wangfeng.pro/tags/Apollo/"}]},{"title":"K8S中搭建Apollo","slug":"微服务/配置中心/K8S中搭建Apollo","date":"2021-05-10T03:19:03.000Z","updated":"2021-05-23T08:32:08.534Z","comments":true,"path":"2021/05/k8s中搭建apollo.html","link":"","permalink":"https://www.wangfeng.pro/2021/05/k8s%E4%B8%AD%E6%90%AD%E5%BB%BAapollo","excerpt":"","text":"环境准备 Rancher k8s 1.20 Helm 3 MySQL数据库 添加Apollo Helm Chart仓库12helm repo add apollo https://www.apolloconfig.com/chartshelm search repo apollo 数据库脚本 下载apollo/scripts/docker-quick-start/sql目录下的apolloportaldb.sql和apolloconfigdb.sql两个SQL脚本; 由于搭建的Apollo服务将会用于公司内网1套开发环境和6套测试环境，所以需要搭建1套apollo-portal服务和7套apollo-configservice和apollo-adminservice服务，对应的需要建立一套ApolloPortalDB和7套ApolloConfigDB: 使用apolloportaldb.sql建立ApolloConfigDB库； 使用apolloportaldb.sql建立ApolloConfigDB_20_21、ApolloConfigDB_20_2、ApolloConfigDB_20_207、ApolloConfigDB_20_22、ApolloConfigDB_20_76、ApolloConfigDB_20_91、ApolloConfigDB_20_105库 服务部署部署apollo-configservice和apollo-adminservice123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687helm install apollo-service-20-2 \\ --set configdb.host=&lt;MYSQL_IP&gt; \\ --set configdb.port=&lt;MYSQL_PORT&gt; \\ --set configdb.userName=&lt;MYSQL_USERNAME&gt; \\ --set configdb.password=&lt;MYSQL_PASSWORD&gt; \\ --set configdb.dbName=ApolloConfigDB_20_2 \\ --set configdb.service.enabled=true \\ --set configService.replicaCount=1 \\ --set adminService.replicaCount=1 \\ -n apollo \\ apollo/apollo-servicehelm install apollo-service-20-207 \\ --set configdb.host=&lt;MYSQL_IP&gt; \\ --set configdb.port=&lt;MYSQL_PORT&gt; \\ --set configdb.userName=&lt;MYSQL_USERNAME&gt; \\ --set configdb.password=&lt;MYSQL_PASSWORD&gt; \\ --set configdb.dbName=ApolloConfigDB_20_207 \\ --set configdb.service.enabled=true \\ --set configService.replicaCount=1 \\ --set adminService.replicaCount=1 \\ -n apollo \\ apollo/apollo-servicehelm install apollo-service-20-21 \\ --set configdb.host=&lt;MYSQL_IP&gt; \\ --set configdb.port=&lt;MYSQL_PORT&gt; \\ --set configdb.userName=&lt;MYSQL_USERNAME&gt; \\ --set configdb.password=&lt;MYSQL_PASSWORD&gt; \\ --set configdb.dbName=ApolloConfigDB_20_21 \\ --set configdb.service.enabled=true \\ --set configService.replicaCount=1 \\ --set adminService.replicaCount=1 \\ -n apollo \\ apollo/apollo-servicehelm install apollo-service-20-22 \\ --set configdb.host=&lt;MYSQL_IP&gt; \\ --set configdb.port=&lt;MYSQL_PORT&gt; \\ --set configdb.userName=&lt;MYSQL_USERNAME&gt; \\ --set configdb.password=&lt;MYSQL_PASSWORD&gt; \\ --set configdb.dbName=ApolloConfigDB_20_22 \\ --set configdb.service.enabled=true \\ --set configService.replicaCount=1 \\ --set adminService.replicaCount=1 \\ -n apollo \\ apollo/apollo-servicehelm install apollo-service-20-76 \\ --set configdb.host=&lt;MYSQL_IP&gt; \\ --set configdb.port=&lt;MYSQL_PORT&gt; \\ --set configdb.userName=&lt;MYSQL_USERNAME&gt; \\ --set configdb.password=&lt;MYSQL_PASSWORD&gt; \\ --set configdb.dbName=ApolloConfigDB_20_76 \\ --set configdb.service.enabled=true \\ --set configService.replicaCount=1 \\ --set adminService.replicaCount=1 \\ -n apollo \\ apollo/apollo-servicehelm install apollo-service-20-91 \\ --set configdb.host=&lt;MYSQL_IP&gt; \\ --set configdb.port=&lt;MYSQL_PORT&gt; \\ --set configdb.userName=&lt;MYSQL_USERNAME&gt; \\ --set configdb.password=&lt;MYSQL_PASSWORD&gt; \\ --set configdb.dbName=ApolloConfigDB_20_91 \\ --set configdb.service.enabled=true \\ --set configService.replicaCount=1 \\ --set adminService.replicaCount=1 \\ -n apollo \\ apollo/apollo-servicehelm install apollo-service-20-105 \\ --set configdb.host=&lt;MYSQL_IP&gt; \\ --set configdb.port=&lt;MYSQL_PORT&gt; \\ --set configdb.userName=&lt;MYSQL_USERNAME&gt; \\ --set configdb.password=&lt;MYSQL_PASSWORD&gt; \\ --set configdb.dbName=ApolloConfigDB_20_105 \\ --set configdb.service.enabled=true \\ --set configService.replicaCount=1 \\ --set adminService.replicaCount=1 \\ -n apollo \\ apollo/apollo-service 部署apollo-portal123456789101112131415161718helm install apollo-portal \\ --set portaldb.host=&lt;MYSQL_IP&gt; \\ --set portaldb.port=&lt;MYSQL_PORT&gt; \\ --set portaldb.userName=&lt;MYSQL_USERNAME&gt; \\ --set portaldb.password=&lt;MYSQL_PASSWORD&gt; \\ --set portaldb.dbName=ApolloPortalDB \\ --set portaldb.service.enabled=true \\ --set config.envs=&quot;dev21\\,test2\\,test22\\,test76\\,test91\\,test105\\,test207&quot; \\ --set config.metaServers.dev21=http://apollo-service-20-21-apollo-configservice.apollo:8080 \\ --set config.metaServers.test2=http://apollo-service-20-2-apollo-configservice.apollo:8080 \\ --set config.metaServers.test22=http://apollo-service-20-22-apollo-configservice.apollo:8080 \\ --set config.metaServers.test76=http://apollo-service-20-76-apollo-configservice.apollo:8080 \\ --set config.metaServers.test91=http://apollo-service-20-91-apollo-configservice.apollo:8080 \\ --set config.metaServers.test105=http://apollo-service-20-105-apollo-configservice.apollo:8080 \\ --set config.metaServers.test207=http://apollo-service-20-207-apollo-configservice.apollo:8080 \\ --set replicaCount=1 \\ -n apollo \\ apollo/apollo-portal 在Rancher配置端口映射准备工作：搭建好metalb，做好虚拟ip规划 metalb搭建：参考metalb官方安装文档 IP规划 Apollo Portal192.168.40.31:8070 Apollo ConfigServer 环境 ip:port dev21 192.168.40.31:8080 test02 192.168.40.32:8080 test22 192.168.40.33:8080 test76 192.168.40.34:8080 test91 192.168.40.35:8080 test105 192.168.40.36:8080 test207 192.168.40.37:8080 部署脚本： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168---apiVersion: v1kind: Servicemetadata: labels: cattle.io/creator: norman name: apollo-portal-port namespace: apollo annotations: metallb.universe.tf/allow-shared-ip: ip_192_168_40_31spec: externalTrafficPolicy: Cluster loadBalancerIP: 192.168.40.31 ports: - port: 8070 protocol: TCP targetPort: 8070 selector: app: apollo-portal sessionAffinity: None type: LoadBalancer---apiVersion: v1kind: Servicemetadata: labels: cattle.io/creator: norman name: apollo-20-21-port namespace: apollo annotations: metallb.universe.tf/allow-shared-ip: ip_192_168_40_31spec: externalTrafficPolicy: Cluster loadBalancerIP: 192.168.40.31 ports: - port: 8080 protocol: TCP targetPort: 8080 selector: app: apollo-service-20-21-apollo-configservice sessionAffinity: None type: LoadBalancer---apiVersion: v1kind: Servicemetadata: labels: cattle.io/creator: norman name: apollo-20-02-port namespace: apollo annotations: metallb.universe.tf/allow-shared-ip: ip_192_168_40_32spec: externalTrafficPolicy: Cluster loadBalancerIP: 192.168.40.32 ports: - port: 8080 protocol: TCP targetPort: 8080 selector: app: apollo-service-20-2-apollo-configservice sessionAffinity: None type: LoadBalancer---apiVersion: v1kind: Servicemetadata: labels: cattle.io/creator: norman name: apollo-20-22-port namespace: apollo annotations: metallb.universe.tf/allow-shared-ip: ip_192_168_40_33spec: externalTrafficPolicy: Cluster loadBalancerIP: 192.168.40.33 ports: - port: 8080 protocol: TCP targetPort: 8080 selector: app: apollo-service-20-22-apollo-configservice sessionAffinity: None type: LoadBalancer---apiVersion: v1kind: Servicemetadata: labels: cattle.io/creator: norman name: apollo-20-76-port namespace: apollo annotations: metallb.universe.tf/allow-shared-ip: ip_192_168_40_34spec: externalTrafficPolicy: Cluster loadBalancerIP: 192.168.40.34 ports: - port: 8080 protocol: TCP targetPort: 8080 selector: app: apollo-service-20-76-apollo-configservice sessionAffinity: None type: LoadBalancer---apiVersion: v1kind: Servicemetadata: labels: cattle.io/creator: norman name: apollo-20-91-port namespace: apollo annotations: metallb.universe.tf/allow-shared-ip: ip_192_168_40_35spec: externalTrafficPolicy: Cluster loadBalancerIP: 192.168.40.35 ports: - port: 8080 protocol: TCP targetPort: 8080 selector: app: apollo-service-20-91-apollo-configservice sessionAffinity: None type: LoadBalancer---apiVersion: v1kind: Servicemetadata: labels: cattle.io/creator: norman name: apollo-20-105-port namespace: apollo annotations: metallb.universe.tf/allow-shared-ip: ip_192_168_40_36spec: externalTrafficPolicy: Cluster loadBalancerIP: 192.168.40.36 ports: - port: 8080 protocol: TCP targetPort: 8080 selector: app: apollo-service-20-105-apollo-configservice sessionAffinity: None type: LoadBalancer---apiVersion: v1kind: Servicemetadata: labels: cattle.io/creator: norman name: apollo-20-207-port namespace: apollo annotations: metallb.universe.tf/allow-shared-ip: ip_192_168_40_37spec: externalTrafficPolicy: Cluster loadBalancerIP: 192.168.40.37 ports: - port: 8080 protocol: TCP targetPort: 8080 selector: app: apollo-service-20-207-apollo-configservice sessionAffinity: None type: LoadBalancer 参考 基于kubernetes原生服务发现","categories":[{"name":"微服务","slug":"微服务","permalink":"https://www.wangfeng.pro/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"配置中心","slug":"微服务/配置中心","permalink":"https://www.wangfeng.pro/categories/%E5%BE%AE%E6%9C%8D%E5%8A%A1/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/"}],"tags":[{"name":"Apollo","slug":"Apollo","permalink":"https://www.wangfeng.pro/tags/Apollo/"},{"name":"K8S","slug":"K8S","permalink":"https://www.wangfeng.pro/tags/K8S/"}]},{"title":"一致性Hash算法","slug":"数据结构与算法/一致性Hash算法","date":"2021-04-27T11:08:03.000Z","updated":"2021-05-23T08:24:53.244Z","comments":true,"path":"2021/04/一致性hash算法.html","link":"","permalink":"https://www.wangfeng.pro/2021/04/%E4%B8%80%E8%87%B4%E6%80%A7hash%E7%AE%97%E6%B3%95","excerpt":"","text":"算法实现不带虚拟节点的实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import java.util.SortedMap;import java.util.TreeMap;/** * 不带虚拟节点的一致性Hash算法 */public class ConsistentHashingWithoutVirtualNode &#123; //待添加入Hash环的服务器列表 private static String[] servers = &#123;&quot;192.168.0.0:111&quot;, &quot;192.168.0.1:111&quot;, &quot;192.168.0.2:111&quot;, &quot;192.168.0.3:111&quot;, &quot;192.168.0.4:111&quot;&#125;; //key表示服务器的hash值，value表示服务器 private static SortedMap&lt;Integer, String&gt; sortedMap = new TreeMap&lt;&gt;(); //程序初始化，将所有的服务器放入sortedMap中 static &#123; for (int i = 0; i &lt; servers.length; i++) &#123; String server = servers[i]; int hash = getHash(server); System.out.println(&quot;[&quot; + server + &quot;]加入集合中, 其Hash值为&quot; + hash); sortedMap.put(hash, server); &#125; System.out.println(); &#125; //得到应当路由到的结点 private static String getServer(String key) &#123; //得到该key的hash值 int hash = getHash(key); //得到大于该Hash值的所有Map SortedMap&lt;Integer, String&gt; subMap = sortedMap.tailMap(hash); if (subMap.isEmpty()) &#123; //如果没有比该key的hash值大的，则从第一个node开始 Integer i = sortedMap.firstKey(); //返回对应的服务器 return sortedMap.get(i); &#125; else &#123; //第一个Key就是顺时针过去离node最近的那个结点 Integer i = subMap.firstKey(); //返回对应的服务器 return subMap.get(i); &#125; &#125; //使用FNV1_32_HASH算法计算服务器的Hash值,这里不使用重写hashCode的方法，最终效果没区别 private static int getHash(String str) &#123; final int p = 16777619; int hash = (int) 2166136261L; for (int i = 0; i &lt; str.length(); i++) hash = (hash ^ str.charAt(i)) * p; hash += hash &lt;&lt; 13; hash ^= hash &gt;&gt; 7; hash += hash &lt;&lt; 3; hash ^= hash &gt;&gt; 17; hash += hash &lt;&lt; 5; // 如果算出来的值为负数则取其绝对值 if (hash &lt; 0) hash = Math.abs(hash); return hash; &#125; public static void main(String[] args) &#123; String[] keys = &#123;&quot;太阳&quot;, &quot;月亮&quot;, &quot;星星&quot;&#125;; for (String key : keys) System.out.println(&quot;[&quot; + key + &quot;]的hash值为&quot; + getHash(key) + &quot;, 被路由到结点[&quot; + getServer(key) + &quot;]&quot;); &#125;&#125; 带虚拟节点的实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121import java.util.List;import java.util.SortedMap;import java.util.TreeMap;import java.util.concurrent.locks.StampedLock;/** * @author &lt;a href=&quot;mailto:wf2311@163.com&quot;&gt;wf2311&lt;/a&gt; * @since 2021/4/25 19:08. */public class ConsistentHashingWithVirtualNode &#123; private static final String NODE_SPILT = &quot;@@&quot;; private static final String NODE_PREFIX = &quot;VN&quot;; /** * key表示服务器的hash,value表示服务器 */ private final SortedMap&lt;Integer, String&gt; map = new TreeMap&lt;&gt;(); /** * 服务器节点 */ private final List&lt;String&gt; servers; /** * 虚拟节点数量 */ private final int virtualNodeNum; private final StampedLock lock = new StampedLock(); public ConsistentHashingWithVirtualNode(List&lt;String&gt; servers, int virtualNodeNum) &#123; this.servers = servers; this.virtualNodeNum = virtualNodeNum; init(); &#125; private void init() &#123; for (String server : servers) &#123; addServer(server); &#125; &#125; public void addServer(String server) &#123; long stamp = lock.writeLock(); try &#123; for (int i = 0; i &lt; virtualNodeNum; i++) &#123; String virtual = server + NODE_SPILT + NODE_PREFIX + i; int hash = getHash(virtual); map.put(hash, virtual); &#125; &#125; finally &#123; lock.unlockWrite(stamp); &#125; &#125; public void removeServer(String server) &#123; long stamp = lock.writeLock(); try &#123; for (int i = 0; i &lt; virtualNodeNum; i++) &#123; String virtual = server + NODE_SPILT + NODE_PREFIX + i; map.remove(getHash(virtual)); &#125; &#125; finally &#123; lock.unlockWrite(stamp); &#125; &#125; private void removeServer(String server, int i) &#123; long stamp = lock.writeLock(); try &#123; String virtual = server + NODE_SPILT + NODE_PREFIX + i; int hash = getHash(virtual); map.put(hash, virtual); &#125; finally &#123; lock.unlockWrite(stamp); &#125; &#125; public String findServer(String request) &#123; int hash = getHash(request); long stamp = lock.tryOptimisticRead(); String server = getServerByHashKey(hash); if (!lock.validate(stamp)) &#123; stamp = lock.readLock(); try &#123; server = getServerByHashKey(hash); &#125; finally &#123; lock.unlockRead(stamp); &#125; &#125; return server; &#125; private String getServerByHashKey(int hash) &#123; SortedMap&lt;Integer, String&gt; subMap = map.tailMap(hash); Integer targetServerKey = subMap.isEmpty() ? map.firstKey() : subMap.firstKey(); String virtual = map.get(targetServerKey); if (virtual != null) &#123; return virtual.split(NODE_SPILT)[0]; &#125; return null; &#125; private static int getHash(String str) &#123; final int p = 16777619; int hash = (int) 2166136261L; for (int i = 0; i &lt; str.length(); i++) hash = (hash ^ str.charAt(i)) * p; hash += hash &lt;&lt; 13; hash ^= hash &gt;&gt; 7; hash += hash &lt;&lt; 3; hash ^= hash &gt;&gt; 17; hash += hash &lt;&lt; 5; // 如果算出来的值为负数则取其绝对值 if (hash &lt; 0) hash = Math.abs(hash); return hash; &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://www.wangfeng.pro/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"分布式","slug":"分布式","permalink":"https://www.wangfeng.pro/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"}]},{"title":"漏桶算法","slug":"数据结构与算法/漏桶算法","date":"2021-04-25T03:52:03.000Z","updated":"2021-05-23T08:28:48.862Z","comments":true,"path":"2021/04/漏桶算法.html","link":"","permalink":"https://www.wangfeng.pro/2021/04/%E6%BC%8F%E6%A1%B6%E7%AE%97%E6%B3%95","excerpt":"","text":"实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788import java.util.concurrent.TimeUnit;/** * @author &lt;a href=&quot;mailto:wf2311@163.com&quot;&gt;wf2311&lt;/a&gt; * @since 2021/4/25 11:52. */public class LeakyBucketRateLimiter &#123; /** * 桶的大小 */ private final long bucket; /** * 桶的已用量 */ private long used; /** * 桶的流出速率 */ private final int rate; /** * 流出速率单位 */ private final TimeUnit rateUnit; /** * */ private final int perMillisRadio; /** * 最新刷新时间 */ private volatile long lastRefreshTime; public static LeakyBucketRateLimiter create(long bucket, int rate, TimeUnit rateUnit) &#123; return new LeakyBucketRateLimiter(bucket, rate, rateUnit); &#125; private LeakyBucketRateLimiter(long bucket, int rate, TimeUnit rateUnit) &#123; this.bucket = bucket; this.rate = rate; this.rateUnit = rateUnit; this.perMillisRadio = convertMillisRadio(); &#125; private int convertMillisRadio() &#123; switch (rateUnit) &#123; case MILLISECONDS: return 1; case SECONDS: return 1000; case MINUTES: return 1000 * 60; case HOURS: return 1000 * 60 * 60; default: throw new AssertionError(); &#125; &#125; private void refreshBucketUsed() &#123; long now = System.currentTimeMillis(); if (lastRefreshTime &gt; 0) &#123; long n = (now - lastRefreshTime) / perMillisRadio; used = Math.max(0, used - n * rate); &#125; lastRefreshTime = now; &#125; public boolean tryAcquire() &#123; return tryAcquire(1); &#125; public synchronized boolean tryAcquire(int n) &#123; //刷新桶的使用量 refreshBucketUsed(); //如果桶未满，则获取成功 if (used + n &lt;= bucket) &#123; used += n; return true; &#125; return false; &#125;&#125;","categories":[{"name":"算法","slug":"算法","permalink":"https://www.wangfeng.pro/categories/%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"限流","slug":"限流","permalink":"https://www.wangfeng.pro/tags/%E9%99%90%E6%B5%81/"}]},{"title":"Queue","slug":"Java/容器/4. Queue","date":"2020-06-18T12:14:24.000Z","updated":"2021-05-24T12:00:41.288Z","comments":true,"path":"2020/06/queue.html","link":"","permalink":"https://www.wangfeng.pro/2020/06/queue","excerpt":"","text":"","categories":[{"name":"Java","slug":"Java","permalink":"https://www.wangfeng.pro/categories/Java/"},{"name":"容器","slug":"Java/容器","permalink":"https://www.wangfeng.pro/categories/Java/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Queue","slug":"Queue","permalink":"https://www.wangfeng.pro/tags/Queue/"},{"name":"Dueue","slug":"Dueue","permalink":"https://www.wangfeng.pro/tags/Dueue/"}]},{"title":"Set","slug":"Java/容器/3. Set","date":"2020-06-17T12:14:24.000Z","updated":"2021-05-24T11:46:13.463Z","comments":true,"path":"2020/06/set.html","link":"","permalink":"https://www.wangfeng.pro/2020/06/set","excerpt":"","text":"","categories":[{"name":"Java","slug":"Java","permalink":"https://www.wangfeng.pro/categories/Java/"},{"name":"容器","slug":"Java/容器","permalink":"https://www.wangfeng.pro/categories/Java/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Set","slug":"Set","permalink":"https://www.wangfeng.pro/tags/Set/"}]},{"title":"NavigableMap","slug":"Java/容器/Map/NavigableMap","date":"2020-06-16T14:15:24.000Z","updated":"2021-05-24T12:11:52.681Z","comments":true,"path":"2020/06/navigablemap.html","link":"","permalink":"https://www.wangfeng.pro/2020/06/navigablemap","excerpt":"","text":"总览","categories":[{"name":"Java","slug":"Java","permalink":"https://www.wangfeng.pro/categories/Java/"},{"name":"容器","slug":"Java/容器","permalink":"https://www.wangfeng.pro/categories/Java/%E5%AE%B9%E5%99%A8/"},{"name":"Map","slug":"Java/容器/Map","permalink":"https://www.wangfeng.pro/categories/Java/%E5%AE%B9%E5%99%A8/Map/"}],"tags":[{"name":"Map","slug":"Map","permalink":"https://www.wangfeng.pro/tags/Map/"}]},{"title":"SortedMap","slug":"Java/容器/Map/SortedMap","date":"2020-06-16T14:14:24.000Z","updated":"2021-05-24T12:05:28.049Z","comments":true,"path":"2020/06/sortedmap.html","link":"","permalink":"https://www.wangfeng.pro/2020/06/sortedmap","excerpt":"","text":"总览","categories":[{"name":"Java","slug":"Java","permalink":"https://www.wangfeng.pro/categories/Java/"},{"name":"容器","slug":"Java/容器","permalink":"https://www.wangfeng.pro/categories/Java/%E5%AE%B9%E5%99%A8/"},{"name":"Map","slug":"Java/容器/Map","permalink":"https://www.wangfeng.pro/categories/Java/%E5%AE%B9%E5%99%A8/Map/"}],"tags":[{"name":"Map","slug":"Map","permalink":"https://www.wangfeng.pro/tags/Map/"}]},{"title":"TreeMap","slug":"Java/容器/Map/TreeMap","date":"2020-06-16T13:14:24.000Z","updated":"2021-05-24T11:59:54.100Z","comments":true,"path":"2020/06/treemap.html","link":"","permalink":"https://www.wangfeng.pro/2020/06/treemap","excerpt":"","text":"总览","categories":[{"name":"Java","slug":"Java","permalink":"https://www.wangfeng.pro/categories/Java/"},{"name":"容器","slug":"Java/容器","permalink":"https://www.wangfeng.pro/categories/Java/%E5%AE%B9%E5%99%A8/"},{"name":"Map","slug":"Java/容器/Map","permalink":"https://www.wangfeng.pro/categories/Java/%E5%AE%B9%E5%99%A8/Map/"}],"tags":[{"name":"Map","slug":"Map","permalink":"https://www.wangfeng.pro/tags/Map/"}]},{"title":"Map","slug":"Java/容器/2. Map","date":"2020-06-16T12:14:24.000Z","updated":"2021-05-24T11:51:55.979Z","comments":true,"path":"2020/06/map.html","link":"","permalink":"https://www.wangfeng.pro/2020/06/map","excerpt":"","text":"总览 Map","categories":[{"name":"Java","slug":"Java","permalink":"https://www.wangfeng.pro/categories/Java/"},{"name":"容器","slug":"Java/容器","permalink":"https://www.wangfeng.pro/categories/Java/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"Map","slug":"Map","permalink":"https://www.wangfeng.pro/tags/Map/"}]},{"title":"List","slug":"Java/容器/1. List","date":"2020-06-15T12:14:24.000Z","updated":"2021-05-24T11:46:13.463Z","comments":true,"path":"2020/06/list.html","link":"","permalink":"https://www.wangfeng.pro/2020/06/list","excerpt":"","text":"","categories":[{"name":"Java","slug":"Java","permalink":"https://www.wangfeng.pro/categories/Java/"},{"name":"容器","slug":"Java/容器","permalink":"https://www.wangfeng.pro/categories/Java/%E5%AE%B9%E5%99%A8/"}],"tags":[{"name":"List","slug":"List","permalink":"https://www.wangfeng.pro/tags/List/"}]},{"title":"02、注册中心与CAP理论","slug":"分布式/分布式协议/02、注册中心与CAP理论","date":"2020-05-17T07:36:00.000Z","updated":"2021-05-23T02:17:49.059Z","comments":true,"path":"2020/05/02、注册中心与cap理论.html","link":"","permalink":"https://www.wangfeng.pro/2020/05/02%E3%80%81%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83%E4%B8%8Ecap%E7%90%86%E8%AE%BA","excerpt":"未完成","text":"f48401abf4af5ea52f379292f7c52cdee04aaad3c4e76cbf5fb2b7117946b99a083099e166ec30ee523f511c69cad33ef09a118837889c00f08b333563068612f9234df138fc6310441b63371d02b09839f336f72afa3b9f8e22e52c3de67e4fb0fd56fe4272f536df59ad27222fe3befef8b7921c5eb95a19493cdfd79cdca05c0c0772267b5c82fb84185f5c72f57900e551552afc0c52605aee79fbd59aa84dfeddae744860363bb2b2ca5b6d0f07236eea3c26612f7a2e19905784ac20fd1c376e05657a8b2fddf7319df05a468bc251043d034c4294c748fee1ebeff2e5564d66177f2e4d17f5d6445d57f6350e5cf3b473c61e32f68f1864540fbaba1073969a97bb203494c585b8dbb96e951611fdb99964a6142098418d2aadf95962ddc5c3e19ce18d33feea57264a97524881f2ecb53923991d0de540ca727057de786216d9a5d9346d827e003a6ec67b7870b0fdce529f7e6f8f47bd59aab8ee1cc62ceea961249f16b10c94e8b43479bd9df6e3d24e2bcaae2582e1096ca468597d1084cf0487da3be551d1427eff40d8366659a743b9f081735384d7a180b9bb0e967e86aa73571aa7a798bc009542440189ae49416fc85906e8f0bd48471c4becfc7e24b9bb86d6386435ddd894ec16 输入密码，查看文章","categories":[{"name":"分布式","slug":"分布式","permalink":"https://www.wangfeng.pro/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"分布式协议","slug":"分布式/分布式协议","permalink":"https://www.wangfeng.pro/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%AE%AE/"}],"tags":[{"name":"nacos","slug":"nacos","permalink":"https://www.wangfeng.pro/tags/nacos/"},{"name":"cap","slug":"cap","permalink":"https://www.wangfeng.pro/tags/cap/"}]},{"title":"01、CAP与BASE理论","slug":"分布式/分布式协议/01、CAP与BASE理论","date":"2020-05-17T06:38:43.000Z","updated":"2021-05-18T03:34:44.417Z","comments":true,"path":"2020/05/01、cap与base理论.html","link":"","permalink":"https://www.wangfeng.pro/2020/05/01%E3%80%81cap%E4%B8%8Ebase%E7%90%86%E8%AE%BA","excerpt":"","text":"CAP定义 一致性（Consistency）： 除非读取失败，否则不管访问的是哪个节点，在同一时间的数据返回的数据都是完全一致的； 可用性（Availability）：服务总是能正常响应数据，但不保证是最新数据； 分区容错性（Partition Tolerance）：在分布式系统内，即使因部分节点或者网络分区故障，导致任意数量的请求响应丢失或者延迟已经发送，后续系统仍能够对外提供服务； 侧重点 一致性强调的不是数据完整性，而是各个节点之间数据一致； 可用性强调的是服务可用，但不保证数据的一致； 分区容错性强调的是对分区故障的容错能力，即分布式系统不会因为已经发生过的故障导致整个系统会挂掉； CAP权衡CA由于在分布式系统中，由于网络延迟或网络分区的存在，P是一个基本要求，CA在分布式系统中几乎不存在； CP必须保证分布式系统的一致性，以至于可以牺牲掉系统的可用作容许系统停机或长时间无响应。例如像Redis、HBASE等分布式存储系统以及想Zookeeper这种分布式协调组件，必须要保证数据的一致性； AP牺牲分布式系统的强一致性，保证分布式系统的可用性； BASE理论定义BASE是Basically Available（基本可用）、Soft state（软状态）和Eventually consistent（最终一致性）三个短语的简写，BASE是对CAP中一致性和可用性权衡的结果，其来源于对大规模互联网系统分布式实践的结论，是基于CAP定理逐步演化而来的，其核心思想是即使无法做到强一致性（Strong consistency），但每个应用都可以根据自身的业务特点，采用适当的方式来使系统达到最终一致性（Eventual consistency）。 参考 轻松理解CAP理论","categories":[{"name":"分布式","slug":"分布式","permalink":"https://www.wangfeng.pro/categories/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"分布式协议","slug":"分布式/分布式协议","permalink":"https://www.wangfeng.pro/categories/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E5%8D%8F%E8%AE%AE/"}],"tags":[{"name":"CAP","slug":"CAP","permalink":"https://www.wangfeng.pro/tags/CAP/"},{"name":"BASE","slug":"BASE","permalink":"https://www.wangfeng.pro/tags/BASE/"}]},{"title":"让处于事务中的特定代码在事务提交成功后再执行","slug":"Spring/让处于事务中的特定代码在事务提交成功后再执行","date":"2019-11-19T12:11:43.000Z","updated":"2021-05-14T13:06:17.456Z","comments":true,"path":"2019/11/让处于事务中的特定代码在事务提交成功后再执行.html","link":"","permalink":"https://www.wangfeng.pro/2019/11/%E8%AE%A9%E5%A4%84%E4%BA%8E%E4%BA%8B%E5%8A%A1%E4%B8%AD%E7%9A%84%E7%89%B9%E5%AE%9A%E4%BB%A3%E7%A0%81%E5%9C%A8%E4%BA%8B%E5%8A%A1%E6%8F%90%E4%BA%A4%E6%88%90%E5%8A%9F%E5%90%8E%E5%86%8D%E6%89%A7%E8%A1%8C","excerpt":"问题描述之前遇到过一个这样的问题：在服务A里的执行一个保存数据库方法，数据保存成功后会将主键ID通过MQ发送给服务B,服务B再根据主键ID去查询保存的数据，进行其他逻辑处理。后来发现，在服务B中根据MQ发送过来的ID通过数据库偶尔会查不到数据信息。 后来通过调试才发现，是因为在服务A里的保存方法加了事务注解，保存的数据结果只有在当前方法执行完成后才会对外生效，而MQ消息则是在保存方法执行前发送的，如果服务B在服务A中保存方法执行完成前就收到了MQ消息，就会导致上述问题发生。同样，如果在MQ发送成功后，保存方法发生了异常导致事务回滚，服务B也会查不到数据或者查询到错误的数据。","text":"问题描述之前遇到过一个这样的问题：在服务A里的执行一个保存数据库方法，数据保存成功后会将主键ID通过MQ发送给服务B,服务B再根据主键ID去查询保存的数据，进行其他逻辑处理。后来发现，在服务B中根据MQ发送过来的ID通过数据库偶尔会查不到数据信息。 后来通过调试才发现，是因为在服务A里的保存方法加了事务注解，保存的数据结果只有在当前方法执行完成后才会对外生效，而MQ消息则是在保存方法执行前发送的，如果服务B在服务A中保存方法执行完成前就收到了MQ消息，就会导致上述问题发生。同样，如果在MQ发送成功后，保存方法发生了异常导致事务回滚，服务B也会查不到数据或者查询到错误的数据。 问题分析导致上述问题发生的根本原因还是因为发送MQ消息是在加了事务回滚的方法内部执行的，通过该方法保存或更新的数据只有在整个方法结束后才会对外生效，而MQ的消费者却有可能于改方法执行完成前收到消息。因此，最直接的解决办法是要将MQ消息放到事务方法结束后再执行。 但是，由于在项目中有很多处都是采用上述的这种逻辑，一个个改起来比较麻烦，最好能有一个通用的方式能够尽量少改动之前的业务逻辑代码就能解决问题。 解决方法对于这种通用业务的问题第一个想到的解决方法就是利用AOP：拦截所有带有事务回滚注解(@Transactional)的方法，通过某种方式获取到该方法内部所有要执行的发送MQ的调用代码，让它们在事务方法执行成功后在执行。 示例代码TransactionMessageAspect继承TransactionSynchronizationAdapter,实现对所有带有@Transactional注解方法的拦截： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970@Aspect@Componentpublic class TransactionMessageAspect extends TransactionSynchronizationAdapter &#123; @Resource private TransactionInterceptorHandler transactionInterceptorHandler; /** * 入口：拦截带有 @Transactional的方法,标记当前方法已进入事务模式 */ @Before(&quot;@annotation(org.springframework.transaction.annotation.Transactional)&quot;) public void registerTransactionSyncrhonization() &#123; TransactionSynchronizationManager.registerSynchronization(this); transactionInterceptorHandler.signInTransaction(); &#125; @Override public void beforeCommit(boolean readOnly) &#123; System.out.println(&quot;before commit&quot;); &#125; /** * 在事务结束并且没被回滚时再依次执行Callable方法 * * @param status */ @Override public void afterCompletion(int status) &#123; System.out.println(&quot;afterCompletion&quot;); try &#123; if (status != STATUS_ROLLED_BACK &amp;&amp; !CollectionUtils.isEmpty(transactionInterceptorHandler.getActions())) &#123; for (Callable action : transactionInterceptorHandler.getActions()) &#123; action.call(); &#125; &#125; &#125; catch (Exception e) &#123; &#125; finally &#123; transactionInterceptorHandler.clear(); &#125; &#125; @Override public void afterCommit() &#123; System.out.println(&quot;afterCommit&quot;); &#125; @Override public void suspend() &#123; System.out.println(&quot;suspend&quot;); &#125; @Override public void resume() &#123; System.out.println(&quot;resume&quot;); &#125; @Override public void flush() &#123; System.out.println(&quot;flush&quot;); &#125; @Override public void beforeCompletion() &#123; System.out.println(&quot;beforeCompletion&quot;); &#125;&#125; TransactionInterceptorHandler:使用ThreadLocal对当前线程中要执行的发送MQ方法进行缓存 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Componentpublic class TransactionInterceptorHandler &#123; private ThreadLocal&lt;Entity&gt; cache = ThreadLocal.withInitial(() -&gt; null); public void clear() &#123; cache.remove(); &#125; public boolean hasTransaction() &#123; Entity e = cache.get(); if (e == null) &#123; return false; &#125; return e.getInTransaction() != null &amp;&amp; e.getInTransaction(); &#125; public List&lt;Callable&gt; getActions() &#123; Entity e = cache.get(); if (e == null) &#123; return Collections.emptyList(); &#125; return e.getActions(); &#125; public void signInTransaction() &#123; Entity e= cache.get(); if (e == null) &#123; e = new Entity(); e.setInTransaction(true); e.setActions(new ArrayList&lt;&gt;()); &#125; cache.set(e); &#125; public void addAction(Callable action) &#123; Entity e = cache.get(); e.getActions().add(action); &#125; @Data public class Entity &#123; private List&lt;Callable&gt; actions; private Boolean inTransaction; &#125;&#125; MqMessage: 发送MQ消息的封装类 123456789@Componentpublic class MqMessage implements BaseMessage &#123; @Resource private TransactionInterceptorHandler transactionInterceptorHandler; @Override public void sendMessage(Object message) &#123; System.out.println(&quot;[&quot; + LocalDateTime.now() + &quot;] sendMsg :&quot; + JSON.toJSONString(message)); &#125;&#125; 将其更改为： 1234567891011121314151617181920@Componentpublic class MqMessage implements BaseMessage &#123; @Resource private TransactionInterceptorHandler transactionInterceptorHandler; @Override public void sendMessage(Object message) &#123; if (transactionInterceptorHandler.hasTransaction()) &#123; Callable&lt;Object&gt; callable = () -&gt; doSendMessage(message); transactionInterceptorHandler.addAction(callable); &#125;else &#123; doSendMessage(message); &#125; &#125; private Object doSendMessage(Object message) &#123; System.out.println(&quot;[&quot; + LocalDateTime.now() + &quot;] sendMsg :&quot; + JSON.toJSONString(message)); return null; &#125;&#125; 流程分析 TransactionMessageAspect会拦截带有@Transactional注解的方法，使用TransactionInterceptorHandler.signInTransaction()标记当前方法已进入事务模式; 如果在执行事务方法的过程中，有调用MqMessage.sendMessage()方法进行传递，会先将要发送的消息逻辑封装到Callable中，并通过TransactionInterceptorHandler.addAction保存在本地线程中； 当事务提交成功并没有回滚后再通过TransactionMessageAspect.afterCompletion()方法执行保存在本地线程中要发送MQ的调用方法； 参考 Spring hibernate , how to call some method after transaction commit or transaction rollback Creating a post commit when using transaction in Spring","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.wangfeng.pro/categories/Spring/"}],"tags":[{"name":"Aop","slug":"Aop","permalink":"https://www.wangfeng.pro/tags/Aop/"},{"name":"ThreadLocal","slug":"ThreadLocal","permalink":"https://www.wangfeng.pro/tags/ThreadLocal/"},{"name":"Transactional","slug":"Transactional","permalink":"https://www.wangfeng.pro/tags/Transactional/"}]},{"title":"wakatime手动同步本地离线数据至服务器","slug":"其它/Wakatime/wakatime手动同步本地离线数据至服务器","date":"2019-10-20T05:40:33.000Z","updated":"2021-05-14T11:59:44.321Z","comments":true,"path":"2019/10/wakatime手动同步本地离线数据至服务器.html","link":"","permalink":"https://www.wangfeng.pro/2019/10/wakatime%E6%89%8B%E5%8A%A8%E5%90%8C%E6%AD%A5%E6%9C%AC%E5%9C%B0%E7%A6%BB%E7%BA%BF%E6%95%B0%E6%8D%AE%E8%87%B3%E6%9C%8D%E5%8A%A1%E5%99%A8","excerpt":"控制台执行 1sudo pip install --upgrade wakatime","text":"控制台执行 1sudo pip install --upgrade wakatime 同步本地的9999条heartbeat数据至服务器 1wakatime --sync-offline-activity 9999 参考 How can i force sync all my coding activity?","categories":[{"name":"其它","slug":"其它","permalink":"https://www.wangfeng.pro/categories/%E5%85%B6%E5%AE%83/"}],"tags":[{"name":"WakaTime","slug":"WakaTime","permalink":"https://www.wangfeng.pro/tags/WakaTime/"}]},{"title":"ssh快捷登录并执行命令","slug":"Linux/ssh快捷登录并执行命令","date":"2019-09-30T07:36:15.000Z","updated":"2021-04-29T12:06:54.512Z","comments":true,"path":"2019/09/ssh快捷登录并执行命令.html","link":"","permalink":"https://www.wangfeng.pro/2019/09/ssh%E5%BF%AB%E6%8D%B7%E7%99%BB%E5%BD%95%E5%B9%B6%E6%89%A7%E8%A1%8C%E5%91%BD%E4%BB%A4","excerpt":"公司有很多测试服务器，经常需要登录这些服务器测试来查看服务日志。由于这些测试服务器只能通过账号+密码的方式登录，Windows下可以通过Xshell实现自动登录，但在MacOS中并没有发现比较好的工具，在终端通过SSH方式登录时每次都需要输入密码，十分麻烦，经过一番搜索，最终实现了使用expect在终端直接ssh自动登录,并在登录成功后执行指定脚本。","text":"公司有很多测试服务器，经常需要登录这些服务器测试来查看服务日志。由于这些测试服务器只能通过账号+密码的方式登录，Windows下可以通过Xshell实现自动登录，但在MacOS中并没有发现比较好的工具，在终端通过SSH方式登录时每次都需要输入密码，十分麻烦，经过一番搜索，最终实现了使用expect在终端直接ssh自动登录,并在登录成功后执行指定脚本。 安装expectMacOS:直接通过Homebrew来安装： 1brew install expect Linux系统请自行搜索 编写脚本在/usr/local/bin目录下新建脚本auth_ssh.sh和do_ssh.sh： auto_ssh.sh12345678910111213#!/bin/bashhost=$1port=$2user=$3pswd=$4cmd=$5if [ -z &quot;$cmd&quot; ];then cmd = &quot;cd ~/&quot;fido_ssh.sh $host $port $user $pswd &quot;$cmd&quot; do_ssh.sh1234567891011121314151617181920212223#!/usr/bin/expectset timeout 30set host [lindex $argv 0]set port [lindex $argv 1]set user [lindex $argv 2]set pswd [lindex $argv 3]set cmd [lindex $argv 4]spawn ssh -p $port $user@$hostexpect &#123; &quot;(yes/no)?&quot; &#123;send &quot;yes\\n&quot;;exp_continue&#125; &quot;password:&quot; &#123;send &quot;$pswd\\n&quot;&#125; &quot;Password:&quot; &#123;send &quot;$pswd\\n&quot;&#125;&#125;expect &#123; &quot;login&quot; &#123;send &quot;$cmd\\n&quot;&#125;&#125; interact 注意：第20行的login表示期待登录成功后的输出会包含字符串login，请根据实际情况做修改 之后在终端执行命令 auto_ssh &lt;host&gt; &lt;port&gt; &lt;user&gt; &lt;pswd&gt; &quot;&lt;cmd&gt;&quot;即可。 为登录命令配置别名在~/.bash_profile添加命令别名,例如: 1alias ss76=&quot;auto_ssh.sh 192.168.12.76 22 root abcd \\&quot;cd /home/tomcat/\\&quot;&quot; 然后执行 1source ~/.bash_profile 之后在终端ss76即可自动登录到192.168.12.76并切换到/home/tomcat/目录中 参考 iterm2 配合 expect 实现 SSH 自动登陆 linux expect详解(ssh自动登录，部署)","categories":[{"name":"Linux","slug":"Linux","permalink":"https://www.wangfeng.pro/categories/Linux/"}],"tags":[{"name":"ssh","slug":"ssh","permalink":"https://www.wangfeng.pro/tags/ssh/"}]},{"title":"Mac中在升级ruby版本后colorls命令报错的解决办法","slug":"其它/Mac/Mac中在升级ruby版本后colorls命令报错的解决办法","date":"2019-09-25T13:33:53.000Z","updated":"2021-04-29T12:04:57.376Z","comments":true,"path":"2019/09/mac中在升级ruby版本后colorls命令报错的解决办法.html","link":"","permalink":"https://www.wangfeng.pro/2019/09/mac%E4%B8%AD%E5%9C%A8%E5%8D%87%E7%BA%A7ruby%E7%89%88%E6%9C%AC%E5%90%8Ecolorls%E5%91%BD%E4%BB%A4%E6%8A%A5%E9%94%99%E7%9A%84%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95","excerpt":"问题为了在mac中使用tmuxinator，按照网上的教程使用rvm升级了系统的ruby版本，ruby升级完成后却发现执行colorls相关命令时，报了如下错误： 12345678910111213System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/2.3.0/rubygems/dependency.rb:319:in `to_specs&#x27;: Could not find &#x27;clocale&#x27; (&gt;= 0) among 20 total gem(s) (Gem::LoadError)Checked in &#x27;GEM_PATH=/Users/em/.gem/ruby/2.3.0:/Library/Ruby/Gems/2.3.0:/System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/gems/2.3.0&#x27;, execute `gem env` for more information from /System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/2.3.0/rubygems/specification.rb:1442:in `block in activate_dependencies&#x27; from /System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/2.3.0/rubygems/specification.rb:1431:in `each&#x27; from /System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/2.3.0/rubygems/specification.rb:1431:in `activate_dependencies&#x27; from /System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/2.3.0/rubygems/specification.rb:1413:in `activate&#x27; from /System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/2.3.0/rubygems.rb:196:in `rescue in try_activate&#x27; from /System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/2.3.0/rubygems.rb:193:in `try_activate&#x27; from /System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/2.3.0/rubygems/core_ext/kernel_require.rb:125:in `rescue in require&#x27; from /System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/2.3.0/rubygems/core_ext/kernel_require.rb:39:in `require&#x27; from /Library/Ruby/Gems/2.3.0/gems/colorls-1.1.1/exe/colorls:3:in `&lt;top (required)&gt;&#x27; from /usr/local/bin/colorls:22:in `load&#x27; from /usr/local/bin/colorls:22:in `&lt;main&gt;&#x27;","text":"问题为了在mac中使用tmuxinator，按照网上的教程使用rvm升级了系统的ruby版本，ruby升级完成后却发现执行colorls相关命令时，报了如下错误： 12345678910111213System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/2.3.0/rubygems/dependency.rb:319:in `to_specs&#x27;: Could not find &#x27;clocale&#x27; (&gt;= 0) among 20 total gem(s) (Gem::LoadError)Checked in &#x27;GEM_PATH=/Users/em/.gem/ruby/2.3.0:/Library/Ruby/Gems/2.3.0:/System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/gems/2.3.0&#x27;, execute `gem env` for more information from /System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/2.3.0/rubygems/specification.rb:1442:in `block in activate_dependencies&#x27; from /System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/2.3.0/rubygems/specification.rb:1431:in `each&#x27; from /System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/2.3.0/rubygems/specification.rb:1431:in `activate_dependencies&#x27; from /System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/2.3.0/rubygems/specification.rb:1413:in `activate&#x27; from /System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/2.3.0/rubygems.rb:196:in `rescue in try_activate&#x27; from /System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/2.3.0/rubygems.rb:193:in `try_activate&#x27; from /System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/2.3.0/rubygems/core_ext/kernel_require.rb:125:in `rescue in require&#x27; from /System/Library/Frameworks/Ruby.framework/Versions/2.3/usr/lib/ruby/2.3.0/rubygems/core_ext/kernel_require.rb:39:in `require&#x27; from /Library/Ruby/Gems/2.3.0/gems/colorls-1.1.1/exe/colorls:3:in `&lt;top (required)&gt;&#x27; from /usr/local/bin/colorls:22:in `load&#x27; from /usr/local/bin/colorls:22:in `&lt;main&gt;&#x27; 解决办法在终端执行以下命令： 12345678xcode-select --installbrew install rbenvecho &#x27;export PATH=&quot;/usr/local/opt/openssl/bin:$PATH&quot;&#x27; &gt;&gt; ~/.zshrcecho &#x27;export LDFLAGS=&quot;-L/usr/local/opt/openssl/lib&quot;&#x27; &gt;&gt; ~/.zshrcecho &#x27;export CPPFLAGS=&quot;-I/usr/local/opt/openssl/include&quot;&#x27; &gt;&gt; ~/.zshrcecho &#x27;export PKG_CONFIG_PATH=&quot;/usr/local/opt/openssl/lib/pkgconfig&quot;&#x27; &gt;&gt; ~/.zshrcsudo gem pristine --all #that produced a permissions error, but i don&#x27;t care everything workedsudo gem install colorls 如果执行xcode-select --install时提示 1xcode-select: error: command line tools are already installed, use &quot;Software Update&quot; to install updates 可以忽略。 参考 https://github.com/avdv/clocale/issues/22","categories":[{"name":"其它","slug":"其它","permalink":"https://www.wangfeng.pro/categories/%E5%85%B6%E5%AE%83/"},{"name":"Mac","slug":"其它/Mac","permalink":"https://www.wangfeng.pro/categories/%E5%85%B6%E5%AE%83/Mac/"}],"tags":[{"name":"colorls","slug":"colorls","permalink":"https://www.wangfeng.pro/tags/colorls/"},{"name":"gem","slug":"gem","permalink":"https://www.wangfeng.pro/tags/gem/"}]},{"title":"彻底搞懂字符串比较问题和String.intern()方法的作用","slug":"Java/Java基础/彻底搞懂字符串比较问题和String.intern()方法的作用","date":"2019-01-30T09:55:56.000Z","updated":"2021-05-14T13:06:17.483Z","comments":true,"path":"2019/01/彻底搞懂字符串比较问题和string-intern-方法的作用.html","link":"","permalink":"https://www.wangfeng.pro/2019/01/%E5%BD%BB%E5%BA%95%E6%90%9E%E6%87%82%E5%AD%97%E7%AC%A6%E4%B8%B2%E6%AF%94%E8%BE%83%E9%97%AE%E9%A2%98%E5%92%8Cstring-intern-%E6%96%B9%E6%B3%95%E7%9A%84%E4%BD%9C%E7%94%A8","excerpt":"网上看面试题时经常看到各种字符串比较的问题，有时看着答案也不知道为什么。于是今天花了一点时间对此做了一下深入的学习，在此记录一下。","text":"网上看面试题时经常看到各种字符串比较的问题，有时看着答案也不知道为什么。于是今天花了一点时间对此做了一下深入的学习，在此记录一下。 创建字符串时需要注意的规则这里列的规则是我结合JDK里的文档和《Java-String.intern的深入研究》、《几张图轻松理解String.intern()》这两篇文章，对于理解下面的实例中我认为比较关键的几点，可能有些理解不正确。 1、通过new String(String original)会有涉及到两个对象。例如 String str = new String(&quot;a&quot;)语句,会先将构造函数里的参数original指向在字符串常量池(简称SCP),如果常量池中不存在，则会在常量池中生成字符串a，再在堆(HEAP)中生成变量str; 2、如果一个字符串str是由多个常量字符串通过**+**拼接的，则字符串str会直接生成或指向在字符串常量池中。 情况一： 1String str = &quot;a&quot; + &quot;b&quot;; 情况二： 12String b = &quot;b&quot;;String str = &quot;a&quot; + b; 情况三： 12final String b = &quot;b&quot;;String str = &quot;a&quot; + b; 在上面的三种情况中，第一种和第三种情况的str都是由常量字符串直接拼接的，所以str会直接指向字符串常量池；而情况二中由于存在局部变量b,编译器将会通过StringBuilder.append()方法拼接字符串a和变量b后，最终再通过StringBuilder.toString()方法得到str，str会在堆中生成。 3、JDK 1.7后，在执行 String.intern()方法时，虚拟机会去字符串常量池检查是否已存在该字符串，如果存在则会直接引用常量池中该字符串的地址作为返回结果的引用地址；如果不存在，则会在常量池中生成一个对在原字符串(位于堆中)的引用作为，而不是像 JDK 1.6之前仍将原字符串拷贝到常量池中。 实例实例112345678@Testpublic void test1() &#123; String c = &quot;ab&quot;; //SCP String i = &quot;a&quot; + &quot;b&quot;; //SCP String j = i.intern(); //SCP System.out.println(i == j); System.out.println(c == j);&#125; String c = &quot;ab&quot;将直接在字符串常量池生成字符串ab；由于i是由两个字符串常量a和b直接拼接而成，所以i也会指向字符串常量池；由于i.intern()得到的字符串在常量池中已存在，所以j也指向常量池。因此c、i、j指向的同一个地址。因此输出结果为： 123truetruetrue 实例2123456789@Testpublic void test2() &#123; String c = &quot;ab&quot;; //SCP String i = new String(&quot;a&quot;) + new String(&quot;b&quot;); //HEAP String j = i.intern(); //SCP System.out.println(c == i); System.out.println(i == j); System.out.println(c == j);&#125; String i = new String(&quot;a&quot;) + new String(&quot;b&quot;);语句会在字符串常量池中生成两个字符串a和b,在堆中生成3个对象：两个是由new String()生成的，另外一个是i。结合实例1的说明，可知：c和j指向字符串常量池中指向地址，而i指向堆中。因此输出结果为： 123falsefalsetrue 实例3123456789@Testpublic void test3() &#123; String c = &quot;ab&quot;; //SCP String i = new String(&quot;ab&quot;); //HEAP String j = i.intern(); //SCP System.out.println(c == i); System.out.println(i == j); System.out.println(c == j);&#125; 和实例2中类似，String i = new String(&quot;ab&quot;);语句中构造函数里的字符串ab会直接指向由String c = &quot;ab&quot;;语句在字符串常量池中生成的字符串的地址，在堆中生成一个字符串对象i。所以输出结果和实例2一样： 123falsefalsetrue 实例412345678910@Testpublic void test4() &#123; String c = &quot;ab&quot;; //SCP String b = &quot;b&quot;; String i = &quot;a&quot; + b; //HEAP String j = i.intern(); //SCP System.out.println(c == i); System.out.println(i == j); System.out.println(c == j);&#125; 根据本文开头的第2点规则，可知String i = &quot;a&quot; + b;语句中生成的变量i是位于堆中的，而c和j都指向字符串常量池。因此输出结果为： 123falsefalsetrue 实例5123456789@Testpublic void test5() &#123; String b = &quot;b&quot;; String i = &quot;a&quot; + b; //HEAP String j = i.intern(); //SCP -&gt; HEAP String c = &quot;ab&quot;; //SCP -&gt; HEAP System.out.println(i == j); System.out.println(c == j);&#125; 与实例4中不同的是，虽然i是位于堆中，但是在执行String j = i.intern()时，由于字符串常量池中不存在字符串ab，根据本文开头的第3点规则，此时并不会直接把字符串ab复制在字符串常量池中，而是在常量池中为字符串ab生成指向堆中对象i的引用，包括之后的语句String c = &quot;ab&quot;;中c指向的也是常量池中指向堆中对象i的引用，所有c、i、j指向的实际是同一个地址。因此输出结果为： 12truetrue 实例612345678@Testpublic void test6() &#123; String i = new String(&quot;ab&quot;); //HEAP String j = i.intern(); //SCP String c = &quot;ab&quot;; //SCP System.out.println(i == j); System.out.println(c == j);&#125; 如果不仔细思考，可能会认为输出结果应该和实例5一样，但实际的输出结果却是如下： 12falsetrue 参考实例3，想清楚String i = new String(&quot;ab&quot;);是会先在字符串常量池生成字符串ab这一点后，就很容易知道和实例5的区别了。 实例7123456789@Testpublic void test7() &#123; final String b = &quot;b&quot;; String i = &quot;a&quot; + b; //SCP String j = i.intern(); //SCP String c = &quot;ab&quot;; //SCP System.out.println(i == j); System.out.println(c == j);&#125; 与实例5的区别在于对象b是用final修饰的，可以看做局部常量，字符串对象i是由两个字符串常量通过+直接拼接而成，i将指向字符串常量池。因此输出结果为： 12truetrue 实例812345678910111213private void test8(final String b) &#123; String i = &quot;a&quot; + b; //HEAP String j = i.intern(); //SCP -&gt; HEAP String c = &quot;ab&quot;; //SCP -&gt; HEAP System.out.println(i == j); System.out.println(c == j);&#125;@Testpublic void test8() &#123; String b = &quot;b&quot;; test8(b);&#125; 这个实例的结果和实例7一样： 12truetrue 但是含义不同，虽然在方法test8(final String b)中，形参b是用final修饰的，但b的值仍然是外部传来的，所以不能看做字符串常量。因此i是执行堆中的对象，而j和c是因为执行i.intern()之后，间接通过常量池指向了和i同一个地址。调换一下上述方法中语句的位置，也可以验证改实例： 12345678910111213private void test8_1(final String b) &#123; String c = &quot;ab&quot;; //SCP String i = &quot;a&quot; + b; //HEAP String j = i.intern(); //SCP System.out.println(i == j); System.out.println(c == j);&#125;@Testpublic void test8_1() &#123; String b = &quot;b&quot;; test8_1(b);&#125; 将String c = &quot;ab&quot;; 语句提至方法内第一行后，在执行i.intern()时，由于常量池中已存在字符串ab，因此j将直接指向常量池中字符串ab的地址，而i是位于堆中的对象，所以输出结果为： 12falsetrue 实例9123456789101112@Testpublic void test9() &#123; String b = &quot;b&quot;; String i = &quot;a&quot; + b; //HEAP_1 String l = &quot;a&quot; + b; //HEAP_2 String j = l.intern(); //SCP -&gt; HEAP_2 String c = &quot;ab&quot;; //SCP -&gt; HEAP_2 System.out.println(i.equals(j)); System.out.println(i == j); System.out.println(l == j); System.out.println(l == c);&#125; 结合前面的例子可知，i和j是位于堆中两个独立的对象。由于有l.intern()操作，j、c和l最终都指向了同一个地址。因此输出结果为： 1234falsetruetruetrue 参考 https://www.cnblogs.com/Kidezyq/p/8040338.html https://blog.csdn.net/soonfly/article/details/70147205 https://www.geeksforgeeks.org/interning-of-string/","categories":[{"name":"Java","slug":"Java","permalink":"https://www.wangfeng.pro/categories/Java/"},{"name":"Java基础","slug":"Java/Java基础","permalink":"https://www.wangfeng.pro/categories/Java/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.wangfeng.pro/tags/Java/"},{"name":"String","slug":"String","permalink":"https://www.wangfeng.pro/tags/String/"}]},{"title":"使用正则表达式解析Nginx默认日志","slug":"Java/其他/使用正则表达式解析Nginx默认日志","date":"2019-01-26T05:13:03.000Z","updated":"2021-05-14T13:06:17.478Z","comments":true,"path":"2019/01/使用正则表达式解析nginx默认日志.html","link":"","permalink":"https://www.wangfeng.pro/2019/01/%E4%BD%BF%E7%94%A8%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%E8%A7%A3%E6%9E%90nginx%E9%BB%98%E8%AE%A4%E6%97%A5%E5%BF%97","excerpt":"","text":"背景想通过 Nginx 的 access.log 分析网站的访问情况，但是直接通过日志文件看不太直观，于是想通过代码把日志文件解析并保存数据库中，这样分析起来更方便。 实现参考 nginx日志解析：java正则解析 这篇文章，通过使用正则表达式把日志文件中的各个参数解析出来即可。 比如，我的服务器上 Nginx 记录的日志格式如下： 1203.208.60.89 - - [04/Jan/2019:16:06:38 +0800] &quot;GET /atom.xml HTTP/1.1&quot; 200 273932 &quot;-&quot; &quot;Mozilla/5.0 (compatible; Googlebot/2.1; +http://www.google.com/bot.html)&quot; 对应的 Java 正则表达式就是： 1(?&lt;ip&gt;\\d+\\.\\d+\\.\\d+\\.\\d+)( - - \\[)(?&lt;datetime&gt;[\\s\\S]+)(?&lt;t1&gt;\\][\\s&quot;]+)(?&lt;request&gt;[A-Z]+) (?&lt;url&gt;[\\S]*) (?&lt;protocol&gt;[\\S]+)[&quot;] (?&lt;code&gt;\\d+) (?&lt;sendbytes&gt;\\d+) [&quot;](?&lt;refferer&gt;[\\S]*)[&quot;] [&quot;](?&lt;useragent&gt;[\\S\\s]+)[&quot;] 完整代码如下： LogEntity类用于保存解析后的日志信息12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import lombok.Data;import javax.persistence.*;import java.time.LocalDateTime;/** * @author &lt;a href=&quot;mailto:wf2311@163.com&quot;&gt;wf2311&lt;/a&gt; * @since 2019-01-25 19:37. */@Data@Table@Entity(name = &quot;log&quot;)public class LogEntity &#123; /** * 主键ID */ @Id @GeneratedValue(strategy = GenerationType.IDENTITY) private Integer id; /** * 客户端IP */ private String ip; /** * 访问时间 */ private LocalDateTime time; /** * 请求方式 GET/POST/PUT 等 */ private String request; /** * 访问的url地址 */ private String url; /** * http协议 */ private String protocol; /** * 请求结果响应码 */ private Integer code; /** * 请求访问的字节数量 */ private Integer sendByteSize; /** * 访问者访问渠道来源 */ private String refferer; /** * 访问者的用户代理 */ private String useAgent; /** * 访问者是不是爬虫或机器人 */ private boolean isBot; /** * 访问的是不是静态资源文件，例如：css、js、图片等文件 */ private boolean isResource; /** * 当前项目名称 */ private String project;&#125; NginxLogConverter类实现解析的具体逻辑123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596import lombok.extern.slf4j.Slf4j;import java.io.IOException;import java.nio.file.Files;import java.nio.file.Path;import java.nio.file.Paths;import java.time.LocalDateTime;import java.time.format.DateTimeFormatter;import java.util.List;import java.util.Locale;import java.util.regex.Matcher;import java.util.regex.Pattern;import java.util.stream.Collectors;/** * @author &lt;a href=&quot;mailto:wf2311@163.com&quot;&gt;wf2311&lt;/a&gt; * @since 2019-01-25 19:35. */@Slf4jpublic class NginxLogConverter &#123; private static final String PATTERN = &quot;(?&lt;ip&gt;\\\\d+\\\\.\\\\d+\\\\.\\\\d+\\\\.\\\\d+)( - - \\\\[)(?&lt;datetime&gt;[\\\\s\\\\S]+)(?&lt;t1&gt;\\\\][\\\\s\\&quot;]+)(?&lt;request&gt;[A-Z]+) (?&lt;url&gt;[\\\\S]*) (?&lt;protocol&gt;[\\\\S]+)[\\&quot;] (?&lt;code&gt;\\\\d+) (?&lt;sendbytes&gt;\\\\d+) [\\&quot;](?&lt;refferer&gt;[\\\\S]*)[\\&quot;] [\\&quot;](?&lt;useragent&gt;[\\\\S\\\\s]+)[\\&quot;]&quot;; /** * 解析转换逻辑 * * @param text 单条的日志记录 * @param project 项目名称 * @return 解析成功则返回具体的对象，解析失败返回&lt;code&gt;null&lt;/code&gt; */ public static LogEntity parse(String text, String project) &#123; Pattern r = Pattern.compile(PATTERN); Matcher m = r.matcher(text); while (m.find()) &#123; LogEntity log = new LogEntity(); log.setIp(m.group(&quot;ip&quot;)); log.setProject(project); String datetime = m.group(&quot;datetime&quot;); log.setTime(convertTime(datetime)); log.setRequest(m.group(&quot;request&quot;)); log.setUrl(m.group(&quot;url&quot;)); log.setProtocol(m.group(&quot;protocol&quot;)); log.setCode(Integer.valueOf(m.group(&quot;code&quot;))); log.setSendByteSize(Integer.valueOf(m.group(&quot;sendbytes&quot;))); log.setRefferer(m.group(&quot;refferer&quot;)); log.setUseAgent(m.group(&quot;useragent&quot;)); log.setBot(isBot(log.getUseAgent())); log.setResource(isResource(log.getUrl())); return log; &#125; log.error(String.format(&quot;%s 格式化错误&quot;, text)); return null; &#125; /** * 提取转换时间 * * @param s 格式化的时间文本：26/Jan/2019:06:51:27 +0800] * @return LocalDateTime 时间 */ private static LocalDateTime convertTime(String s) &#123; String t = s.substring(0, s.indexOf(&quot; &quot;)); return LocalDateTime.parse(t, DateTimeFormatter.ofPattern(&quot;dd/MMM/yyyy:HH:mm:ss&quot;, Locale.ENGLISH)); &#125; /** * 通过 userAgent 字段判断是不是爬虫或机器人的访问记录 * * @param userAgent 访问者的用户代理 * @return 是否是爬虫或机器人的访问记录 */ private static boolean isBot(String userAgent) &#123; String t = userAgent.toLowerCase(); return t.contains(&quot;bot&quot;) || t.contains(&quot;spider&quot;); &#125; /** * 通过 url 字段判断访问的是不是静态资源文件 * * @param url 访问的url路径 * @return 访问的是否是静态资源文件 */ private static boolean isResource(String url) &#123; String t = url.toLowerCase(); return t.contains(&quot;.js&quot;) || t.contains(&quot;.css&quot;) || t.contains(&quot;.png&quot;) || t.contains(&quot;.ico&quot;) || t.contains(&quot;.gif&quot;) || t.contains(&quot;.txt&quot;) || t.contains(&quot;.woff&quot;) || t.contains(&quot;.eot&quot;) || t.contains(&quot;.jpg&quot;); &#125;&#125; 使用方式12345678910public static void main(String[] args) &#123; Path path = Paths.get(&quot;/xx/xxx/access.log&quot;); try &#123; List&lt;String&gt; logs = Files.readAllLines(path); List&lt;LogEntity&gt; list = logs.stream().map(s -&gt; parse(s, &quot;$&#123;projectName&#125;&quot;)).collect(Collectors.toList()); System.out.println(list.size()); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; 参考 nginx日志解析：java正则解析","categories":[{"name":"Java","slug":"Java","permalink":"https://www.wangfeng.pro/categories/Java/"},{"name":"其他","slug":"Java/其他","permalink":"https://www.wangfeng.pro/categories/Java/%E5%85%B6%E4%BB%96/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.wangfeng.pro/tags/Java/"},{"name":"笔记","slug":"笔记","permalink":"https://www.wangfeng.pro/tags/%E7%AC%94%E8%AE%B0/"},{"name":"Nginx","slug":"Nginx","permalink":"https://www.wangfeng.pro/tags/Nginx/"},{"name":"正则表达式","slug":"正则表达式","permalink":"https://www.wangfeng.pro/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"}]},{"title":"Java虚拟机结构(二):内存结构概述","slug":"Java/JVM/从零学习JVM/Java虚拟机结构(二):内存结构概述","date":"2019-01-23T09:22:29.000Z","updated":"2019-01-23T10:15:22.487Z","comments":true,"path":"2019/01/java虚拟机结构-二-内存结构概述.html","link":"","permalink":"https://www.wangfeng.pro/2019/01/java%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%BB%93%E6%9E%84-%E4%BA%8C-%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84%E6%A6%82%E8%BF%B0","excerpt":"","text":"运行时数据区Java 虚拟机在会将它所管理的内存划分成若干个不同的区域，作用各不相同。 线程私有区PC寄存器PC 寄存器是一块较小的内存区域，属于线程私有。PC 寄存器用于保存当前线程中正在执行的字节码指令的地址：对于非原生方法，指向的是字节码指令的地址;对于原生方法，保存的是 undefined。 Java虚拟机栈Java 虚拟机栈也是属于线程私有，随线程同时创建，用于存储栈帧(Frame)。其内存既可以设置成固定大小，也可以根据计算动态扩展和收缩；使用的内存不需要保证是连续的。 Java 虚拟机栈可能会抛出以下异常： StackOverflowError:线程请求分配的栈容量超过栈允许的最大值; OutOfMemoryError: 栈尝试扩展但无法申请到足够的内存或者创建新的线程时没有足够的内存； 本地方法栈本地方法栈与 Java 虚拟机栈的作用类似，主要用于支持 native 。如果虚拟机支持本地方法栈，在线程创建时按线程分配。 同 Java 虚拟机栈一样，本地方法栈有可能会抛出下异常： StackOverflowError:线程请求分配的栈容量超过栈允许的最大值; OutOfMemoryError: 栈尝试扩展但无法申请到足够的内存或者创建新的线程时没有足够的内存； HotSpot 虚拟机直接把本地方法栈和 Java 虚拟机栈合二为一。 栈帧栈帧是用来存储数据和部分过程结果的数据结构，同时也用来处理动态链接、方法返回和异常分发。栈帧在线程内随着方法调用而创建、方法结束(包含抛出异常)而销毁。其存储空间由创建它的线程在虚拟机栈中分配。 每个栈帧都有自己的本地变量表、操作数栈和指向当前方法所属类的运行时常量池的引用，本地变量表和操作数栈的容量在编译期确定。 本地变量表本地变量表用于保存局部变量，位于栈帧中，长度由编译期决定。 在本地变量表中保存 boolean、byte、char、short、int、float、reference或returnAddress 类型的数据需一个局部变量；保存 long、double 类型的数据需两个连续的局部变量。在本地变量表中的变量使用索引来定位访问，第一个变量的索引为0；在实例方法中，本地变量表中索引为0的位置存储的是该实例方法所在对象的引用(this)。 操作数栈操作数栈是一个后进先出的栈，位于栈帧中，最大深度由编译期决定。 在任意时刻，操作数栈都有一个确定的深度，long、double类型会占用两个单位的深度，其他数据类型只占一个单位的深度。 动态链接动态链接可以理解为栈帧内部指向当前方法所在类型的运行时常量池的引用。 线程共享区Java堆Java 堆是供所有类实例和数组对象分配内存的共享区域。它在虚拟机启动时被创建，存储被自动内存管理系统(垃圾收集器)所管理的各种对象。Java 堆的容量既可以设置成固定大小，也可以根据计算动态扩展和收缩；使用的内存不需要保证是连续的。 当实际所需的堆超出了自动内存管理系统能提供的最大值，会抛出OutOfMemoryError异常。 方法区方法区存储了每一个类的结构信息：运行时常量池、字段和方法数据、构造函数和普通方法的字节码内容；还包含一些在类、实例、接口初始化时用到的特殊方法。方法区是堆的逻辑组成部分，但虚拟机可以在这个区域不实现垃圾回收和压缩。方法区的容量既可以设置成固定大小，也可以根据计算动态扩展和收缩；使用的内存不需要保证是连续的。 当方法区的内存不能满足内存分配请求，会抛出OutOfMemoryError异常。 运行时常量池运行时常量池是class文件中每一个类或接口的常量池表的运行时表现形式。在方法区中分配，在加载类或接口到虚拟机后会被创建。 当创建接口或类构造运行时常量池所需的内存超过了方法区所能提供的最大值时，会抛出OutOfMemoryError异常。 直接内存直接内存并不是虚拟机运行时数据区的一部分，也不是 Java 虚拟机规范字定义的内存区域。在 JDK 1.4中新加入的 NIO 引入了一种基于通道(Channel)与缓冲区(Buffer)的 I/O 方式，它可以使用 Native 函数库直接分配堆外内存，然后通过一个存储在 Java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在 Java 堆 和 Native 堆中来回复制数据。 当动态扩展直接内存的大小导致各个内存区域总和大于本机的物理内存限制时，会抛出OutOfMemoryError异常。 思维导图","categories":[{"name":"Java","slug":"Java","permalink":"https://www.wangfeng.pro/categories/Java/"},{"name":"JVM","slug":"Java/JVM","permalink":"https://www.wangfeng.pro/categories/Java/JVM/"},{"name":"从零学习JVM","slug":"Java/JVM/从零学习JVM","permalink":"https://www.wangfeng.pro/categories/Java/JVM/%E4%BB%8E%E9%9B%B6%E5%AD%A6%E4%B9%A0JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://www.wangfeng.pro/tags/JVM/"},{"name":"Java","slug":"Java","permalink":"https://www.wangfeng.pro/tags/Java/"}]},{"title":"Java虚拟机结构(一):数据类型","slug":"Java/JVM/从零学习JVM/Java虚拟机结构(一):数据类型","date":"2019-01-17T06:35:58.000Z","updated":"2019-01-23T10:15:22.495Z","comments":true,"path":"2019/01/java虚拟机结构-一-数据类型.html","link":"","permalink":"https://www.wangfeng.pro/2019/01/java%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%BB%93%E6%9E%84-%E4%B8%80-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B","excerpt":"本文的内容实际上是对《Java虚拟机规范(Java SE 8版)》第2.2章节的一个笔记概述。 在学习 JVM 之前，我们首先对虚拟机中的数据类型做一个基本的认识。与 Java 程序语言中的数据结构类似，Java 虚拟机可以操作的数据类型可分为两类：原始类型和引用类型，与之对应也存在原始值和引用值两种类型的数值，他们可以用于变量赋值、参数传递、方法返回和运算操作。","text":"本文的内容实际上是对《Java虚拟机规范(Java SE 8版)》第2.2章节的一个笔记概述。 在学习 JVM 之前，我们首先对虚拟机中的数据类型做一个基本的认识。与 Java 程序语言中的数据结构类似，Java 虚拟机可以操作的数据类型可分为两类：原始类型和引用类型，与之对应也存在原始值和引用值两种类型的数值，他们可以用于变量赋值、参数传递、方法返回和运算操作。 原始类型Java 虚拟机所支持的原始数据类型包括数值类型、boolean 类型和 returnAddress 类型三类。 数值类型数值类型又分为整数类型和浮点数类型，具体如下表所示： 数值类型位数默认值取值范围整数类型byte8位有符号0[-2^7,2^7-1]short16位有符号0[-2^15,2^15-1]int32位有符号0[-2^31,2^31-1]long64位有符号0[-2^63,2^63-1]char16位无符号\\u0000[0,2^16-1]浮点数类型float32位单精度浮点数正数0-double64位双精度浮点数正数0- boolean类型Java 虚拟机没有提供 boolean 值专用的字节码指令，Java 语言表达式所操作的 boolean 值，在编译后都使用虚拟机中的 int 数据类型代替。另外，boolean 类型数组在虚拟机中会被编码成 byte 类型数值，每个 boolean 元素占8位。 returnAddress类型returnAddress 类型的值指向一条虚拟机指令的操作码。与数值类型相比，returnAddress 类型在 Java 语言中并不存在对应的类型，而且也无法再程序运行期间更改。 引用类型Java 虚拟机中有三种引用类型：类类型、数组类型、接口类型。这些引用类型的值分别指向动态创建的类实例、数组实例和实现了某个接口的类实例或数组实例。 除三种引用类型外，在引用类型的值中还有一个特殊的值—— null,它是所有引用类型的默认值。 数组类型一个多维数组类型可以看做是由两维的数据构成：在外维的称为组件类型，在里维的称为元素类型。 组件类型也可以是数组类型，例如 int[][][]的组件类型可以看做是int[][]；而元素类型必须是原生类型、类类型或接口类型之一。 参考 《Java虚拟机规范(Java SE 8版)》 第2.2章节","categories":[{"name":"Java","slug":"Java","permalink":"https://www.wangfeng.pro/categories/Java/"},{"name":"JVM","slug":"Java/JVM","permalink":"https://www.wangfeng.pro/categories/Java/JVM/"},{"name":"从零学习JVM","slug":"Java/JVM/从零学习JVM","permalink":"https://www.wangfeng.pro/categories/Java/JVM/%E4%BB%8E%E9%9B%B6%E5%AD%A6%E4%B9%A0JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://www.wangfeng.pro/tags/JVM/"},{"name":"Java","slug":"Java","permalink":"https://www.wangfeng.pro/tags/Java/"}]},{"title":"如何优雅地在Hexo博客中嵌入SVG文件","slug":"前端/如何优雅地在Hexo博客中嵌入SVG文件","date":"2019-01-16T12:43:39.000Z","updated":"2021-04-29T12:04:57.401Z","comments":true,"path":"2019/01/如何优雅地在hexo博客中嵌入svg文件.html","link":"","permalink":"https://www.wangfeng.pro/2019/01/%E5%A6%82%E4%BD%95%E4%BC%98%E9%9B%85%E5%9C%B0%E5%9C%A8hexo%E5%8D%9A%E5%AE%A2%E4%B8%AD%E5%B5%8C%E5%85%A5svg%E6%96%87%E4%BB%B6","excerpt":"今天遇到一个问题：想在自己的Hexo博客中展示SVG格式的思维导图，本文简单的记录一下如何解决这个问题。","text":"今天遇到一个问题：想在自己的Hexo博客中展示SVG格式的思维导图，本文简单的记录一下如何解决这个问题。 在Markdown文件中嵌入SVG我们知道在 MarkDown 文件中可以直接使用 HTML 元素，所以可以直接使用写 HTML 结构的形式应该就可以实现，下面说说我尝试过的三种方案： iframe最开始想到的是用 iframe 的形式，在正文中加入如下代码： 1&lt;iframe width=&quot;100%&quot; height=&quot;auto&quot; src=&quot;xxx.svg&quot;&gt;&lt;/iframe&gt; 结果如下：效果显然不行，放弃此种方案。 img接着尝试了使用 img 元素的方法，代码如下： 展示结果如下： 这种方法的展示效果虽然比使用 iframe 要好，但是 svg 的内容还是收到了父元素宽度的限制，并且里面的文本无法被复制。此方案也不太理想。 object最终在网上搜到了这篇文章 The Best Way to Embed SVG on HTML (2019) ,里面介绍了多种在 HTML 页面中嵌入 SVG 的方式，我尝试了里面说到的第二种，可以达到按照原始大小显示 SVG 中内容的效果。代码如下： 1&lt;object type=&quot;image/svg+xml&quot; data=&quot;xxx.svg&quot;&gt;&lt;/object&gt; 页面效果： 可以看出 SVG 中的内容虽然是按照原始比例显示的，但是可能会超出父元素的宽度。接下来就要解决第二个问题：在子元素宽度超出父元素后，如何让子元素在父元素内滑动，而不是溢出父元素。 子元素比父元素宽的布局显示问题由于不是专业前端，此问题描述清楚后，通过搜索引擎就可以很轻松的找到答案，在此只是记录一下：对上一节中的 object节点 外面定义一个父元素，样式如下： 12345.post-svg-container&#123; display: flex; overflow-x: auto; overflow-y: hidden;&#125; 对object节点定义如下样式： 1234.post-svg-container &gt; object&#123; justify-content: center; height:100%;&#125; 在 MarkDown 中这样引入 SVG 文件： 123&lt;div class=&quot;post-svg-container&quot;&gt; &lt;object type=&quot;image/svg+xml&quot; data=&quot;xxx.svg&quot;&gt;&lt;/object&gt;&lt;/div&gt; 即可达到最终想要的效果: 参考 https://vecta.io/blog/best-way-to-embed-svg","categories":[{"name":"前端","slug":"前端","permalink":"https://www.wangfeng.pro/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://www.wangfeng.pro/tags/%E7%AC%94%E8%AE%B0/"},{"name":"Hexo","slug":"Hexo","permalink":"https://www.wangfeng.pro/tags/Hexo/"},{"name":"SVG","slug":"SVG","permalink":"https://www.wangfeng.pro/tags/SVG/"}]},{"title":"WakaTime数据同步展示工具","slug":"其它/Wakatime/WakaTime数据同步展示工具","date":"2019-01-15T15:07:18.000Z","updated":"2019-01-18T06:55:36.799Z","comments":true,"path":"2019/01/wakatime数据同步展示工具.html","link":"","permalink":"https://www.wangfeng.pro/2019/01/wakatime%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E5%B1%95%E7%A4%BA%E5%B7%A5%E5%85%B7","excerpt":"从16年知道 WakaTime 后就开始使用它来记录自己的编码时间，但作为免费版只能查看最近两周的数据，于是很久之前就写了一个程序同步自己的历史数据，不过一直没找到合适的图表插件像官网那样展示数据信息。前些日子咨询了一下同事，得知了用 antv 可以绘制对应的图表数据，刚好现在也处于失业阶段，就花了几天时间又重新做了一个项目用于同步和展示 WakaTime 数据。","text":"从16年知道 WakaTime 后就开始使用它来记录自己的编码时间，但作为免费版只能查看最近两周的数据，于是很久之前就写了一个程序同步自己的历史数据，不过一直没找到合适的图表插件像官网那样展示数据信息。前些日子咨询了一下同事，得知了用 antv 可以绘制对应的图表数据，刚好现在也处于失业阶段，就花了几天时间又重新做了一个项目用于同步和展示 WakaTime 数据。 WakaTimeWakaTime简介WakaTime 是一款可以记录你的编码时间的工具，目前支持绝大部分主流的 IDE 以及 Chrome 浏览器。 使用步骤 注册 WakaTime 账号； 在官网找到对应的 IDE 插件，按照步骤安装 WakaTime 插件(下图中灰色表示目前官方还不支持): 在个人设置页面复制 Secret API Key ，填入对应的 WakaTime 插件中； 过一段时间后，你就可以在 WakaTime 网站上看到你的编码情况，如下图所示： wakatime-sync项目项目简介 WakaTime 提供了丰富多样的图表可以多维度地查看自己的编码时间情况。不过作为免费用户，最多只能查看自己最近14天的数据；如果要查看全部的数据，需要 $9/月的订阅费用。 还好 WakaTime 提供了 API 接口，通过接口可以获取到编码时间统计情况的原始数据(作为免费用户还是有只能查看最近14天数据的限制)。 本项目通过 WakaTime 提供的 API 接口，可以把自己的 WakaTime 数据保存在的数据库中，然后利用图表插件展示出来，目前已完成三种类型的图表展示： 每日项目持续时间图： 时间范围内活动情况： 每日编码耗时日历图： 项目地址 GITHUB: https://github.com/wf2311/wakatime-sync 码云: https://gitee.com/wf2311/wakatime-sync 所用技术后端：JDK1.8、SpringBoot、Jodd-HTTP、Thymeleaf; 数据库：MySQL 5.7; 前端：Moment.js、ElementUI、AntV-G2 、Echarts; 通知服务：Server酱、钉钉机器人 项目逻辑比较简单，就是每天会定时通过 WakaTime 的 API 抓取并保存前一天的数据，再通过图标插件展示出来。之后还会完善接口缓存、同步通知等功能； 同时使用了 AntV-G2 和 Echarts 的原因是因为持续时间图可以用 AntV-G2 实现，但日历图用 AntV-G2 实现过于复杂，就采用了用 Echarts 实现日历图； 另外本项目最初是的数据库是 MongoDB ，但是考虑到通用性和易用性后来又换成了 MySQL。MongoDB 版本的代码也实现了相关的同步展示逻辑，代码在 mongodb 分支中。 使用方法替换或设置好src/main/resources/application.yml配置文件中的wakatime.app.key和spring.datasource.* 相关数据库配置，采用 maven 打包的方式安装即可，支持 Docker 方式安装。 数据库建库脚本位于sql/wakatime_sync.sql中。 数据库使用 MongoDB 的版本位于分支 mongdb 中。 示例地址：https://wakatime.wangfeng.pro/。 消息通知系统中有一个定时任务，会在每天早上09:00会根据配置信息想钉钉或微信发送上一天的编码时间信息；需要在application.yml配置对应的参数: Server酱微信通知：按照Server酱网站说明获得一个SCKEY，设置成wakatime.ftqq-key的值； 钉钉机器人通知：在要获得提醒的钉钉群里面生成一个自定义机器人，将机器人的 Hook 地址中的 access_token 的值设置成wakatime.dingding-key的值； 如果不想使用对应的消息通知，请将application.yml中对应的参数注释掉或将值置为空 可能会遇到的问题 由于本项目采用的是SpringBoot 2，对应的 mysql-connector-java 驱动使用的是MySQL服务端的时区，如果你使用的MySQL的时区和你程序中的时区以及你在 WakaTime 个人设置中的时区不一致，就会导致保存的相关数据中时间不准，解决办法就是首先调整好 WakaTime 个人设置里的时区，再调整 MySQL 数据库的时区，或者是使用 5.X版本的mysql-connector-java驱动。 如果你一直在使用 WakaTime ，如果想使用本项目同步你所有的历史数据，可以在官网上试用团队版的方式获得1个月(还是半个月？)的付费版功能或者是订阅一个月的付费版，然后通过本项目来同步所有的历史数据：POST /api/v1/sync 或参见项目中的测试方法。使用测试方法进行时不能同时使用太多的线程去同时调用 API 接口，会被限流。 TODO 查询接口缓存； 可以对项目名称设置别名展示； 结语如果本项目对你有用的话，欢迎在 GITHUB 或码云上 star，也欢迎对项目提出修改意见和建议。","categories":[{"name":"其它","slug":"其它","permalink":"https://www.wangfeng.pro/categories/%E5%85%B6%E5%AE%83/"}],"tags":[{"name":"WakaTime","slug":"WakaTime","permalink":"https://www.wangfeng.pro/tags/WakaTime/"},{"name":"工具","slug":"工具","permalink":"https://www.wangfeng.pro/tags/%E5%B7%A5%E5%85%B7/"}]},{"title":"Mac使用tree生成目录结构","slug":"其它/Mac/Mac使用tree生成目录结构","date":"2019-01-02T04:14:02.000Z","updated":"2021-04-29T12:04:57.366Z","comments":true,"path":"2019/01/mac使用tree生成目录结构.html","link":"","permalink":"https://www.wangfeng.pro/2019/01/mac%E4%BD%BF%E7%94%A8tree%E7%94%9F%E6%88%90%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84","excerpt":"","text":"前言程序员经常会有需求，需要列出项目的结构树。Mac或者Linux下可以使用tree列出项目结构，如下图这种： 123456789101112131415├── build├── config├── docs│ └── static│ ├── css│ └── js├── src│ ├── assets│ ├── components│ ├── store│ │ └── modules│ └── views│ ├── book│ └── movie└── static 使用起来也非常简单。Mac下可以使用brew install tree进行安装。安装后，在terminal中输入tree -a便可以查看某个文件夹下的所有文件。 常用的命令当然了，我们的需求肯定不止列出所有文件这么简单。下面介绍几个常用的命令： tree -d 只显示文件夹； tree -L n 显示项目的层级。n表示层级数。比如想要显示项目三层结构，可以用tree -l 3； tree -I pattern 用于过滤不想要显示的文件或者文件夹。比如你想要过滤项目中的node_modules文件夹，可以使用tree -I &quot;node_modules&quot;； tree &gt; tree.md 将项目结构输出到tree.md这个文件。 举个例子，如果我们要显示某个项目下3层的所有文件结构，同时又过滤node_modules文件夹，最后输出到tree.md，可以这么写 1tree -L 3 -I &quot;node_modules&quot; 结果为： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950.├── README.md├── build│ ├── build.js│ ├── check-versions.js│ ├── dev-client.js│ ├── dev-server.js│ ├── utils.js│ ├── webpack.base.conf.js│ ├── webpack.dev.conf.js│ └── webpack.prod.conf.js├── config│ ├── dev.env.js│ ├── index.js│ └── prod.env.js├── docs│ ├── index.html│ └── static│ ├── css│ └── js├── git.sh├── index.html├── npm-debug.log├── open├── package.json├── src│ ├── App.vue│ ├── assets│ │ ├── list.scss│ │ ├── logo.png│ │ ├── search-btn.png│ │ └── style.scss│ ├── components│ │ ├── Hello.vue│ │ ├── Spinner.vue│ │ └── header.vue│ ├── main.js│ ├── router.js│ ├── store│ │ ├── api.js│ │ ├── modules│ │ ├── store.js│ │ └── types.js│ └── views│ ├── book│ ├── index.vue│ ├── movie│ └── vuex-demo.vue├── static└── tree.md 更多命令的使用可以查看tree --help。","categories":[{"name":"Mac","slug":"Mac","permalink":"https://www.wangfeng.pro/categories/Mac/"},{"name":"其它","slug":"Mac/其它","permalink":"https://www.wangfeng.pro/categories/Mac/%E5%85%B6%E5%AE%83/"}],"tags":[{"name":"命令","slug":"命令","permalink":"https://www.wangfeng.pro/tags/%E5%91%BD%E4%BB%A4/"},{"name":"转载","slug":"转载","permalink":"https://www.wangfeng.pro/tags/%E8%BD%AC%E8%BD%BD/"},{"name":"MAC","slug":"MAC","permalink":"https://www.wangfeng.pro/tags/MAC/"}]},{"title":"Java操作码助记符","slug":"Java/JVM/Java操作码助记符","date":"2018-11-23T10:39:11.000Z","updated":"2019-01-17T06:53:38.587Z","comments":true,"path":"2018/11/java操作码助记符.html","link":"","permalink":"https://www.wangfeng.pro/2018/11/java%E6%93%8D%E4%BD%9C%E7%A0%81%E5%8A%A9%E8%AE%B0%E7%AC%A6","excerpt":"","text":"本表内容来自《Java虚拟机规范（Java SE 8 版）》第7章 操作码助记码指令含义常量00x00nop什么都不做10x01aconst_null将null推送至栈顶20x02iconst_ml将int类型-1推送至栈顶30x03iconst_0将int类型0推送至栈顶40x04iconst_1将int类型1推送至栈顶50x05iconst_2将int类型2推送至栈顶60x06iconst_3将int类型3推送至栈顶70x07iconst_4将int类型4推送至栈顶80x08iconst_5将int类型5推送至栈顶90x09lconst_0将long类型0推送至栈顶100x0alconst_1将long类型1推送至栈顶110x0bfconst_0将float类型0推送至栈顶120x0cfconst_1将float类型1推送至栈顶130x0dfconst_2将float类型2推送至栈顶140x0edconst_0将double类型0推送至栈顶150x0fdconst_1将double类型1推送至栈顶160x10bipush将单字节的常量值(-128~127)推送至栈顶170x11sipush将一个短整类型常量值(-32768~32767) 推送至栈顶180x12ldc将int、float或String类型常量值从常量池中推送至栈顶190x13ldc_w将int、float 或String类型常量值从常量池中推送至栈顶(宽索引)&nbsp;200x14ldc2_w将long或double类型常量值从常量池中推送至栈顶(宽索引)加载210x15iload将指定的int类型本地变量推送至栈顶220x16lload将指定的long类型本地变量推送至栈顶230x17fload将指定的float类型本地变量推送至栈顶240x18dload将指定的double类型本地变量推送至栈顶250x19aload将指定的引用类型本地变量推送至栈顶260xlaiload_0将第1个int类型本地变量推送至栈顶270x1biload_1将第2个int类型本地变量推送至栈顶280x1ciload_2将第3个int类型本地变量推送至栈顶290xldiload_3将第4个int类型本地变量推送至栈顶300xlelload_0将第1个long类型本地变量推送至栈顶310x1flload_1将第2个long类型本地变量推送至栈顶320x20lload_2将第3个long类型本地变量推送至栈顶330x21lload_3将第4个long类型本地变量推送至栈顶340x22fload_0将第1个float类型本地变量推送至栈顶350x23fload_1将第2个float类型本地变量推送至栈顶360x24fload_2将第3个float类型本地变量推送至栈顶370x25fload_3将第4个float类型本地变量推送至栈顶380x26dload_0将第1个double类型本地变量推送至栈顶390x27dload_1将第2个double类型本地变量推送至栈顶400x28dload_2将第3个double类型本地变量推送至栈顶410x29dload_3将第4个double类型本地变量推送至栈顶420x2aaload_0将第1个引用类型本地变量推送至栈顶430x2baload_1将第2个引用类型本地变量推送至栈项440x2caload_2将第3个引用类型本地变量推送至栈顶450x2daload_3将第4个引用类型本地变量推送至栈顶460x2eiaload将int类型数组的指定元素推送至栈顶470x2flaload将long类型数组的指定元素推送至栈顶480x30faload将float类型数组的指定元素推送至栈顶490x31daload将double类型数组的指定元素推送至栈顶500x32aaload将引用类型数组的指定元素推送至栈顶510x33baload将boolean或byte类型数组的指定元素推送至栈顶520x34caload将char类型数组的指定元素推送至栈顶530x35saload将short类型数组的指定元素推送至栈顶存储540x36istore将栈顶int类型数值存入指定本地变量550x37lstore将栈顶long类型数值存人指定本地变量560x38fstore将栈顶float类型数值存人指定本地变量570x39dstore将栈顶double类型数值存人指定本地变量580x3aastore将栈顶引用类型数值存人指定本地变量590x3bistore_0将栈顶int类型数值存人第1个本地变量600x3cistore_1将栈顶int类型数值存入第2个本地变量610x3distore_2将栈顶int类型数值存人第3个本地变量620x3eistore_3将栈顶int类型数值存人第4个本地变量630x3flstore_0将栈顶long类型数值存人第1个本地变量640x40lstore_1将栈顶long类型数值存人第2个本地变量650x41lstore_2将栈顶long类型数值存人第3个本地变量660x42lstore_3将栈顶long类型数值存人第4个本地变量670x43fstore_0将栈顶float类型数值存人第1个本地变量680x44fstore_1将栈顶float类型数值存人第2个本地变量690x45fstore_2将栈顶float类型数值存人第3个本地变量700x46fstore_3将栈顶float类型数值存人第4个本地变量710x47dstore_0将栈顶double类型数值存人第1个本地变量720x48dstore_1将栈顶double类型数值存人第2个本地变量730x49dstore_2将栈顶double类型数值存人第3个本地变量740x4adstore_3将栈顶double类型数值存人第4个本地变量750x4bastore_0将栈顶引用类型数值存入第1个本地变量760x4castore_1将栈顶引用类型数值存人第2个本地变量770x4dastore_2将栈顶引用类型数值存入第3个本地变量780x4eastore_3将栈顶引用类型数值存入第4个本地变量790x4fiastore将栈顶int类型数值存人指定数组的指定索引位置800x50lastore将栈顶long类型数值存人指定数组的指定索引位置810x51fastore将栈顶float类型数值存人指定数组的指定索引位置820x52dastore将栈顶double类型数值存人指定数组的指定索引位置830x53uastore将栈顶引用类型数值存人指定数组的指定索引位置840x54bastore将栈顶boolean或byte类型数值存人指定数组的指定索引位置850x55castore将栈顶char类型数值存人指定数组的指定索引位置860x56sastore将栈顶short类型数值存人指定数组的指定索引位置栈870x57pop将栈顶数值弹出( 数值不能是long或double类型的)880x58pop2将栈顶的一个long或double类型的数值或两个其他类型的数值弹出890x59dup复制栈顶数值并将复制值压人栈顶900x5adup_x1复制栈顶值并将其插人栈顶那两个值的下面910x5bdup_x2复制栈顶值并将其插人栈顶那两个或三个值的下面920x5cdup2复制栈顶的一个long或double类型的值，或两个其他类型的值，并将其压人栈顶930x5ddup2_x1复制栈顶的一个或两个值，并将其插人栈顶那两个或三个值的下面940x5edup2_x2复制栈顶的一个或两个值，并将其插人栈顶那两个、三个或四个值的下面950x5fswap将栈顶的两个数值互换(数值不能是long或double类型的)数学960x60iadd将栈顶两int类型数值相加并将结果压人栈顶970x61ladd将栈顶两long类型数值相加并将结果压人栈顶980x62fadd将栈顶两float类型数值相加并将结果压人栈顶990x63dadd将栈顶两double类型数值相加并将结果压人栈顶1000x64isub将栈顶两int类型数值相减并将结果压人栈顶1010x65lsub将栈顶两long类型数值相减并将结果压人栈顶1020x66fsub将栈顶两float类型数值相减并将结果压人栈顶1030x67dsub将栈顶两double类型数值相减并将结果压人栈顶1040x68imul将栈顶两int类型数值相乘并将结果压人栈顶1050x69lmul将栈顶两long类型数值相乘并将结果压人栈顶1060x6afmul将栈顶两float类型数值相乘并将结果压人栈顶1070x6bdmul将栈顶两double类型数值相乘并将结果压人栈顶1080x6cidiv将栈顶两int类型数值相除并将结果压人栈顶1090x6dldiv将栈顶两long类型数值相除并将结果压人栈顶1100x6efdiv将栈顶两float类型数值相除并将结果压人栈顶1110x6fddiv将栈顶两double类型数值相除并将结果压人栈顶1120x70irem将栈顶两int类型数值作取模运算并将结果压人栈顶1130x71lrem将栈顶两long类型数值作取模运算并将结果压人栈顶1140x72frem将栈顶两float类型数值作取模运算并将结果压人栈顶1150x73drem将栈顶两double类型数值作取模运算并将结果压人栈顶1160x74ineg将栈顶int类型数值取负并将结果压入栈项1170x75lneg将栈顶long类型数值取负并将结果压人栈顶1180x76fineg将栈顶float类型数值取负并将结果压人栈顶1190x77dneg将栈顶double类型数值取负并将结果压人栈顶1200x78ishl将int类型数值左移位指定位数并将结果压人栈项1210x79lshl将long类型数值左移位指定位数并将结果压人栈顶1220x7aishr将int类型数值(有符号)右移位指定位数并将结果压入栈顶1230x7blshr将long类型数值(有符号)右移位指定位数并将结果压入栈顶1240x7ciushr将int类型数值(无符号)右移位指定位数并将结果压入栈顶1250x7dlushr将long类型数值(无符号)右移位指定位数并将结果压入栈顶1260x7eiand将栈顶两int类型数值作“按位与”并将结果压人栈顶1270x7fland将栈顶两long类型数值作“按位与” 并将结果压人栈顶1280x80ior将栈顶两int类型数值作“按位或”并将结果压人栈项1290x81lor将栈顶两long类型数值作“按位或”并将结果压人栈顶1300x82ixor将栈顶两int类型数值作“按位异或”并将结果压人栈顶转换1310x83lxor将栈顶两long类型数值作“按位异或”并将结果压人栈顶1320x84iinc将指定int类型变量增加指定值(i++，i--, i+=2)1330x85i2l将栈顶int类型数值强制转换成long类型数值并将结果压入栈顶1340x86i2f将栈顶int类型数值强制转换成float类型数值并将结果压入栈顶1350x87i2d将栈顶int类型数值强制转换成double类型数值并将结果压入栈顶1360x88l2i将栈顶long类型数值强制转换成int类型数值并将结果压入栈顶1370x89l2f将栈顶long类型数值强制转换成float类型数值并将结果压入栈顶1380x8al2d将栈顶long类型数值强制转换成double类型数值并果压入栈顶1390x8bf2i将栈顶float类型数值强制转换成int类型数值并将结果压入栈顶1400x8cf2l将栈顶float类型数值强制转换成long类型数值并将结果压入栈顶1410x8df2d将栈顶float类型数值强制转换成double类型数值并果压入栈顶1420x8ed2i将栈顶double类型数值强制转换成int类型数值并将果压入栈顶1430x8fd2l将栈顶double类型数值强制转换成long类型数值并果压入栈顶1440x90d2f将栈顶double类型数值强制转换成float类型数值并果压入栈顶1450x91i2b将栈顶int类型数值强制转换成byte类型数值并将结果压入栈顶比较1460x92i2c将栈顶int类型数值强制转换成char类型数值并将结果压入栈顶1470x93i2s将栈顶int类型数值强制转换成short类型数值并将结果压入栈顶1480x94lcmp比较栈顶两long类型数值大小，并将结果( 1, 0, -1)压入栈顶1490x95fcmpl比较栈顶两float类型数值大小，并将结果(1, 0, -1)压入栈顶;当其中-一个数值为“NaN&quot;时，将-1压入栈顶1500x96fcmpg比较栈顶两float类型数值大小，并将结果(1，0, -1)压入栈顶;当其中-一个数值为“NaN&quot;时，将1压入栈顶1510x97dcmpl比较栈顶两double类型数值大小，并将结果(1,0,-1)压入栈顶;当其中-一个数值为“NaN&quot;时，将-1压入栈顶1520x98dcmpg比较栈顶两double类型数值大小，并将结果(1.0,-1)压入栈顶;当其中一个数值为“NaN&quot; 时，将1压入栈顶1530x99ifeq当栈顶int类型数值等于0时跳转1540x9aifne当栈顶int类型数值不等于0时跳转1550x9bjft当栈顶int类型数值小于0时跳转1560x9cifge当栈顶int类型数值大于等于0时跳转1570x9difgt当栈顶int类型数值大于0时跳转1580x9eifle当栈顶int类型数值小于等于0时跳转1590x9fif_icmpeq比较栈顶两int类型数值大小，当前者等于后者时跳转1600xa0f_icmpne比较栈顶两int类型数值大小，当前者不等于后者时跳转1610xa1if_icmplt比较栈顶两int类型数值大小，当前者小于后者时跳转1620xa2if_icmpge比较栈顶两int类型数值大小，当前者大于等于后者时跳转1630xa3if_icmpgt比较栈顶两int类型数值大小，当前者大于后者时跳转1640xa4if_icmple比较栈顶两int类型数值大小，当前者小于等于后者时跳转控制1650xa5if_acmpeq比较栈顶两引用类型数值，当结果相等时跳转1660xa6if_acmpne比较栈顶两引用类型数值，当结果不相等时跳转1670xa 7goto无条件跳转1680xa8jsr跳转至指定16位offset位置，并将jsr下一条指令地址压入栈顶1690xa9ret返回至由指定的局部变量所给出的指令位置(一般与jsr、jsr_w联合使用)1700xaatableswitch用于switch条件跳转，case值连续(变长指令)1710xablookupswitch用于switch条件跳转，case 值不连续(变长指令)1720xacireturn从当前方法返回int1730xadlreturn从当前方法返回long1740xaefreturn从当前方法返回float1750xafdreturn从当前方法返回double引用1760xb0areturn从当前方法返回对象引用1770xb1return从当前方法返回void1780xb2getstatic获取指定类的静态字段，并将其值压人栈顶1790xb3putstatic为指定类的静态字段赋值1800xb4getfield获取指定类的实例字段，并将其值压人栈顶1810xb5pufield为指定类的实例字段赋值1820xb6invokevirtual调用实例方法1830xb7invokespecial调用父类方法、实例初始化方法、私有方法1840xb8invokestatic调用静态方法1850xb9invokeinterface调用接口方法1860xbainvokedynamic调用动态链接方法1870xbbnew创建一个对象，并将其引用值压人栈顶1880xbcnewarray创建一个指定原始类型(如int、float、char等)的数组，并将其引用值压人栈顶1890xbdanewarray创建一个引用型(如类、接口、数组)的数组，并将其引用值压人栈顶1900xbearraylength获得数组的长度值并压人栈顶1910xbfathrow将栈顶的异常抛出1920xc0checkcast检验类型转换，检验未通过将抛出ClassCastException1930xc1instanceof检验对象是否是指定类的实例，如果是，就将1压人栈顶，否则将0压人栈顶扩展1940xc2monitorenter获得对象的锁，用于实现同步块1950xc3monitorexit释放对象的锁，用于实现同步块1960xc4wide扩展本地变量索引的宽度1970xc5multianewarray创建指定类型和指定维度的多维数组(执行该指令时，操作栈中必须包含各维度的长度值)，并将其引用值压人栈项1980xc6ifnull为null时跳转1990xc7ifnonnull不为null时跳转2000xc8goto_w无条件跳转(宽索引)2010xc9jsr_w跳转至指定32位offset位置，并将jsr_w下一条指令地址压人栈顶保留字段2020xcabreakpoint调试时的断点标记2540xfeimpdep1为特定软件而预留的语言后门2550xffimpdep2为特定硬件而预留的语言后门","categories":[{"name":"Java","slug":"Java","permalink":"https://www.wangfeng.pro/categories/Java/"},{"name":"JVM","slug":"Java/JVM","permalink":"https://www.wangfeng.pro/categories/Java/JVM/"}],"tags":[{"name":"JVM","slug":"JVM","permalink":"https://www.wangfeng.pro/tags/JVM/"}]},{"title":"将Maven项目打包发布到中央仓库","slug":"Maven/将Maven项目打包发布到中央仓库","date":"2018-06-06T05:02:58.000Z","updated":"2021-04-29T11:56:08.535Z","comments":true,"path":"2018/06/将maven项目打包发布到中央仓库.html","link":"","permalink":"https://www.wangfeng.pro/2018/06/%E5%B0%86maven%E9%A1%B9%E7%9B%AE%E6%89%93%E5%8C%85%E5%8F%91%E5%B8%83%E5%88%B0%E4%B8%AD%E5%A4%AE%E4%BB%93%E5%BA%93","excerpt":"","text":"项目配置groupId 要求项目的groupId一般为域名倒置，比如我的网址为wangfeng.pro，groupId则可以命名为pro.wangfeng。如果你没有属于自己的域名，则最好使用github相关的groupId，比如你的项目地址的github路径为https://www.github.com/username/projectName,那groupId最好为com.github.username。groupId的命名规范关系到在接下来的Sonatype OSSRH审核能否通过。 修改 pom.xml123456789101112131415161718192021222324252627282930313233343536373839404142&lt;!--开源协议--&gt;&lt;licenses&gt; &lt;license&gt; &lt;name&gt;The Apache License, Version 2.0&lt;/name&gt; &lt;url&gt;http://www.apache.org/licenses/LICENSE-2.0.txt&lt;/url&gt; &lt;/license&gt;&lt;/licenses&gt;&lt;!--开发者信息--&gt;&lt;developers&gt; &lt;developer&gt; &lt;name&gt;wf2311&lt;/name&gt; &lt;email&gt;wf2311@163.com&lt;/email&gt; &lt;roles&gt; &lt;role&gt;developer&lt;/role&gt; &lt;/roles&gt; &lt;timezone&gt;+8&lt;/timezone&gt; &lt;organization&gt;wf2311&lt;/organization&gt; &lt;organizationUrl&gt;https://www.wangfeng.pro&lt;/organizationUrl&gt; &lt;/developer&gt;&lt;/developers&gt;&lt;scm&gt; &lt;connection&gt;scm:git:https://github.com/wf2311/common-lang.git&lt;/connection&gt; &lt;developerConnection&gt;scm:git:https://github.com/wf2311/common-lang.git&lt;/developerConnection&gt; &lt;url&gt;https://github.com/wf2311/common-lang&lt;/url&gt; &lt;tag&gt;v$&#123;project.version&#125;&lt;/tag&gt;&lt;/scm&gt;&lt;!--仓库--&gt;&lt;distributionManagement&gt; &lt;!--快照库--&gt; &lt;snapshotRepository&gt; &lt;id&gt;ossrh&lt;/id&gt; &lt;url&gt;https://oss.sonatype.org/content/repositories/snapshots&lt;/url&gt; &lt;/snapshotRepository&gt; &lt;!--正式库--&gt; &lt;repository&gt; &lt;id&gt;ossrh&lt;/id&gt; &lt;name&gt;Maven Central Staging Repository&lt;/name&gt; &lt;url&gt;https://oss.sonatype.org/service/local/staging/deploy/maven2/&lt;/url&gt; &lt;/repository&gt;&lt;/distributionManagement&gt; 注意将其中与项目相关的路径修改为当前项目的加入相关插件: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566&lt;build&gt; &lt;plugins&gt; &lt;!--编译插件--&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-surefire-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;!--源码插件--&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-source-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-sources&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;!--javadoc插件--&gt; &lt;plugin&gt; &lt;artifactId&gt;maven-javadoc-plugin&lt;/artifactId&gt; &lt;version&gt;2.9.1&lt;/version&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;attach-javadocs&lt;/id&gt; &lt;goals&gt; &lt;goal&gt;jar&lt;/goal&gt; &lt;/goals&gt; &lt;configuration&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;additionalparam&gt;-Xdoclint:none&lt;/additionalparam&gt; &lt;/configuration&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;configuration&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;!--gpg签名插件--&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-gpg-plugin&lt;/artifactId&gt; &lt;executions&gt; &lt;execution&gt; &lt;id&gt;sign-artifacts&lt;/id&gt; &lt;phase&gt;verify&lt;/phase&gt; &lt;goals&gt; &lt;goal&gt;sign&lt;/goal&gt; &lt;/goals&gt; &lt;/execution&gt; &lt;/executions&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 修改完以上配置后，将代码同步到github上面。 注册 Sonatype OSSRH注册地址：https://issues.sonatype.org/secure/Signup!default.jspa 提交一个 ISSUE登录成功后，进入首页，点击页面上方的 Create 按钮，弹出如下窗口： Project 选择 Open Source Project Repository Hosting；Issue Type 选择 New Project；Summary 可以填你的项目名称；其它的必填项请参考示例填写，填写完成后点击下方的 Create 按钮提交 ISSUE 。 提交成功后，点击页面上方的 Issue 按钮，可以看到刚刚你提交的 ISSUE : 稍等片刻，你就会审核者的相关评论，询问你填写的groupId对应的域名是不是属于你的： 然后你需要点击下方的 Comment 按钮回答审核者，向他确认该域名是属于你的: 这个确认过程可能需要你和审核者交流几个来回才能搞定，具体过程可参考笔者的一个ISSUE案例。 当最终审核通过后，你将收到审核者的如下回复： 并且该 ISSUE 的状态将变为RESOLVED： 至此，你就有权限将该项目发布到maven中央仓库中了。 注意：如果你还有其它的项目也需要发布到中央仓库，并且 groupId 和上面的一样，就不需要再次创建 ISSUE 了；只有在使用新的 groupId 时才需要提交 ISSUE。 gpg安装配置安装 gpg由于各个系统版本的 gpg 安装方式不尽相同，这里就不写详细安装方式了。具体步骤可以 google 、百度或者按官网上给的步骤下载安装。 安装完成后在终端或命令行运行以下命令，确认是否安装成功： 1gpg --version 出现类似信息表上安装成功： 1234567891011121314gpg (GnuPG) 2.1.21libgcrypt 1.7.8Copyright (C) 2017 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;https://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law.Home: /Users/wf2311/.gnupg支持的算法：公钥：RSA, ELG, DSA, ECDH, ECDSA, EDDSA对称加密：IDEA, 3DES, CAST5, BLOWFISH, AES, AES192, AES256, TWOFISH, CAMELLIA128, CAMELLIA192, CAMELLIA256散列：SHA1, RIPEMD160, SHA256, SHA384, SHA512, SHA224压缩：不压缩, ZIP, ZLIB, BZIP2 生成密钥对以 Mac 下操作为例，不同系统的过程可能有所差异运行命令: 1gpg --gen-key 会让你输入真实姓名: 1234567891011gpg (GnuPG) 2.1.21; Copyright (C) 2017 Free Software Foundation, Inc.This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law.Note: Use &quot;gpg2 --full-generate-key&quot; for a full featured key generation dialog.You need a user ID to identify your key; the software constructs the user IDfrom the Real Name, Comment and Email Address in this form: &quot;Heinrich Heine (Der Dichter) &lt;heinrichh@duesseldorf.de&gt;&quot;真实姓名： 输入 你的姓名(至少为5个字符) ，回车再输入你的电子邮箱 ，回车，出现： 1Change (N)ame, (E)mail, or (O)kay/(Q)uit? 选择 O 回车，出现如下提示: 12我们需要生成大量的随机字节。这个时候您可以多做些琐事(像是敲打键盘、移动鼠标、读写硬盘之类的)，这会让随机数字发生器有更好的机会获得足够的熵数。 并且提示让你输入密码，输入密码后回车，稍等片刻就会出现如下生成信息：图中的CD4809496C405C2F72F62B31052A2DC27A064C14即为生成的公钥 发布公钥到 GPG 密钥服务器运行命令： 1gpg --keyserver hkp://pool.sks-keyservers.net --send-keys CD4809496C405C2F72F62B31052A2DC27A064C14 此操作因为网络原因可能需要等待一定的时间 查询公钥是否发布成功运行命令 1gpg --keyserver hkp://pool.sks-keyservers.net --recv-keys CD4809496C405C2F72F62B31052A2DC27A064C14 出现类似以下信息即表示发布成功： 123gpg: 密钥 052A2DC27A064C14：“wf2311 &lt;wf2311@163.com&gt;”未改变gpg: 合计被处理的数量：1gpg: 未改变：1 更多 gpg 命令请参考阮一峰的GPG入门教程 修改 maven 配置文件在maven的配置文件 settings.xml 中添加以下内容: 1234567891011121314151617&lt;servers&gt; &lt;server&gt; &lt;id&gt;id须与pom.xml中distributionManagement下设置的id保持一致&lt;/id&gt; &lt;username&gt;注册Sonatype账号是填写的用户名&lt;/username&gt; &lt;password&gt;注册Sonatype账号是填写的密码&lt;/password&gt; &lt;/server&gt;&lt;/servers&gt;...&lt;profile&gt; &lt;id&gt;gpg&lt;/id&gt; &lt;properties&gt; &lt;gpg.executable&gt;与gpg版本有关mac下一般填写gpg2,window下填gpg&lt;/gpg.executable&gt; &lt;gpg.passphrase&gt;生成gpg秘钥过程中填写的密码&lt;/gpg.passphrase&gt; &lt;/properties&gt;&lt;/profile&gt; 打包上传切换到当前项目路径，运行命令: 1mvn -DskipTests clean deploy 正常情况下，如果运行成功未出错，项目会打包并上传的对应的仓库中： 对应快照版本，即版本号以 -SNAPSHOT 结尾的，会立即上传到 https://oss.sonatype.org/content/repositories/snapshots 中，并且可以直接通过 maven 快照仓库引用，但是在 maven 中央仓库中搜索不到。 对应正式版本，即版本号不是以 -SNAPSHOT 结尾的，虽然也会上传到 https://oss.sonatype.org/service/local/staging/deploy/maven2/ 中，但还需要我们手动发布一下，才会发布到中央仓库中。 提示： 如果在 Mac 环境下打包是出现 gpg 相关的错误，可以参考 gpg: 签名时失败处理这篇文章来处理 在 OSS 中发布构件登录登录 https://oss.sonatype.org，用户名密码与上面 Sonatype 的相同 发布构建登录成功后会进入如下页面： 点击左侧的 Build Promotion 下的 Staging Repositories，出现： 在搜索输入框输入项目的 groupId，找到并选择你刚刚打包上传的项目。点击上方的 Close 按钮： 再在弹窗中点击 Confirm 按钮，过几秒后再点击上面的 Refresh 按钮进行刷新，就可以看到如下界面： 展开下方 Activity 面板的结果信息，如果出现如上图的信息，即表示构建通过。再过几秒后再次点击点击上面的 Refresh 按钮进行刷新，就会看到旁边的 Release 按钮变为可操作状态： 最后点击 Release 按钮，出现弹窗： 点击 Confirm 按钮，确认发布构建，至此发布构建的的步骤全部结束。再等待大概一到两小时的同步时间后，便可以在中央仓库中搜索到你发布的项目了： 修改 README.md 文件在项目的 README.md 头部 加上 如下格式的内容： 1[![Maven Central](https://maven-badges.herokuapp.com/maven-central/&lt;groupId&gt;/&lt;projectName&gt;/badge.svg)](https://maven-badges.herokuapp.com/maven-central/&lt;groupId&gt;/&lt;projectName&gt;) 比如我的这个项目的 gorupId 为 pro.wangfeng，projectName 为 common-lang，则加上： 1[![Maven Central](https://maven-badges.herokuapp.com/maven-central/pro.wangfeng/common-lang/badge.svg)](https://maven-badges.herokuapp.com/maven-central/pro.wangfeng/common-lang) 之后就会出现如下显示： 最后再给出两个在打包时十分有用的 maven 命令： 更新父模块到指定版本号： 1mvn versions:set -DnewVersion=1.0.1-SNAPSHOT 更新子模块版本到与模块相同： 1mvn -N versions:update-child-modules 参考 将jar发布到maven中央仓库小记 向maven中央仓库提交jar","categories":[{"name":"Maven","slug":"Maven","permalink":"https://www.wangfeng.pro/categories/Maven/"}],"tags":[{"name":"Maven","slug":"Maven","permalink":"https://www.wangfeng.pro/tags/Maven/"}]},{"title":"Docker命令备忘","slug":"Docker/Docker命令备忘","date":"2018-06-01T04:20:24.000Z","updated":"2021-05-14T12:27:05.032Z","comments":true,"path":"2018/06/docker命令备忘.html","link":"","permalink":"https://www.wangfeng.pro/2018/06/docker%E5%91%BD%E4%BB%A4%E5%A4%87%E5%BF%98","excerpt":"镜像相关列出所有镜像1docker images 删除镜像1docker image rm [选项] &lt;镜像1&gt; [&lt;镜像2&gt; ...] 删除名称或标签为none的镜像1docker rmi -f `docker images | grep &#x27;&lt;none&gt;&#x27; | awk &#x27;&#123;print $3&#125;&#x27;`","text":"镜像相关列出所有镜像1docker images 删除镜像1docker image rm [选项] &lt;镜像1&gt; [&lt;镜像2&gt; ...] 删除名称或标签为none的镜像1docker rmi -f `docker images | grep &#x27;&lt;none&gt;&#x27; | awk &#x27;&#123;print $3&#125;&#x27;` 容器相关创建并启动容器1$ docker run -d --name MyJenkins -p 8080:8080 -p 50000:50000 -v jenkins_home:/var/jenkins_home jenkins/jenkins:lts docker run : 由 image 建立 container 并执行之; -d : 建立 container 后，就脱离目前 process —name : 替 container 设置一个易识别的名字 MyJenkins (若省略，Docker 将随机命名，不易维护) -p : Docker 外部与 Jenkins 內部所对应的 port，其中左边为外部 Docker 的 port，右边为 Jenkins 內部的 port -v : 建立 JENKINS_HOME 环境变量，其目录在 /var/jenkins_home，为 Jenkins 的工作目录 重命名容器名称1docker rename &lt;old_name&gt; &lt;new_name&gt; 显示所有容器1docker ps -a 根据容器名称启动/停止容器1docker [stop] [start] &lt;container_name&gt; 进入容器1docker exec -it &lt;container_name&gt; /bin/bash 退出容器1exit 上传文件到容器1docker cp [本地文件路径] &lt;container_name&gt;: [目标路径] 查看容器日志1docker logs -t -f &lt;container_name&gt; 删除异常停止的docker容器1docker rm `docker ps -a | grep Exited | awk &#x27;&#123;print $1&#125;&#x27;` 参考 如何使用 Docker 安裝 Jenkins ?","categories":[{"name":"Docker","slug":"Docker","permalink":"https://www.wangfeng.pro/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://www.wangfeng.pro/tags/Docker/"},{"name":"命令","slug":"命令","permalink":"https://www.wangfeng.pro/tags/%E5%91%BD%E4%BB%A4/"},{"name":"笔记","slug":"笔记","permalink":"https://www.wangfeng.pro/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"Spring事件的使用","slug":"Spring/Spring事件的使用","date":"2018-01-15T13:57:13.000Z","updated":"2021-05-14T13:06:17.489Z","comments":true,"path":"2018/01/spring事件的使用.html","link":"","permalink":"https://www.wangfeng.pro/2018/01/spring%E4%BA%8B%E4%BB%B6%E7%9A%84%E4%BD%BF%E7%94%A8","excerpt":"简介 Spring 的事件(Spring Application Event)为 Bean 与 Bean 之间传递消息。一个 Bean 处理完了希望其余一个接着处理。这时我们就需要其余的一个 Bean 监听当前 Bean 所发送的事件。","text":"简介 Spring 的事件(Spring Application Event)为 Bean 与 Bean 之间传递消息。一个 Bean 处理完了希望其余一个接着处理。这时我们就需要其余的一个 Bean 监听当前 Bean 所发送的事件。 Spring 事件使用步骤如下: 先自定义事件: 需要继承ApplicationEvent; 定义事件监听者: 使用注解@EventListener或者实现ApplicationListener; 使用容器对事件进行发布; 基于注解监听模式的基本用法以下用一个每天的定时同步任务为例进行讲解: 定义同步事件SyncEvent: 123456789/** * 同步任务事件 * @author wf2311 */public class SyncEvent extends ApplicationEvent&#123; public SyncEvent(Object source) &#123; super(source); &#125;&#125; 事件监听者定义一个 MailHandler.java 在监听到事件后发送邮件: 12345678910111213141516/** * 邮件发送处理器 * * @author wf2311 */@Servicepublic class MailHandler &#123; private static final Logger log = LoggerFactory.getLogger(MailService.class); @EventListener public void sendSycResult(SyncEvent event) throws InterruptedException &#123; log.debug(&quot;MailHandler接收到同步结果:&#123;&#125;&quot;,event); TimeUnit.SECONDS.sleep(1); log.debug(&quot;mock send sync data ...&quot;); &#125;&#125; 在void sendSycResult(SyncEvent event)方法上使用注解@EventListener, 表明sendSycResult方法将会监听SyncEvent事件; EventListener的源码如下: 1234567891011121314151617181920212223242526@Target(&#123;ElementType.METHOD, ElementType.ANNOTATION_TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface EventListener &#123; /** * classes的别名 */ @AliasFor(&quot;classes&quot;) Class&lt;?&gt;[] value() default &#123;&#125;; /** * 要监听的事件类。 * 如果该属性只绑定了一个监听类，那使用该注解的方法最多只能有一个参数，并且参数类型需要该属性绑定的监听类相匹配(即参数类型需是监听类或者其父类); * 如果该属性绑定了多个监听类，那使用该注解的方法不能带有任何参数。 */ @AliasFor(&quot;value&quot;) Class&lt;?&gt;[] classes() default &#123;&#125;; /** * 匹配条件，SpEL表达式； * 默认为空，表示总是匹配 */ String condition() default &quot;&quot;;&#125; 发布事件SyncService: 123456789101112131415161718192021222324252627/** * 数据同步服务 * * @author wf2311 */@Servicepublic class SyncService &#123; private static final Logger log = LoggerFactory.getLogger(SyncService.class); @Autowired private ApplicationEventPublisher applicationEventPublisher; public void syncDayData(LocalDate day) throws InterruptedException &#123; log.debug(&quot;开始同步&#123;&#125;的数据&quot;, day); long start = System.currentTimeMillis(); TimeUnit.SECONDS.sleep(1); long end = System.currentTimeMillis(); long speed = end - start; log.debug(&quot;&#123;&#125;的数据同步完成,耗时&#123;&#125; ms&quot;, day, speed); SyncData syncData = SyncData.builder().day(day).speed(speed).data(new Object()).build(); applicationEventPublisher.publishEvent(new SyncEvent(syncData, &quot;mail&quot;)); TimeUnit.SECONDS.sleep(3); long end2 = System.currentTimeMillis(); log.debug(&quot;sleep &#123;&#125; ns&quot;, end2 - end); &#125;&#125; 测试12345678910111213@RunWith(SpringRunner.class)@SpringBootTestpublic class SpringEventApplicationTests &#123; @Autowired private SyncService syncService; @Test public void testSyncData() throws InterruptedException &#123; syncService.syncDayData(LocalDate.now()); &#125;&#125; 运行测试方法testSyncData(),得到如下结果: 123452018-01-15 16:37:11.387 DEBUG 132812 --- [ main] c.w.s.e.s.SyncService : 开始同步2018-01-15的数据2018-01-15 16:37:12.389 DEBUG 132812 --- [ main] c.w.s.e.s.SyncService : 2018-01-15的数据同步完成,耗时1001 ms2018-01-15 16:37:12.390 DEBUG 132812 --- [ main] c.w.s.e.h.MailHandler : MailHandler接收到同步结果:SyncEvent(type=mail)2018-01-15 16:37:13.391 DEBUG 132812 --- [ main] c.w.s.e.h.MailHandler : mock send sync data ...2018-01-15 16:37:16.391 DEBUG 132812 --- [ main] c.w.s.e.s.SyncService : sleep 4002 ns 由测试结果可知：在方法syncDayData()运行到applicationEventPublisher.publishEvent(new SyncEvent(syncData))后就会立即自动调用void sendSycResult(SyncEvent event)方法。 多个事件监听者如果在同步任务完成后，不仅需要发送邮件，还需要对数据进行缓存和消息推送，只需要仿照MailHandler,再建立相应的类。CacheHandler: 1234567891011121314151617/** * 缓存处理器 * @author wf2311 */@Componentpublic class CacheHandler &#123; private static final Logger log = LoggerFactory.getLogger(CacheHandler.class); @EventListener public void cacheSycResult(SyncEvent event) throws InterruptedException &#123; log.debug(&quot;CacheHandler接收到同步结果:&#123;&#125;&quot;, event.getSource()); TimeUnit.SECONDS.sleep(2); log.debug(&quot;mock cache sync data ...&quot;); &#125;&#125; MqHandler: 1234567891011@Componentpublic class MqHandler &#123; private static final Logger log = LoggerFactory.getLogger(MqHandler.class); @EventListener public void pushSycResult(SyncEvent event) throws InterruptedException &#123; log.debug(&quot;MqHandler接收到同步结果:&#123;&#125;&quot;, event.getSource()); TimeUnit.SECONDS.sleep(3); log.debug(&quot;mock push sync data ...&quot;); &#125;&#125; 运行syncDayData()测试方法得到如下结果: 1234567892018-01-15 16:44:57.280 DEBUG 135208 --- [ main] c.w.s.e.s.SyncService : 开始同步2018-01-15的数据2018-01-15 16:44:58.281 DEBUG 135208 --- [ main] c.w.s.e.s.SyncService : 2018-01-15的数据同步完成,耗时1001 ms2018-01-15 16:44:58.282 DEBUG 135208 --- [ main] c.w.s.e.h.CacheHandler : CacheHandler接收到同步结果:SyncData(day=2018-01-15, speed=1001, data=java.lang.Object@3f9270ed)2018-01-15 16:45:00.282 DEBUG 135208 --- [ main] c.w.s.e.h.CacheHandler : mock cache sync data ...2018-01-15 16:45:00.282 DEBUG 135208 --- [ main] c.w.s.e.h.MailHandler : MailHandler接收到同步结果:SyncEvent(type=mail)2018-01-15 16:45:01.283 DEBUG 135208 --- [ main] c.w.s.e.h.MailHandler : mock send sync data ...2018-01-15 16:45:01.283 DEBUG 135208 --- [ main] c.w.s.e.h.MqHandler : MqHandler接收到同步结果:SyncData(day=2018-01-15, speed=1001, data=java.lang.Object@3f9270ed)2018-01-15 16:45:04.283 DEBUG 135208 --- [ main] c.w.s.e.h.MqHandler : mock push sync data ...2018-01-15 16:45:07.283 DEBUG 135208 --- [ main] c.w.s.e.s.SyncService : sleep 9002 ns 由测试结果可以看出，在方法syncDayData()运行到applicationEventPublisher.publishEvent(new SyncEvent(syncData))后就会立即依次调用我们定义的多个监听者。但是如果我们对邮件发送、消息推送、缓存更新的执行顺序由特定的需求怎么办？(经简单测试，在有多个监听者时，默认情况下监听者的执行顺序是安装监听者所在的类名(不是beanName)来执行的) 使用@Order来指定监听者执行顺序查看EventListener的API文档，其中有这样一段描述： It is also possible to define the order in which listeners for a certain event are to be invoked. To do so, add Spring’s common @Order annotation alongside this event listener annotation. 所以我们可以用@Order来配合@EventListener来指定多个监听者的执行顺序。分别修改MailHandler: 12345@EventListener@Order(1)public void sendSycResult(SyncEvent event) throws InterruptedException &#123; //...&#125; CacheHandler: 12345@EventListener@Order(2)public void cacheSycResult(SyncEvent event) throws InterruptedException &#123; //...&#125; MqHandler: 12345@EventListener@Order(3)public void pushSycResult(SyncEvent event) throws InterruptedException &#123; //...&#125; 以上的代码为我们指定了3个监听者的依次执行顺序为: MailHandler、CacheHandler、MqHandler再次运行syncDayData()测试方法得到如下结果: 1234567892018-01-15 17:09:34.830 DEBUG 138192 --- [ main] c.w.s.e.s.SyncService : 开始同步2018-01-15的数据2018-01-15 17:09:35.831 DEBUG 138192 --- [ main] c.w.s.e.s.SyncService : 2018-01-15的数据同步完成,耗时1001 ms2018-01-15 17:09:35.832 DEBUG 138192 --- [ main] c.w.s.e.h.MailHandler : MailHandler接收到同步结果:SyncEvent(type=mail)2018-01-15 17:09:36.832 DEBUG 138192 --- [ main] c.w.s.e.h.MailHandler : mock send sync data ...2018-01-15 17:09:36.832 DEBUG 138192 --- [ main] c.w.s.e.h.CacheHandler : CacheHandler接收到同步结果:SyncData(day=2018-01-15, speed=1001, data=java.lang.Object@129bd55d)2018-01-15 17:09:38.833 DEBUG 138192 --- [ main] c.w.s.e.h.CacheHandler : mock cache sync data ...2018-01-15 17:09:38.833 DEBUG 138192 --- [ main] c.w.s.e.h.MqHandler : MqHandler接收到同步结果:SyncData(day=2018-01-15, speed=1001, data=java.lang.Object@129bd55d)2018-01-15 17:09:41.833 DEBUG 138192 --- [ main] c.w.s.e.h.MqHandler : mock push sync data ...2018-01-15 17:09:44.834 DEBUG 138192 --- [ main] c.w.s.e.s.SyncService : sleep 9003 ns 测试顺序与设置的顺序一致。 基于多个监听者的链式调用同样是在EventListener的API文档中，有这样一段描述： Annotated methods may have a non-void return type. When they do, the result of the method invocation is sent as a new event. If the return type is either an array or a collection, each element is sent as a new individual event. 大概意思是说: EventListener注解的方法，可以返回一个非空的类型。并且该方法的返回结果可以作为一个新的事件被发送。如果返回类型是数组或集合，则将每个元素作为新的单独事件发送。我们可以基于此特性，实现多个监听者的链式调用。 定义 OrderInfo:123456789101112/** * @author wf2311 */@Data@Builderpublic class OrderInfo&#123; private String customer; private LocalDateTime orderTime; private Integer emailResultId; private Integer cacheResultId; private Integer mqResultId;&#125; 订单事件类 OrderEvent12345678910111213/** * 订单事件 * @author wf2311 */@Datapublic class OrderEvent extends ApplicationEvent &#123; private String nextListenerType; public OrderEvent(Object source, String nextListenerType) &#123; super(source); this.nextListenerType = nextListenerType; &#125;&#125; 设置订单事件监听者MqHandler中,添加:12345678@EventListener(condition = &quot;#event.nextListenerType == &#x27;mq&#x27;&quot;)public OrderEvent pushOrderInfo(OrderEvent event) &#123; log.debug(&quot;MqHandler接收到订单信息:&#123;&#125;&quot;, event); ((OrderInfo) event.getSource()).setMqResultId(1); log.debug(&quot;mock push order event ...&quot;); event.setNextListenerType(&quot;cache&quot;); return event;&#125; CacheHandler中,添加: 12345678@EventListener(condition = &quot;event.nextListenerType == &#x27;cache&#x27;&quot;)public OrderEvent cacheOrderInfo(OrderEvent event) &#123; log.debug(&quot;CacheHandler接收到订单信息:&#123;&#125;&quot;, event.getSource()); ((OrderInfo) event.getSource()).setCacheResultId(2); log.debug(&quot;mock cache order info ...&quot;); event.setNextListenerType(&quot;mail&quot;); return event;&#125; 在MailHandler中,添加: 12345678@EventListener(condition = &quot;#event.nextListenerType == &#x27;mail&#x27;&quot;)public OrderEvent sendOrderInfo(OrderEvent event) &#123; log.debug(&quot;MailHandler接收到订单信息:&#123;&#125;&quot;, event.getSource()); ((OrderInfo) event.getSource()).setMqResultId(3); log.debug(&quot;mock send order event ...&quot;); event.setNextListenerType(null); return event;&#125; 以上各个EventListener中的condition表示，只有当对应的事件中对应的自定义属性nextListenerType等于对应值时，才会执行该方法。 设置事件发布者:OrderService:12345678910111213141516171819/** * 订单服务 * @author wf2311 */@Servicepublic class OrderService &#123; private static final Logger log = LoggerFactory.getLogger(OrderService.class); @Autowired private ApplicationEventPublisher applicationEventPublisher; public void saveOrder(String customer, LocalDateTime time) throws InterruptedException &#123; OrderInfo order = OrderInfo.builder().orderTime(time).customer(customer).build(); log.debug(&quot;保存订单信息:&#123;&#125;&quot;, order); TimeUnit.SECONDS.sleep(3); applicationEventPublisher.publishEvent(new OrderEvent(order, &quot;mq&quot;)); &#125;&#125; 测试方法：123456@Autowiredprivate OrderService orderService;@Testpublic void testOrderInfo() throws InterruptedException &#123; orderService.saveOrder(&quot;test&quot;, LocalDateTime.now());&#125; 运行后得到如下结果：12345672018-01-15 18:51:46.677 DEBUG 135904 --- [ main] c.w.s.e.s.OrderService : 保存订单信息:OrderInfo(customer=test, orderTime=2018-01-15T18:51:46.674, emailResultId=null, cacheResultId=null, mqResultId=null)2018-01-15 18:51:49.702 DEBUG 135904 --- [ main] c.w.s.e.h.MqHandler : MqHandler接收到订单信息:OrderEvent(nextListenerType=mq)2018-01-15 18:51:49.702 DEBUG 135904 --- [ main] c.w.s.e.h.MqHandler : mock push order event ...2018-01-15 18:51:49.703 DEBUG 135904 --- [ main] c.w.s.e.h.CacheHandler : CacheHandler接收到订单信息:OrderInfo(customer=test, orderTime=2018-01-15T18:51:46.674, emailResultId=null, cacheResultId=null, mqResultId=1)2018-01-15 18:51:49.703 DEBUG 135904 --- [ main] c.w.s.e.h.CacheHandler : mock cache order info ...2018-01-15 18:51:49.703 DEBUG 135904 --- [ main] c.w.s.e.h.MailHandler : MailHandler接收到订单信息:OrderInfo(customer=test, orderTime=2018-01-15T18:51:46.674, emailResultId=null, cacheResultId=2, mqResultId=1)2018-01-15 18:51:49.703 DEBUG 135904 --- [ main] c.w.s.e.h.MailHandler : mock send order event ... 结果分析：saveOrder()发布的事件中event.nextListenerType = ‘mq’,只有pushOrderInfo()方法符合条件；执行完pushOrderInfo()后，event.nextListenerType变为’cache’,只有cacheOrderInfo()方法符合条件；执行完cacheOrderInfo()后,event.nextListenerType变为’mail’,只有sendOrderInfo()方法符合条件；执行完sendOrderInfo()后,event.nextListenerType变为null,无符合条件的事件监听者，结束事件监听； 基于实现ApplicationListener的事件监听者参考Spring Application Event Example","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.wangfeng.pro/categories/Spring/"}],"tags":[{"name":"Spring","slug":"Spring","permalink":"https://www.wangfeng.pro/tags/Spring/"},{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.wangfeng.pro/tags/SpringBoot/"},{"name":"ApplicationEvent","slug":"ApplicationEvent","permalink":"https://www.wangfeng.pro/tags/ApplicationEvent/"}]},{"title":"有了Closeable为什么还要定义AutoCloseable","slug":"Java/Java基础/有了Closeable为什么还要定义AutoCloseable","date":"2017-09-27T01:24:31.000Z","updated":"2021-05-14T13:06:17.467Z","comments":true,"path":"2017/09/有了closeable为什么还要定义autocloseable.html","link":"","permalink":"https://www.wangfeng.pro/2017/09/%E6%9C%89%E4%BA%86closeable%E4%B8%BA%E4%BB%80%E4%B9%88%E8%BF%98%E8%A6%81%E5%AE%9A%E4%B9%89autocloseable","excerpt":"","text":"从try-with-resources语法块说起我们知道java7中引入了新的语法块try-with-resources:实现了java.lang.AutoCloseable的对象都可以作为资源，在try后面的括号类声明实例化，在后面的&#123;...&#125;语句块执行完后被自动关闭(close()方法被自动调用)。例如：在java7前，我们需要这样定义语句: 1234567891011121314public void writeFile(String path,byte[] data)&#123; OutputStream os = null; try &#123; os = new FileOutputStream(path); os.write(data); os.flush(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;finally &#123; if (os!=null)&#123; os.close(); &#125; &#125;&#125; 而在java7后，可以变成这样： 12345678public void writeFile(String path,byte[] data)&#123; try ( OutputStream os = new FileOutputStream(path))&#123; os.write(data); os.flush(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125;&#125; Closeable与AutoCloseable的关系与区别AutoCloseable的源码如下: 123456/** * @since 1.7 */public interface AutoCloseable &#123; void close() throws Exception;&#125; Closeable的源码如下: 123456/** * @since 1.5 */public interface Closeable extends AutoCloseable &#123; public void close() throws IOException;&#125; 由上可知Closeable在jdk1.5中就定义了，而AutoCloseable在jdk1.7才被引入，并且Closeable继承了AutoCloseable。为什么要这样设计呢？答案很简单，仔细查看源码就可以知道原因:因为Closeable的close()方法只会抛出IOException异常，而AutoCloseable的close()方法抛出的是Exception异常。如此一来try-with-resources的适用性就更大了。 参考 https://stackoverflow.com/questions/19572537/why-is-autocloseable-the-base-interface-for-closeable-and-not-vice-versa","categories":[{"name":"Java","slug":"Java","permalink":"https://www.wangfeng.pro/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://www.wangfeng.pro/tags/Java/"}]},{"title":"IDEA 远程调试spring boot项目","slug":"其它/远程调试/IDEA 远程调试spring boot项目","date":"2017-09-21T01:33:52.000Z","updated":"2021-04-29T12:04:57.383Z","comments":true,"path":"2017/09/idea-远程调试spring-boot项目.html","link":"","permalink":"https://www.wangfeng.pro/2017/09/idea-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95spring-boot%E9%A1%B9%E7%9B%AE","excerpt":"","text":"IDEA 远程调试spring boot项目1. Dokcer容器中在Dockefile中配置(方法1)在Dockerfile文件中加入参数-agentlib:jdwp=transport=dt_socket,address=8000,server=y,suspend=n,例如： 123...ENV JAVA_OPTS=&quot;-agentlib:jdwp=transport=dt_socket,address=8000,server=y,suspend=n&quot;ENTRYPOINT [ &quot;sh&quot;, &quot;-c&quot;, &quot;java $JAVA_OPTS -Djava.security.egd=file:/dev/./urandom -jar /app.jar&quot; ] 启动docker命令： 1docker run -p 8000:8000 -p 4000:4000 -t imageName 参数说明： -p 8000:8000 表示把在Dockerfile中定义的远程调试端口8000映射到服务器端口8000中； -p 4000:4000 表示把在应用程序的启动端口4000映射到服务器端口4000中； 启动命令中配置(方法2)在启动命令中加上参数-e &quot;JAVA_OPTS=-agentlib:jdwp=transport=dt_socket,address=8000,server=y,suspend=y&quot;，例如： 1docker run -e &quot;JAVA_OPTS=-agentlib:jdwp=transport=dt_socket,address=8000,server=y,suspend=y&quot; -p 8000:8000 -p 4000:4000 -t imageName 2. 以嵌入式web容器运行时在启动命令中加上参数-e &quot;-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8000，例如： 1java -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8000 -jar application.jar 3. 以mvn spring-boot:run运行时在pom.xml中加入如下插件: 123456789&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;jvmArguments&gt; -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=y,address=8000 &lt;/jvmArguments&gt; &lt;/configuration&gt;&lt;/plugin&gt; 参考资料 debug spring-boot in docker spring boot + IDEA 远程调试 Spring Boot Maven Plugin - Debug the application","categories":[{"name":"其它","slug":"其它","permalink":"https://www.wangfeng.pro/categories/%E5%85%B6%E5%AE%83/"},{"name":"远程调试","slug":"其它/远程调试","permalink":"https://www.wangfeng.pro/categories/%E5%85%B6%E5%AE%83/%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.wangfeng.pro/tags/SpringBoot/"},{"name":"远程调试","slug":"远程调试","permalink":"https://www.wangfeng.pro/tags/%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/"}]},{"title":"SpringBoot + IDEA 远程调试","slug":"其它/远程调试/SpringBoot + IDEA 远程调试","date":"2017-09-19T02:20:54.000Z","updated":"2021-04-29T12:04:57.407Z","comments":true,"path":"2017/09/springboot-idea-远程调试.html","link":"","permalink":"https://www.wangfeng.pro/2017/09/springboot-idea-%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95","excerpt":"","text":"配置若想调试远端web容器内部的应用，需要接入web容器的jvm，以Tomcat为例，需修改web容器的配置 12345678// bin\\startup.bat（.sh）文件，在里面添加 // windowsset CATALINA_OPTS=&quot;-agentlib:jdwp=transport=dt_socket,address=8888（自定义调试端口）,server=y,suspend=n %CATALINA_OPTS%&quot; // linuxexport CATALINA_OPTS=&quot;-agentlib:jdwp=transport=dt_socket,address= 8888（自定义调试端口）,server=y,suspend=n $CATALINA_OPTS&quot; 若是使用了spring boot并将工程打成了可执行JAR包 123456// 在使用java指令启动程序时需要附加额外的参数以开启外部调试，如下-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8888（自定义调试端口） // 完整的启动指令是类似下面酱的java -Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8888（自定义调试端口） -jar application.jar IDEA连接远端调试填写远端JMV所在服务器IP和调试端口号，保存即可：连接远端JVM启动调试：如若连接成功，调试控制台将输出以下内容，如果没成功，请自行检查服务器防火墙以及网络接下来的操作就和在本地调试一样了，打断点，远端JVM会通过网络同步调试信息，和在本地没什么两样，要注意调试的时候和本地一样都是会暂停JVM继续往下执行的。","categories":[{"name":"其它","slug":"其它","permalink":"https://www.wangfeng.pro/categories/%E5%85%B6%E5%AE%83/"},{"name":"远程调试","slug":"其它/远程调试","permalink":"https://www.wangfeng.pro/categories/%E5%85%B6%E5%AE%83/%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.wangfeng.pro/tags/SpringBoot/"},{"name":"远程调试","slug":"远程调试","permalink":"https://www.wangfeng.pro/tags/%E8%BF%9C%E7%A8%8B%E8%B0%83%E8%AF%95/"}]},{"title":"Java的枚举类使用技巧","slug":"Java/Java基础/Java的枚举类使用技巧","date":"2017-08-02T06:05:07.000Z","updated":"2021-05-14T13:06:17.439Z","comments":true,"path":"2017/08/java的枚举类使用技巧.html","link":"","permalink":"https://www.wangfeng.pro/2017/08/java%E7%9A%84%E6%9E%9A%E4%B8%BE%E7%B1%BB%E4%BD%BF%E7%94%A8%E6%8A%80%E5%B7%A7","excerpt":"","text":"枚举接口在web开发中我们常常会定义一些enum来表示常量，比如: 1234567891011121314151617181920212223enum BlogType &#123; BLOG(1, &quot;原创博文&quot;), REPRINT(2, &quot;转载文章&quot;), QUESTION(3, &quot;问答&quot;), VOTE(4, &quot;投票&quot;), SUBJECT(5, &quot;专栏&quot;); private Integer code; private String name; BlogType(Integer code, String name) &#123; this.code = code; this.name = name; &#125; public Integer getCode() &#123; return code; &#125; public String getName() &#123; return name; &#125;&#125; 以及: 123456789101112131415161718192021enum BlogStatus &#123; PRIVATE(1, &quot;自己可见&quot;), FRIEND(2, &quot;好友可见&quot;), ONLINE(3, &quot;登陆用户可见&quot;), PUBLISH(4, &quot;公开&quot;); private Integer code; private String name; BlogStatus(Integer code, String name) &#123; this.code = code; this.name = name; &#125; public Integer getCode() &#123; return code; &#125; public String getName() &#123; return name; &#125;&#125; 可以看出它们的结构一样，都有code和name这两个属性，以及对应的getter方法，因此可以定义一个如下的接口： 123456public interface Common&lt;C, N&gt; &#123; C getCode(); N getName();&#125; 所有如上面的常量枚举类都可以实现该接口。 1234567enum BlogType implements Common &#123; //...&#125;enum BlogStatus implements Common &#123; //...&#125; 公用静态方法我们可以在在Common接口中定义一个如下的静态方法： 12345static &lt;E extends Enum&lt;E&gt; &amp; Common, C&gt; E getByCode(Class&lt;E&gt; clazz, C code) &#123; return Arrays.stream(clazz.getEnumConstants()) .filter(t -&gt; t.getCode().equals(code)) .findFirst().orElse(null);&#125; 使用此方法可以根据code来查找指定的Common实现类中的值，比如： 12Assert.assertEquals(BlogType.QUESTION, Common.getByCode(BlogType.class, BlogType.QUESTION.getCode()));Assert.assertEquals(BlogStatus.PUBLISH, Common.getByCode(BlogType.class, BlogStatus.PUBLISH.getCode())); 自定义序列化当我们定义如下的方法 123456789@GetMapping(&quot;/consts&quot;)public ApiResult consts() &#123; ApiResult result = new ApiResult(); Map&lt;String, Object&gt; consts = new HashMap&lt;&gt;(); consts.put(&quot;blogType&quot;, BlogType.values()); consts.put(&quot;blogStatus&quot;, BlogStatus.values()); result.setData(consts); return result;&#125; 通过请求，得到的结果格式是 12345678910111213141516171819&#123; &quot;code&quot;: 0, &quot;success&quot;: true, &quot;data&quot;: &#123; &quot;blogStatus&quot;: [ &quot;PRIVATE&quot;, &quot;FRIEND&quot;, &quot;ONLINE&quot;, &quot;PUBLISH&quot; ], &quot;blogType&quot;: [ &quot;BLOG&quot;, &quot;REPRINT&quot;, &quot;QUESTION&quot;, &quot;VOTE&quot;, &quot;SUBJECT&quot; ] &#125;&#125; 而我们期待的到是格式是包含code和name的键值对的形式，而不是以上的形式。通过在Common接口中添加以上方法可以实现： 123456@JsonValuedefault Map&lt;C, N&gt; toMap() &#123; Map&lt;C, N&gt; map = new HashMap&lt;&gt;(1); map.put(getCode(), getName()); return map;&#125; 此时再次通过页面请求，得到的结果将如下： 12345678910111213141516171819202122232425262728293031323334353637&#123; &quot;code&quot;: 0, &quot;success&quot;: true, &quot;data&quot;: &#123; &quot;blogStatus&quot;: [ &#123; &quot;1&quot;: &quot;自己可见&quot; &#125;, &#123; &quot;2&quot;: &quot;好友可见&quot; &#125;, &#123; &quot;3&quot;: &quot;登陆用户可见&quot; &#125;, &#123; &quot;4&quot;: &quot;公开&quot; &#125; ], &quot;blogType&quot;: [ &#123; &quot;1&quot;: &quot;原创博文&quot; &#125;, &#123; &quot;2&quot;: &quot;转载文章&quot; &#125;, &#123; &quot;3&quot;: &quot;问答&quot; &#125;, &#123; &quot;4&quot;: &quot;投票&quot; &#125;, &#123; &quot;5&quot;: &quot;专栏&quot; &#125; ] &#125;&#125; 此外，如果想通过使用fastjson的JSON.toJSONString()也能得到如上格式的结果，可以让Common继承com.alibaba.fastjson.JSONAware,并在Common中实现JSONAware的toJSONString方法: 1234@Overridedefault String toJSONString() &#123; return JSON.toJSONString(toMap());&#125; 以下代码将会通过: 1Assert.assertEquals(&quot;&#123;2:\\&quot;转载文章\\&quot;&#125;&quot;, JSON.toJSONString(BlogType.REPRINT)); 完整代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283import com.alibaba.fastjson.JSON;import com.alibaba.fastjson.JSONAware;import com.fasterxml.jackson.annotation.JsonValue;import java.util.Arrays;import java.util.HashMap;import java.util.Map;/** * @author wf2311 */public interface Enums &#123; interface Common&lt;C, N&gt; extends JSONAware &#123; C getCode(); N getName(); static &lt;E extends Enum&lt;E&gt; &amp; Common, C&gt; E getByCode(Class&lt;E&gt; clazz, C code) &#123; return Arrays.stream(clazz.getEnumConstants()) .filter(t -&gt; t.getCode().equals(code)) .findFirst().orElse(null); &#125; @JsonValue default Map&lt;C, N&gt; toMap() &#123; Map&lt;C, N&gt; map = new HashMap&lt;&gt;(1); map.put(getCode(), getName()); return map; &#125; @Override default String toJSONString() &#123; return JSON.toJSONString(toMap()); &#125; &#125; enum BlogType implements Common &#123; BLOG(1, &quot;原创博文&quot;), REPRINT(2, &quot;转载文章&quot;), QUESTION(3, &quot;问答&quot;), VOTE(4, &quot;投票&quot;), SUBJECT(5, &quot;专栏&quot;); private Integer code; private String name; BlogType(Integer code, String name) &#123; this.code = code; this.name = name; &#125; public Integer getCode() &#123; return code; &#125; public String getName() &#123; return name; &#125; &#125; enum BlogStatus implements Common &#123; PRIVATE(1, &quot;自己可见&quot;), FRIEND(2, &quot;好友可见&quot;), ONLINE(3, &quot;登陆用户可见&quot;), PUBLISH(4, &quot;公开&quot;); private int code; private String name; BlogStatus(Integer code, String name) &#123; this.code = code; this.name = name; &#125; public Integer getCode() &#123; return code; &#125; public String getName() &#123; return name; &#125; &#125;&#125;","categories":[],"tags":[{"name":"枚举","slug":"枚举","permalink":"https://www.wangfeng.pro/tags/%E6%9E%9A%E4%B8%BE/"}]},{"title":"Maven命令备忘","slug":"Maven/Maven命令备忘","date":"2017-07-28T08:49:07.000Z","updated":"2021-05-14T12:27:05.039Z","comments":true,"path":"2017/07/maven命令备忘.html","link":"","permalink":"https://www.wangfeng.pro/2017/07/maven%E5%91%BD%E4%BB%A4%E5%A4%87%E5%BF%98","excerpt":"更新父模块到指定版本号 1mvn versions:set -DnewVersion=1.0.1-SNAPSHOT 更新子模块版本到与模块相同 1mvn -N versions:update-child-modules 发布版本到指定本地仓库 1mvn deploy -DskipTests -DaltDeploymentRepository=wf2311-mvn-repo::default::file:D:/Projects/open-source/maven-repo/repository/","text":"更新父模块到指定版本号 1mvn versions:set -DnewVersion=1.0.1-SNAPSHOT 更新子模块版本到与模块相同 1mvn -N versions:update-child-modules 发布版本到指定本地仓库 1mvn deploy -DskipTests -DaltDeploymentRepository=wf2311-mvn-repo::default::file:D:/Projects/open-source/maven-repo/repository/ 跳过测试 1-DskipTests 跳过gpg签名 1-DskipGPG 查看执行过程 1-X 把jar包加入本地仓库 1mvn install:install-file -Dfile=D:\\thrift-0.9.2.jar -DgroupId=org.apache.thrift -DartifactId=libthrift -Dversion=0.9.2 -Dpackaging=jar","categories":[{"name":"Maven","slug":"Maven","permalink":"https://www.wangfeng.pro/categories/Maven/"}],"tags":[{"name":"命令","slug":"命令","permalink":"https://www.wangfeng.pro/tags/%E5%91%BD%E4%BB%A4/"},{"name":"笔记","slug":"笔记","permalink":"https://www.wangfeng.pro/tags/%E7%AC%94%E8%AE%B0/"},{"name":"Maven","slug":"Maven","permalink":"https://www.wangfeng.pro/tags/Maven/"}]},{"title":"SpringBoot中使用Thymeleaf模板在找不到对于模板的解决方法","slug":"Spring/SpringBoot/SpringBoot中使用Thymeleaf模板在找不到对于模板的解决方法","date":"2017-07-28T03:04:21.000Z","updated":"2021-04-29T11:45:39.593Z","comments":true,"path":"2017/07/springboot中使用thymeleaf模板在找不到对于模板的解决方法.html","link":"","permalink":"https://www.wangfeng.pro/2017/07/springboot%E4%B8%AD%E4%BD%BF%E7%94%A8thymeleaf%E6%A8%A1%E6%9D%BF%E5%9C%A8%E6%89%BE%E4%B8%8D%E5%88%B0%E5%AF%B9%E4%BA%8E%E6%A8%A1%E6%9D%BF%E7%9A%84%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95","excerpt":"问题描述SpringBoot中使用thymeleaf模板，在IDEA中以main方法运行可以正常显示页面，但在打包之后就会提示找不到模板页面的错误信息:","text":"问题描述SpringBoot中使用thymeleaf模板，在IDEA中以main方法运行可以正常显示页面，但在打包之后就会提示找不到模板页面的错误信息: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116[THYMELEAF][http-nio-4000-exec-1] Exception processing template &quot;/blog/index&quot;: Error resolving template &quot;/blog/index&quot;, template might not exist or might not be accessible by any of the configured Template Resolversorg.thymeleaf.exceptions.TemplateInputException: Error resolving template &quot;/blog/index&quot;, template might not exist or might not be accessible by any of the configured Template Resolvers at org.thymeleaf.engine.TemplateManager.resolveTemplate(TemplateManager.java:870) ~[thymeleaf-3.0.7.RELEASE.jar!/:3.0.7.RELEASE] at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:607) ~[thymeleaf-3.0.7.RELEASE.jar!/:3.0.7.RELEASE] at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1098) [thymeleaf-3.0.7.RELEASE.jar!/:3.0.7.RELEASE] at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1072) [thymeleaf-3.0.7.RELEASE.jar!/:3.0.7.RELEASE] at org.thymeleaf.spring4.view.ThymeleafView.renderFragment(ThymeleafView.java:353) [thymeleaf-spring4-3.0.7.RELEASE.jar!/:3.0.7.RELEASE] at org.thymeleaf.spring4.view.ThymeleafView.render(ThymeleafView.java:191) [thymeleaf-spring4-3.0.7.RELEASE.jar!/:3.0.7.RELEASE] at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1286) [spring-webmvc-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1041) [spring-webmvc-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:984) [spring-webmvc-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) [spring-webmvc-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) [spring-webmvc-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) [spring-webmvc-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:635) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) [spring-webmvc-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:742) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) [tomcat-embed-websocket-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.springframework.web.servlet.resource.ResourceUrlEncodingFilter.doFilter(ResourceUrlEncodingFilter.java:59) [spring-webmvc-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) [spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:105) [spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81) [spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) [spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) [spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:478) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:80) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:799) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1455) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_74] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_74] at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at java.lang.Thread.run(Thread.java:745) [?:1.8.0_74]Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is org.thymeleaf.exceptions.TemplateInputException: Error resolving template &quot;/blog/index&quot;, template might not exist or might not be accessible by any of the configured Template Resolvers] with root causeorg.thymeleaf.exceptions.TemplateInputException: Error resolving template &quot;/blog/index&quot;, template might not exist or might not be accessible by any of the configured Template Resolvers at org.thymeleaf.engine.TemplateManager.resolveTemplate(TemplateManager.java:870) ~[thymeleaf-3.0.7.RELEASE.jar!/:3.0.7.RELEASE] at org.thymeleaf.engine.TemplateManager.parseAndProcess(TemplateManager.java:607) ~[thymeleaf-3.0.7.RELEASE.jar!/:3.0.7.RELEASE] at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1098) ~[thymeleaf-3.0.7.RELEASE.jar!/:3.0.7.RELEASE] at org.thymeleaf.TemplateEngine.process(TemplateEngine.java:1072) ~[thymeleaf-3.0.7.RELEASE.jar!/:3.0.7.RELEASE] at org.thymeleaf.spring4.view.ThymeleafView.renderFragment(ThymeleafView.java:353) ~[thymeleaf-spring4-3.0.7.RELEASE.jar!/:3.0.7.RELEASE] at org.thymeleaf.spring4.view.ThymeleafView.render(ThymeleafView.java:191) ~[thymeleaf-spring4-3.0.7.RELEASE.jar!/:3.0.7.RELEASE] at org.springframework.web.servlet.DispatcherServlet.render(DispatcherServlet.java:1286) ~[spring-webmvc-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.web.servlet.DispatcherServlet.processDispatchResult(DispatcherServlet.java:1041) ~[spring-webmvc-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:984) ~[spring-webmvc-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:901) ~[spring-webmvc-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:970) ~[spring-webmvc-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:861) ~[spring-webmvc-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:635) ~[tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:846) ~[spring-webmvc-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at javax.servlet.http.HttpServlet.service(HttpServlet.java:742) ~[tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:231) ~[tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:52) ~[tomcat-embed-websocket-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.springframework.web.servlet.resource.ResourceUrlEncodingFilter.doFilter(ResourceUrlEncodingFilter.java:59) ~[spring-webmvc-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:99) ~[spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.springframework.web.filter.HttpPutFormContentFilter.doFilterInternal(HttpPutFormContentFilter.java:105) ~[spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.springframework.web.filter.HiddenHttpMethodFilter.doFilterInternal(HiddenHttpMethodFilter.java:81) ~[spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:197) ~[spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:107) ~[spring-web-4.3.10.RELEASE.jar!/:4.3.10.RELEASE] at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:193) ~[tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:166) ~[tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:198) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:96) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:478) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:140) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:80) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:87) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:342) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:799) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:66) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:868) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1455) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142) [?:1.8.0_74] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617) [?:1.8.0_74] at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61) [tomcat-embed-core-8.5.16.jar!/:8.5.16] at java.lang.Thread.run(Thread.java:745) [?:1.8.0_74] 错误原因参考stackflow 类似的问题 You don’t need the leading / on the view name, i.e. you should return fragments :: nodeList rather than /fragments :: nodeList. Having made this change Thymeleaf should be able to find the template when run from your IDE or from a jar file.If you’re interested, here’s what’s happening under the hood:The view name is used to search for a resource on the classpath. fragments :: nodeList means that the resource name is /templates/fragments.html and /fragments :: nodeList means that the resource name is /templates//fragments.html (note the double slash). When you’re running in your IDE the resource is available straight off the filesystem and the double slash doesn’t cause a problem. When you’re running from a jar file the resource is nested within that jar and the double slash prevents it from being found. I don’t fully understand why there’s this difference in behaviour and it is rather unfortunate. I’ve opened an issue so that we (the Spring Boot team) can see if there’s anything we can do to make the behaviour consistent. 简单来说就是在springboot配置文件里的spring.thymeleaf.prefix=classpath:/templates/的与返回页面的视图设置mav.setViewName(&quot;/blog/write&quot;); 在组成url路径时会构成一个双斜杠//，在IDEA中运行时是可以被识别的，但在程序打包运行之后就不能被识别了，所以会出现这个问题。 解决办法根据上面的错误原因分析，目前的解决办法就是让模板的路径中不会出现双斜杠//，或者支持双斜杠//路径(目前已经有人在jira中提出了该bug 期待在之后的版本中能狗支持双斜杠//路径) 去掉返回视图页面最前面的斜杠： mav.setViewName(&quot;/blog/write&quot;); 改为 mav.setViewName(&quot;blog/write&quot;); 或者在配置文件里去掉最后的斜杠： spring.thymeleaf.prefix=classpath:/templates/ 改为 spring.thymeleaf.prefix=classpath:/templates 同时需要修改thymeleaf模板文件中的相关内容，比如 layout:decorate=&quot;~&#123;blog/common/common&#125; 此时应变为 layout:decorate=&quot;~&#123;/blog/common/common&#125;","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.wangfeng.pro/categories/Spring/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"https://www.wangfeng.pro/categories/Spring/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.wangfeng.pro/tags/SpringBoot/"},{"name":"Thymeleaf","slug":"Thymeleaf","permalink":"https://www.wangfeng.pro/tags/Thymeleaf/"}]},{"title":"Git常用命令备忘","slug":"Git/Git常用命令备忘","date":"2017-07-19T09:24:22.000Z","updated":"2021-05-14T12:27:05.023Z","comments":true,"path":"2017/07/git常用命令备忘.html","link":"","permalink":"https://www.wangfeng.pro/2017/07/git%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%E5%A4%87%E5%BF%98","excerpt":"克隆远程制定分支到本地1git clone -b &lt;branch&gt; &lt;remote_repo&gt; ## branch为分支名，remote_repo为远程仓库 强制覆盖本地文件123git fetch --allgit reset --hard origin/mastergit pull 提交文件123git add a.file b.flegit commit -m &quot;备注&quot;git push 标签相关切换到指定分支1git checkout &lt;branch&gt; 检出指定分支1git checkout tags/&lt;tag_name&gt; -b &lt;branch_name&gt; 新建标签1git tag &lt;tagName&gt; 查看所有标签1git tag","text":"克隆远程制定分支到本地1git clone -b &lt;branch&gt; &lt;remote_repo&gt; ## branch为分支名，remote_repo为远程仓库 强制覆盖本地文件123git fetch --allgit reset --hard origin/mastergit pull 提交文件123git add a.file b.flegit commit -m &quot;备注&quot;git push 标签相关切换到指定分支1git checkout &lt;branch&gt; 检出指定分支1git checkout tags/&lt;tag_name&gt; -b &lt;branch_name&gt; 新建标签1git tag &lt;tagName&gt; 查看所有标签1git tag 统计相关查看git上个人代码量1git log --author=&quot;&lt;username&gt;&quot; --pretty=tformat: --numstat | awk &#x27;&#123; add += $1; subs += $2; loc += $1 - $2 &#125; END &#123; printf &quot;added lines: %s, removed lines: %s, total lines: %s\\n&quot;, add, subs, loc &#125;&#x27; - 统计每个人的增删行数1git log --format=&#x27;%aN&#x27; | sort -u | while read name; do echo -en &quot;$name\\t&quot;; git log --author=&quot;$name&quot; --pretty=tformat: --numstat | awk &#x27;&#123; add += $1; subs += $2; loc += $1 - $2 &#125; END &#123; printf &quot;added lines: %s, removed lines: %s, total lines: %s\\n&quot;, add, subs, loc &#125;&#x27; -; done 查看仓库提交者排名前 51git log --pretty=&#x27;%aN&#x27; | sort | uniq -c | sort -k1 -n -r | head -n 5 贡献者统计1git log --pretty=&#x27;%aN&#x27; | sort -u | wc -l 提交数统计1git log --oneline | wc -l 统计项目某个某个时间段的行数1git log --author=&quot;$(git config --get user.name)&quot; --before=&#x27;2018-12-31 23:59:59&#x27; --after=&#x27;2018-01-01 00:00:00&#x27; --pretty=tformat: --numstat | awk &#x27;&#123; add += $1 ; subs += $2 ; loc += $1 - $2 &#125; END &#123; printf &quot;added lines: %s removed lines : %s total lines: %s\\n&quot;,add,subs,loc &#125;&#x27; 参考 git统计项目中各成员代码量 https://liuyueyi.github.io/hexblog/2019/01/27/190127-Git%E9%A1%B9%E7%9B%AE%E4%BB%A3%E7%A0%81%E8%A1%8C%E6%95%B0%E7%BB%9F%E8%AE%A1/","categories":[{"name":"Git","slug":"Git","permalink":"https://www.wangfeng.pro/categories/Git/"}],"tags":[{"name":"命令","slug":"命令","permalink":"https://www.wangfeng.pro/tags/%E5%91%BD%E4%BB%A4/"},{"name":"笔记","slug":"笔记","permalink":"https://www.wangfeng.pro/tags/%E7%AC%94%E8%AE%B0/"},{"name":"Git","slug":"Git","permalink":"https://www.wangfeng.pro/tags/Git/"}]},{"title":"HttpServletRequest常用获取URL的方法","slug":"Spring/HttpServletRequest常用获取URL的方法","date":"2017-07-17T02:56:50.000Z","updated":"2021-04-29T11:37:10.249Z","comments":true,"path":"2017/07/httpservletrequest常用获取url的方法.html","link":"","permalink":"https://www.wangfeng.pro/2017/07/httpservletrequest%E5%B8%B8%E7%94%A8%E8%8E%B7%E5%8F%96url%E7%9A%84%E6%96%B9%E6%B3%95","excerpt":"","text":"request.getRequestURL()返回的是完整的url，包括Http协议，端口号，servlet名字和映射路径，但它不包含请求参数。 request.getRequestURI()得到的是request URL的部分值，并且web容器没有decode过的 request.getContextPath()返回 the context of the request. request.getServletPath()返回调用servlet的部分url. request.getQueryString() 返回url路径后面的查询字符串 示例：当前url：http://localhost:8080/CarsiLogCenter_new/idpstat.jsp?action=idp.sptopn request.getRequestURL(): http://localhost:8080/CarsiLogCenter_new/idpstat.jsp request.getRequestURI(): /CarsiLogCenter_new/idpstat.jsp request.getContextPath():/CarsiLogCenter_new request.getServletPath(): /idpstat.jsp request.getQueryString(): action=idp.sptopn","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.wangfeng.pro/categories/Spring/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://www.wangfeng.pro/tags/%E7%AC%94%E8%AE%B0/"},{"name":"Servlet","slug":"Servlet","permalink":"https://www.wangfeng.pro/tags/Servlet/"},{"name":"HttpServletRequest","slug":"HttpServletRequest","permalink":"https://www.wangfeng.pro/tags/HttpServletRequest/"},{"name":"SpringMvc","slug":"SpringMvc","permalink":"https://www.wangfeng.pro/tags/SpringMvc/"}]},{"title":"使用Thymeleaf变量给onclick属性赋值","slug":"Spring/使用Thymeleaf变量给onclick属性赋值","date":"2017-07-15T01:47:13.000Z","updated":"2021-04-29T11:41:46.039Z","comments":true,"path":"2017/07/使用thymeleaf变量给onclick属性赋值.html","link":"","permalink":"https://www.wangfeng.pro/2017/07/%E4%BD%BF%E7%94%A8thymeleaf%E5%8F%98%E9%87%8F%E7%BB%99onclick%E5%B1%9E%E6%80%A7%E8%B5%8B%E5%80%BC","excerpt":"","text":"在使用thymeleaf渲染页面时，遇到如下情况： 1&lt;button onclick=&quot;submit(&#x27;publish&#x27;);&quot;&gt;提交&lt;/button&gt; submit函数的参数会根据后端参数的不同而动态改变，Google搜索到了一些类似问题，记录一下解决方法。 已经测试可用的： 1th:onclick=&quot;&#x27;alert(\\&#x27;&#x27; + $&#123;myVar&#125; + &#x27;\\&#x27;);&#x27;&quot; 还未测试： 123456&lt;button th:onclick=&quot;&#x27;javascript:upload(&#x27; + $&#123;gallery&#125; + &#x27;)&#x27;&quot;&gt;&lt;/button&gt;th:onclick=&quot;|upload(&#x27;$&#123;command[&#x27;class&#x27;].simpleName&#125;&#x27;, &#x27;$&#123;gallery&#125;&#x27;)|&quot;&lt;div th:style=&quot;&#x27;background:url(&#x27; + @&#123;/&lt;path-to-image&gt;&#125; + &#x27;);&#x27;&quot;&gt;&lt;/div&gt;","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.wangfeng.pro/categories/Spring/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://www.wangfeng.pro/tags/%E7%AC%94%E8%AE%B0/"},{"name":"Thymeleaf","slug":"Thymeleaf","permalink":"https://www.wangfeng.pro/tags/Thymeleaf/"}]},{"title":"MySQL 优化之 index merge(索引合并)","slug":"MySQL/MySQL 优化之 index merge(索引合并)","date":"2017-07-14T08:09:10.000Z","updated":"2021-04-29T11:45:39.619Z","comments":true,"path":"2017/07/mysql-优化之-index-merge-索引合并.html","link":"","permalink":"https://www.wangfeng.pro/2017/07/mysql-%E4%BC%98%E5%8C%96%E4%B9%8B-index-merge-%E7%B4%A2%E5%BC%95%E5%90%88%E5%B9%B6","excerpt":"深入理解 index merge 是使用索引进行优化的重要基础之一。理解了 index merge 技术，我们才知道应该如何在表上建立索引。","text":"深入理解 index merge 是使用索引进行优化的重要基础之一。理解了 index merge 技术，我们才知道应该如何在表上建立索引。 1.为什么会有index merge我们的 where 中可能有多个条件(或者join)涉及到多个字段，它们之间进行 AND 或者 OR，那么此时就有可能会使用到 index merge 技术。index merge 技术如果简单的说，其实就是：对多个索引分别进行条件扫描，然后将它们各自的结果进行合并(intersect/union)。 MySQL5.0之前，一个表一次只能使用一个索引，无法同时使用多个索引分别进行条件扫描。但是从5.1开始，引入了 index merge 优化技术，对同一个表可以使用多个索引分别进行条件扫描。 相关文档：http://dev.mysql.com/doc/refman/5.6/en/index-merge-optimization.html (注意该文档中说的有几处错误) The Index Merge method is used to retrieve rows with several range scans and to merge their results into one. The merge can produce unions, intersections, or unions-of-intersections of its underlying scans. This access method merges index scans from a single table; it does not merge scans across multiple tables. In EXPLAIN output, the Index Merge method appears as index_merge in the type column. In this case, the key column contains a list of indexes used, and key_len contains a list of the longest key parts for those indexes. index merge: 同一个表的多个索引的范围扫描可以对结果进行合并，合并方式分为三种：union, intersection, 以及它们的组合(先内部intersect然后在外面union)。 官方文档给出了四个例子： 1234SELECT * FROM tbl_name WHERE key1 = 10 OR key2 = 20;SELECT * FROM tbl_name WHERE (key1 = 10 OR key2 = 20) AND non_key=30;SELECT * FROM t1, t2 WHERE (t1.key1 IN (1,2) OR t1.key2 LIKE &#x27;value%&#x27;) AND t2.key1=t1.some_col;SELECT * FROM t1, t2 WHERE t1.key1=1 AND (t2.key1=t1.some_col OR t2.key2=t1.some_col2); 但是第四个例子，感觉并不会使用 index merge. 因为 t2.key1=t1.some_col 和 t2.key2=t1.some_col2 之间进行的是 OR 运算，而且 t2.key2 是复合索引的第二个字段(非第一个字段)。所以：t2.key2 = t1.some_col2 并不能使用到复合索引。(文档这里应该是错误的) index merge 算法根据合并算法的不同分成了三种：intersect, union, sort_union. 2.index merge 之 intersect简单而言，index intersect merge就是多个索引条件扫描得到的结果进行交集运算。显然在多个索引提交之间是 AND 运算时，才会出现 index intersect merge. 下面两种where条件或者它们的组合时会进行 index intersect merge: 条件使用到复合索引中的所有字段或者左前缀字段(对单字段索引也适用) key_part1=const1 AND key_part2=const2 … AND key_partN=constN2) 主键上的任何范围条件 例子： 12SELECT * FROM innodb_table WHERE primary_key &lt; 10 AND key_col1=20;SELECT * FROM tbl_name WHERE (key1_part1=1 AND key1_part2=2) AND key2=2; 上面只说到复合索引，但是其实单字段索引显然也是一样的。比如 select * from tab where key1=xx and key2 =xxx; 也是有可能进行index intersect merge的。另外上面两种情况的 AND 组合也一样可能会进行 index intersect merge. The Index Merge intersection algorithm performs simultaneous scans on all used indexes and produces the intersection of row sequences that it receives from the merged index scans. (intersect merge运行方式：多个索引同时扫描，然后结果取交集) If all columns used in the query are covered by the used indexes, full table rows are not retrieved (EXPLAIN output contains Using index in Extra field in this case). Here is an example of such a query:(索引覆盖扫描，无需回表) 1SELECT COUNT(*) FROM t1 WHERE key1=1 AND key2=1; If the used indexes do not cover all columns used in the query, full rows are retrieved only when the range conditions for all used keys are satisfied.(索引不能覆盖，则对满足条件的再进行回表) If one of the merged conditions is a condition over a primary key of an InnoDB table, it is not used for row retrieval, but is used to filter out rows retrieved using other conditions. 3.index merge 之 union简单而言，index uion merge就是多个索引条件扫描，对得到的结果进行并集运算，显然是多个条件之间进行的是 OR 运算。 下面几种类型的 where 条件，以及他们的组合可能会使用到 index union merge算法： 条件使用到复合索引中的所有字段或者左前缀字段(对单字段索引也适用) 主键上的任何范围条件 任何符合 index intersect merge 的where条件； 上面三种 where 条件进行 OR 运算时，可能会使用 index union merge算法。 例子： SELECT * FROM t1 WHERE key1=1 OR key2=2 OR key3=3;SELECT * FROM innodb_table WHERE (key1=1 AND key2=2) OR (key3=’foo’ AND key4=’bar’) AND key5=5;第一个例子，就是三个 单字段索引 进行 OR 运算，所以他们可能会使用 index union merge算法。 第二个例子，复杂一点。(key1=1 AND key2=2) 是符合 index intersect merge; (key3=’foo’ AND key4=’bar’) AND key5=5 也是符合index intersect merge，所以 二者之间进行 OR 运算，自然可能会使用 index union merge算法。 4.index merge 之 sort_unionThis access algorithm is employed when the WHERE clause was converted to several range conditions combined by OR, but for which the Index Merge method union algorithm is not applicable.(多个条件扫描进行 OR 运算，但是不符合 index union merge算法的，此时可能会使用 sort_union算法) 官方文档给出了两个例子： SELECT * FROM tbl_name WHERE key_col1 &lt; 10 OR key_col2 &lt; 20;SELECT * FROM tbl_name WHERE (key_col1 &gt; 10 OR key_col2 = 20) AND nonkey_col=30;但是显然：因为 key_col2 不是复合索引的第一个字段，对它进行 OR 运算，是不可能使用到索引的。所以这两个例子应该也是错误的，它们实际上并不会进行 index sort_union merge算法。 The difference between the sort-union algorithm and the union algorithm is that the sort-union algorithm must first fetch row IDs for all rows and sort them before returning any rows.(sort-union合并算法和union合并算法的不同点，在于返回结果之前是否排序，为什么需要排序呢？可能是因为两个结果集，进行并集运算，需要去重，所以才进行排序？？？) 5.index merge的局限1）If your query has a complex WHERE clause with deep AND/OR nesting and MySQL does not choose the optimal plan, try distributing terms using the following identity laws: (x AND y) OR z = (x OR z) AND (y OR z)(x OR y) AND z = (x AND z) OR (y AND z)如果我们的条件比较复杂，用到多个 and / or 条件运算，而MySQL没有使用最优的执行计划，那么可以使用上面的两个等式将条件进行转换一下。 2）Index Merge is not applicable to full-text indexes. We plan to extend it to cover these in a future MySQL release.(全文索引没有index merge) 3）Before MySQL 5.6.6, if a range scan is possible on some key, the optimizer will not consider using Index Merge Union or Index Merge Sort-Union algorithms. For example, consider this query: SELECT * FROM t1 WHERE (goodkey1 &lt; 10 OR goodkey2 &lt; 20) AND badkey &lt; 30;For this query, two plans are possible: An Index Merge scan using the (goodkey1 &lt; 10 OR goodkey2 &lt; 20) condition. A range scan using the badkey &lt; 30 condition. However, the optimizer considers only the second plan. 这一点对以低版本的MySQL是一个很大的缺陷。就是如果where条件中有 &gt;, &lt;, &gt;=, &lt;=等条件，那么优化器不会使用 index merge，而且还会忽略其他的索引，不会使用它们，哪怕他们的选择性更优。 6.对 index merge 的进一步优化index merge使得我们可以使用到多个索引同时进行扫描，然后将结果进行合并。听起来好像是很好的功能，但是如果出现了 index intersect merge，那么一般同时也意味着我们的索引建立得不太合理，因为 index intersect merge 是可以通过建立 复合索引进行更一步优化的。 比如下面的select: SELECT * FROM t1 WHERE key1=1 AND key2=2 AND key3=3;显然我们是可以在这三个字段上建立一个复合索引来进行优化的，这样就只需要扫描一个索引一次，而不是对三个所以分别扫描一次。 percona官网有一篇 比较复合索引和index merge 的好文章：Multi Column indexes vs Index Merge 7.复合索引的最左前缀原则上面我们说到，对复合索引的非最左前缀字段进行 OR 运算，是无法使用到复合索引的。比如： SELECT * FROM tbl_name WHERE (key_col1 &gt; 10 OR key_col2 = 20) AND nonkey_col=30;其原因是，MySQL中的索引，使用的是B+tree, 也就是说他是：先按照复合索引的 第一个字段的大小来排序，插入到 B+tree 中的，当第一个字段值相同时，在按照第二个字段的值比较来插入的。那么如果我们需要对： OR key_col2 = 20 这样的条件也使用复合索引，那么该怎么操作呢？应该要对复合索引进行全扫描，找出所有 key_col2 =20 的项，然后还要回表去判断 nonkey_col=30，显然代价太大了。所以一般而言 OR key_col2 = 20 这样的条件是无法使用到复合索引的。如果一定要使用索引，那么可以在 col2 上单独建立一个索引。 复合索引的最左前缀原则： MySQL中的复合索引，查询时只会使用到最左前缀，比如： 1234567891011121314 mysql&gt; show index from role_goods; +------------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+ | Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | +------------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+ | role_goods | 0 | PRIMARY | 1 | id | A | 22816 | NULL | NULL | | BTREE | | | | role_goods | 1 | roleId | 1 | roleId | A | 1521 | NULL | NULL | YES | BTREE | | | | role_goods | 1 | goodsId | 1 | goodsId | A | 1521 | NULL | NULL | YES | BTREE | | | | role_goods | 1 | roleId_2 | 1 | roleId | A | 1901 | NULL | NULL | YES | BTREE | | | | role_goods | 1 | roleId_2 | 2 | status | A | 4563 | NULL | NULL | YES | BTREE | | | | role_goods | 1 | roleId_2 | 3 | number | A | 22816 | NULL | NULL | YES | BTREE | | | +------------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+6 rows in set (0.00 sec) 上面有一个复合索引：roleId_2(roleId,status,number)，如果条件是： where roleId=xxx and number=xxx，那么此时只会使用到最左前缀roleId，而不会使用到 number 来进行过滤。因为它们中间存在一个字段 status 没有出现在where条件中。实验如下所示： 123456789101112131415161718192021222324252627282930mysql&gt; explain select * from role_goods where roleId=100000001 and status=1 and number=1 limit 1;+----+-------------+------------+------+-----------------+----------+---------+-------------------+------+-------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+------------+------+-----------------+----------+---------+-------------------+------+-------+| 1 | SIMPLE | role_goods | ref | roleId,roleId_2 | roleId_2 | 23 | const,const,const | 13 | NULL |+----+-------------+------------+------+-----------------+----------+---------+-------------------+------+-------+1 row in set (0.00 sec)mysql&gt; explain select * from role_goods where roleId=100000001 and status=1 limit 1;+----+-------------+------------+------+-----------------+----------+---------+-------------+------+-------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+------------+------+-----------------+----------+---------+-------------+------+-------+| 1 | SIMPLE | role_goods | ref | roleId,roleId_2 | roleId_2 | 14 | const,const | 13 | NULL |+----+-------------+------------+------+-----------------+----------+---------+-------------+------+-------+1 row in set (0.00 sec)mysql&gt; explain select * from role_goods where roleId=100000001 and number=1 limit 1;+----+-------------+------------+------+-----------------+--------+---------+-------+------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+------------+------+-----------------+--------+---------+-------+------+-------------+| 1 | SIMPLE | role_goods | ref | roleId,roleId_2 | roleId | 9 | const | 14 | Using where |+----+-------------+------------+------+-----------------+--------+---------+-------+------+-------------+1 row in set (0.01 sec)mysql&gt; explain select * from role_goods ignore index(roleId) where roleId=100000001 and number=1 limit 1;+----+-------------+------------+------+---------------+----------+---------+-------+------+-----------------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+------------+------+---------------+----------+---------+-------+------+-----------------------+| 1 | SIMPLE | role_goods | ref | roleId_2 | roleId_2 | 9 | const | 14 | Using index condition |+----+-------------+------------+------+---------------+----------+---------+-------+------+-----------------------+1 row in set (0.01 sec) 可以看到 key_len 的变化： 显然最后一个查询仅仅使用到符合索引中的 roleId, 没有使用到 number. number使用在了 index conditon(也就是索引的push down技术) 注意最左前缀，并不是是指：一定要按照各个字段出现在where中的顺序来建立复合索引的。比如 1where status=2 and roleId=xxx and number = xxx 该条件建立符合索引，我们并不需要按照status,roleId，number它们出现的顺序来建立索引： 1alter table role_goods add index sin(status,roleId,number) 这是对最左前缀极大的误解。因为 where status=2 and roleId=xxx and number = xxx 和 where roleId=xxx and number = xxx and status=2它们是等价的。复合索引，哪个字段放在最前面，需要根据哪个字段经常出现在where条件中，哪个字段的选择性最好来判断的。 进一步可以参考的文章： http://www.orczhou.com/index.php/2013/01/mysql-source-code-query-optimization-index-merge/ http://www.cnblogs.com/nocode/archive/2013/01/28/2880654.html","categories":[{"name":"MySQL","slug":"MySQL","permalink":"https://www.wangfeng.pro/categories/MySQL/"}],"tags":[{"name":"索引","slug":"索引","permalink":"https://www.wangfeng.pro/tags/%E7%B4%A2%E5%BC%95/"}]},{"title":"在SpringBoot里面使用Thymeleaf3","slug":"Spring/SpringBoot/在SpringBoot里面使用Thymeleaf3","date":"2017-05-26T01:53:26.000Z","updated":"2021-04-29T11:45:39.601Z","comments":true,"path":"2017/05/在springboot里面使用thymeleaf3.html","link":"","permalink":"https://www.wangfeng.pro/2017/05/%E5%9C%A8springboot%E9%87%8C%E9%9D%A2%E4%BD%BF%E7%94%A8thymeleaf3","excerpt":"","text":"最近在一个springboot项目里使用thymeleaf模板，访问页面时一直报错。而之前的项目中没发现过这种情况发生。和之前的项目对比发现，在springboot项目中引入 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt; 引入的thymeleaf版本居然是2.x.x版本，之前项目引入的是3.x.x版本的 查看相应的pom文件发现，thymeleaf.version确实是2.x.x的。究竟怎么回事呢？搜索springboot文档中相关thymeleaf的段落，发现了如下描述: 原来在spring-boot-starter-thymeleaf中默认引入的版本thymeleaf是2.1,如果需要使用thymeleaf3,需要在pom.xml中加入如下配置： 1234&lt;properties&gt; &lt;thymeleaf.version&gt;3.0.2.RELEASE&lt;/thymeleaf.version&gt; &lt;thymeleaf-layout-dialect.version&gt;2.1.1&lt;/thymeleaf-layout-dialect.version&gt;&lt;/properties&gt;","categories":[{"name":"Spring","slug":"Spring","permalink":"https://www.wangfeng.pro/categories/Spring/"},{"name":"SpringBoot","slug":"Spring/SpringBoot","permalink":"https://www.wangfeng.pro/categories/Spring/SpringBoot/"}],"tags":[{"name":"SpringBoot","slug":"SpringBoot","permalink":"https://www.wangfeng.pro/tags/SpringBoot/"},{"name":"Thymeleaf","slug":"Thymeleaf","permalink":"https://www.wangfeng.pro/tags/Thymeleaf/"}]},{"title":"Runnable实现资源共享","slug":"Java/多线程与并发/Runnable实现资源共享","date":"2017-05-25T09:03:18.000Z","updated":"2021-05-14T13:06:17.472Z","comments":true,"path":"2017/05/runnable实现资源共享.html","link":"","permalink":"https://www.wangfeng.pro/2017/05/runnable%E5%AE%9E%E7%8E%B0%E8%B5%84%E6%BA%90%E5%85%B1%E4%BA%AB","excerpt":"","text":"参考地址 以抢票或秒杀为例 错误示例1： Service12345678910111213class Service implements Runnable &#123; private int remain = 100; public AtomicInteger count = new AtomicInteger(0); @Override public void run() &#123; while (remain &gt; 0) &#123; System.out.println(Thread.currentThread().getName() + &quot; 剩余：&quot; + this.remain--); count.addAndGet(1); &#125; &#125;&#125; 测试方法：12345678910111213141516171819202122232425public class Main &#123; public static int buy() throws InterruptedException &#123; Service service = new Service(); Thread[] threads = new Thread[100]; for (int i = 0; i &lt; threads.length; i++) &#123; threads[i] = new Thread(service); &#125; for (int i = 0; i &lt; threads.length; i++) &#123; threads[i].start(); &#125; Thread.sleep(50); return service.count.get(); &#125; public static void main(String[] args) throws InterruptedException &#123; int[] array = new int[100]; for (int i = 0; i &lt; array.length; i++) &#123; array[i] = buy(); &#125; long a = Arrays.stream(array).filter(i -&gt; i &gt; 100).count(); System.out.println(&quot;执行次数大于100的个数：&quot; + a); &#125;&#125; 测试结果： 执行100次中出现了13次下单次数大于100次的情况 原因分析:在上述方法中，多个线程共享一个变量，会存在并发争抢资源的问题，可能多买票的现象。","categories":[{"name":"Java","slug":"Java","permalink":"https://www.wangfeng.pro/categories/Java/"},{"name":"多线程与并发","slug":"Java/多线程与并发","permalink":"https://www.wangfeng.pro/categories/Java/%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%8E%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"Thread","slug":"Thread","permalink":"https://www.wangfeng.pro/tags/Thread/"}]},{"title":"jQuery checkbox选中、改变状态、change和click事件","slug":"前端/jQuery checkbox选中、改变状态、change和click事件","date":"2017-05-25T02:55:13.000Z","updated":"2021-05-14T12:30:07.832Z","comments":true,"path":"2017/05/jquery-checkbox选中、改变状态、change和click事件.html","link":"","permalink":"https://www.wangfeng.pro/2017/05/jquery-checkbox%E9%80%89%E4%B8%AD%E3%80%81%E6%94%B9%E5%8F%98%E7%8A%B6%E6%80%81%E3%80%81change%E5%92%8Cclick%E4%BA%8B%E4%BB%B6","excerpt":"jquery判断checked的三种方法:123.attr(&#x27;checked&#x27;); //看版本1.6+返回:”checked”或”undefined” ;1.5-返回:true或false.prop(&#x27;checked&#x27;); //1.6+:true/false.is(&#x27;:checked&#x27;); //所有版本:true/false//别忘记冒号哦","text":"jquery判断checked的三种方法:123.attr(&#x27;checked&#x27;); //看版本1.6+返回:”checked”或”undefined” ;1.5-返回:true或false.prop(&#x27;checked&#x27;); //1.6+:true/false.is(&#x27;:checked&#x27;); //所有版本:true/false//别忘记冒号哦 jquery赋值checked的几种写法:123456789101112//所有的jquery版本都可以这样赋值:$(&quot;#cb1&quot;).attr(&quot;checked&quot;, &quot;checked&quot;);$(&quot;#cb1&quot;).attr(&quot;checked&quot;, true);//jquery1.6+:prop的4种赋值:$(&quot;#cb1&quot;).prop(&quot;checked&quot;, true);$(&quot;#cb1&quot;).prop(&#123;checked: true&#125;);$(&quot;#cb1&quot;).prop(&quot;checked&quot;, function () &#123; return true;//函数返回true或false&#125;);//记得还有这种哦:$(&quot;#cb1″).prop(&quot;checked&quot;,&quot;checked&quot;); checkbox click和change事件123456789101112131415161718192021222324252627282930313233343536//方法1:$(&quot;#ischange&quot;).change(function () &#123; alert(&quot;checked&quot;);&#125;);//方法2:$(function () &#123; if ($.browser.msie) &#123; $(&#x27;input:checkbox&#x27;).click(function () &#123; this.blur(); this.focus(); &#125;); &#125;&#125;);//方法3：$(&quot;#ischange&quot;).change(function () &#123; alert(&quot;checked&quot;);&#125;);//方法4:$(function () &#123; if ($.browser.msie) &#123; $(&#x27;input:checkbox&#x27;).click(function () &#123; this.blur(); this.focus(); &#125;); &#125;&#125;);//方法5:$(document).ready(function () &#123; $(&quot;testCheckbox&quot;).change(function () &#123; alert(&quot;Option changed!&quot;); &#125;);&#125;);","categories":[{"name":"前端","slug":"前端","permalink":"https://www.wangfeng.pro/categories/%E5%89%8D%E7%AB%AF/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://www.wangfeng.pro/tags/%E7%AC%94%E8%AE%B0/"},{"name":"jQuery","slug":"jQuery","permalink":"https://www.wangfeng.pro/tags/jQuery/"},{"name":"转载","slug":"转载","permalink":"https://www.wangfeng.pro/tags/%E8%BD%AC%E8%BD%BD/"}]},{"title":"Nginx出现413 Request Entity Too Large 解决方法","slug":"Nginx/Nginx出现413 Request Entity Too Large 解决方法","date":"2017-05-24T07:50:14.000Z","updated":"2021-04-29T11:45:39.610Z","comments":true,"path":"2017/05/nginx出现413-request-entity-too-large-解决方法.html","link":"","permalink":"https://www.wangfeng.pro/2017/05/nginx%E5%87%BA%E7%8E%B0413-request-entity-too-large-%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95","excerpt":"","text":"nginx.conf中默认没有设置client_max_body_size，这个参数默认只是1M， 解决办法： 增加如下两行到nginx.conf的http&#123;&#125;段， 增大nginx上传文件大小限制 123#设置允许发布内容为8Mclient_max_body_size 8M;client_body_buffer_size 128k;","categories":[{"name":"Nginx","slug":"Nginx","permalink":"https://www.wangfeng.pro/categories/Nginx/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://www.wangfeng.pro/tags/%E7%AC%94%E8%AE%B0/"},{"name":"Nginx","slug":"Nginx","permalink":"https://www.wangfeng.pro/tags/Nginx/"}]},{"title":"水仙花算法","slug":"数据结构与算法/水仙花算法","date":"2017-05-23T03:24:15.000Z","updated":"2021-05-14T13:06:17.446Z","comments":true,"path":"2017/05/水仙花算法.html","link":"","permalink":"https://www.wangfeng.pro/2017/05/%E6%B0%B4%E4%BB%99%E8%8A%B1%E7%AE%97%E6%B3%95","excerpt":"算法描述 水仙花数是一个n(&gt;=3)位数字的数,它等于每个数字的n次幂之和 列如153分别是1 5 3 这几个数的立方之和","text":"算法描述 水仙花数是一个n(&gt;=3)位数字的数,它等于每个数字的n次幂之和 列如153分别是1 5 3 这几个数的立方之和 算法实现12345678910111213141516171819202122232425262728293031323334353637/** * 计算从100到endNum范围内的水仙花数 */public int[] narcissisticNumber(int endNum) &#123; return IntStream.range(100, endNum).parallel() //判断n是否为水仙花数 .filter(n -&gt; isNarcissistic(n)) //得到结 果作为数值返回 .toArray();&#125;/** * 判断一个整数是否是水仙花数 */private boolean isNarcissistic(int n) &#123; //切割整数 String[] array = String.valueOf(n).split(&quot;&quot;); int sum = Arrays.stream(array) //n次方 .mapToInt(i -&gt; nPower(Integer.valueOf(i), array.length)) //求和 .sum(); return sum == n;&#125;/** * 计算n次方 */public int nPower(int i, int n) &#123; int sum = 1; while (n &gt; 0) &#123; sum *= i; n--; &#125; return sum;&#125; 测试12345678/** * 计算1_0000_0000以内的水仙花数 */@Testpublic void test() &#123; int[] ints = narcissisticNumber(1_0000_0000); Arrays.stream(ints).forEach(System.out::println);&#125; 输出1234567891011121314151617181533703714071634820894745474892727930845488341741725421081898008179926315246780502467805188593477","categories":[{"name":"数据结构与算法","slug":"数据结构与算法","permalink":"https://www.wangfeng.pro/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/"}],"tags":[{"name":"Java8","slug":"Java8","permalink":"https://www.wangfeng.pro/tags/Java8/"},{"name":"算法","slug":"算法","permalink":"https://www.wangfeng.pro/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"Java8中利用Stream过滤属性重复的元素","slug":"Java/Java基础/Java8中利用Stream过滤属性重复的元素","date":"2017-05-23T03:10:08.000Z","updated":"2021-05-14T13:06:17.451Z","comments":true,"path":"2017/05/java8中利用stream过滤属性重复的元素.html","link":"","permalink":"https://www.wangfeng.pro/2017/05/java8%E4%B8%AD%E5%88%A9%E7%94%A8stream%E8%BF%87%E6%BB%A4%E5%B1%9E%E6%80%A7%E9%87%8D%E5%A4%8D%E7%9A%84%E5%85%83%E7%B4%A0","excerpt":"","text":"根据属性过滤重复的元素参考地址 1234567/** * 根据属性过滤重复的元素 */public static &lt;T&gt; Predicate&lt;T&gt; distinctByKey(Function&lt;? super T,Object&gt; keyExtractor) &#123; Map&lt;Object,Boolean&gt; seen = new ConcurrentHashMap&lt;&gt;(); return t -&gt; seen.putIfAbsent(keyExtractor.apply(t), Boolean.TRUE) == null;&#125; 测试12345678910111213141516171819202122232425262728293031323334353637static String[] data = new String[]&#123; &quot;1,2,a,4,5,6&quot;, &quot;2,2,b,4,5,6&quot;, &quot;3,2,a,4,5,6&quot;, &quot;4,2,d,4,5,6&quot;, &quot;5,2,b,5,5,6&quot;, &quot;6,2,f,4,5,6&quot;, &quot;7,2,c,4,5,6&quot;, &quot;8,2,g,4,5,6&quot;, &quot;9,2,d,4,5,6&quot;, &quot;10,2,g,5,5,6&quot;,&#125;;/** * 根据单个属性过滤 */@Testpublic void test1() &#123; int[] arrays = Stream.of(data).map(d -&gt; d.split(&quot;,&quot;)) .filter(array -&gt; !array[0].equals(&quot;1&quot;)) .filter(distinctByKey(array -&gt; array[2])) .mapToInt(array -&gt; Integer.valueOf(array[0])) .toArray(); Assert.assertArrayEquals(new int[]&#123;2, 3, 4, 6, 7, 8&#125;, arrays);&#125;/** * 根据多个属性过滤 */@Testpublic void test2() &#123; int[] arrays = Stream.of(data).map(d -&gt; d.split(&quot;,&quot;)) .filter(distinctByKey(array -&gt; array[2] + array[3])) .mapToInt(array -&gt; Integer.valueOf(array[0])) .toArray(); Assert.assertArrayEquals(new int[]&#123;1, 2, 4, 5, 6, 7, 8, 10&#125;, arrays);&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://www.wangfeng.pro/categories/Java/"},{"name":"Java基础","slug":"Java/Java基础","permalink":"https://www.wangfeng.pro/categories/Java/Java%E5%9F%BA%E7%A1%80/"}],"tags":[{"name":"Java8","slug":"Java8","permalink":"https://www.wangfeng.pro/tags/Java8/"},{"name":"Stream","slug":"Stream","permalink":"https://www.wangfeng.pro/tags/Stream/"}]}]}